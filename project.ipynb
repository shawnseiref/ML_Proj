{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project.ipynb","provenance":[],"collapsed_sections":["eA6sW5nFNPSB"],"toc_visible":true,"authorship_tag":"ABX9TyOLoeZxr1PM0r4HoW3laZXA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"yj6Vq6n7BKuP","colab_type":"text"},"source":["###Connect to Drive"]},{"cell_type":"code","metadata":{"id":"CsZ5Ho0LAIVk","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590375418,"user_tz":-180,"elapsed":1893,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["# # Import PyDrive and associated libraries.\n","# # This only needs to be done once per notebook.\n","# from pydrive.auth import GoogleAuth\n","# from pydrive.drive import GoogleDrive\n","# from google.colab import auth\n","# from oauth2client.client import GoogleCredentials\n","\n","# # Authenticate and create the PyDrive client.\n","# # This only needs to be done once per notebook.\n","# auth.authenticate_user()\n","# gauth = GoogleAuth()\n","# gauth.credentials = GoogleCredentials.get_application_default()\n","# drive = GoogleDrive(gauth)\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"4G0NumKIBKYY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1597590516049,"user_tz":-180,"elapsed":968,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"11ba5d0e-dc8f-4897-f034-9a6472f7c5b1"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=False)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8Z3pqBvrBVzR","colab_type":"text"},"source":["#Installs and Import"]},{"cell_type":"code","metadata":{"id":"w74zbA8JorPA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":583},"executionInfo":{"status":"ok","timestamp":1597590530456,"user_tz":-180,"elapsed":10608,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"0f8567ce-3d9b-4042-8a31-b0740dcfb219"},"source":["# !pip install -q keras\n","# !pip install --upgrade opencv-python\n","# !pip install --upgrade tensorflow\n","# !pip install --upgrade tensorflow-gpu\n","# !pip install --upgrade matplotlib\n","# !pip install --upgrade numpy\n","# !pip install --upgrade pydot\n","# !pip install --upgrade tqdm\n","!pip install --upgrade category_encoders\n","!pip install --upgrade rotation-forest\n","!pip install --upgrade scikit_posthocs\n","# !pip install https://github.com/AmazaspShumik/sklearn_bayes/archive/master.zip\n","# !pip install --upgrade https://github.com/AmazaspShumik/sklearn_bayes/archive/master.zip\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: category_encoders in /usr/local/lib/python3.6/dist-packages (2.2.2)\n","Requirement already satisfied, skipping upgrade: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n","Requirement already satisfied, skipping upgrade: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n","Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied, skipping upgrade: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n","Requirement already satisfied, skipping upgrade: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.0.5)\n","Requirement already satisfied, skipping upgrade: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.16.0)\n","Requirement already up-to-date: rotation-forest in /usr/local/lib/python3.6/dist-packages (0.4)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from rotation-forest) (1.18.5)\n","Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from rotation-forest) (0.22.2.post1)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from rotation-forest) (1.4.1)\n","Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->rotation-forest) (0.16.0)\n","Requirement already up-to-date: scikit_posthocs in /usr/local/lib/python3.6/dist-packages (0.6.5)\n","Requirement already satisfied, skipping upgrade: seaborn in /usr/local/lib/python3.6/dist-packages (from scikit_posthocs) (0.10.1)\n","Requirement already satisfied, skipping upgrade: pandas>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from scikit_posthocs) (1.0.5)\n","Requirement already satisfied, skipping upgrade: statsmodels in /usr/local/lib/python3.6/dist-packages (from scikit_posthocs) (0.10.2)\n","Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.6/dist-packages (from scikit_posthocs) (3.2.2)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from scikit_posthocs) (1.18.5)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from scikit_posthocs) (1.4.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->scikit_posthocs) (2018.9)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->scikit_posthocs) (2.8.1)\n","Requirement already satisfied, skipping upgrade: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels->scikit_posthocs) (0.5.1)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit_posthocs) (0.10.0)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit_posthocs) (1.2.0)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->scikit_posthocs) (2.4.7)\n","Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.20.0->scikit_posthocs) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3kypRwmwpzS3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597610004466,"user_tz":-180,"elapsed":955,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["\n","# Helper libraries\n","import math\n","import numpy as np\n","import pandas as pd\n","import cv2\n","import csv\n","\n","\n","import os, shutil,io\n","import keras\n","from keras import layers\n","from keras import models\n","from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras.utils import np_utils\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from datetime import datetime\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n","from sklearn.utils import check_random_state\n","from sklearn.preprocessing import LabelEncoder,label_binarize\n","from sklearn.model_selection import GridSearchCV,cross_validate,train_test_split, KFold\n","from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier\n","from sklearn.metrics import *\n","from sklearn.multiclass import OneVsRestClassifier\n","import rotation_forest as af\n","from skimage.transform import resize\n","from xgboost import XGBClassifier\n","import torch\n","from torch.utils.data import DataLoader, TensorDataset\n","from torch import nn, optim\n","from numpy import genfromtxt\n","import inspect\n","import tensorflow as tf\n","import xgboost as xgb\n","import argparse\n","# from skbayes.mixture_models import VBBMM\n","from scipy.special import logsumexp\n","from scipy.stats import friedmanchisquare\n","from sklearn.metrics import auc as auc_score\n","import scikit_posthocs as scl_hoc\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # suppress tf verbose logs\n","\n","try:\n","\tfrom time import perf_counter\n","except:\n","\tfrom time import time\n","\tperf_counter = time\n","\n","# Improve progress bar display\n","import tqdm.auto\n","tqdm.tqdm = tqdm.auto.tqdm\n","\n","\n","import PIL\n","import pydot\n","import warnings\n","import category_encoders as ce\n","from google.colab import output\n","warnings.filterwarnings('ignore')"],"execution_count":302,"outputs":[]},{"cell_type":"code","metadata":{"id":"K_PYjB65-ffR","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kUjGyU2pCYo8","colab_type":"text"},"source":["##check gpu connection and print tf version"]},{"cell_type":"code","metadata":{"id":"NU0WQUuXqqrI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1597590534946,"user_tz":-180,"elapsed":1034,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"90beb9b5-768f-442a-c919-e1c7661516a8"},"source":["device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Found GPU at: {}'.format(device_name))\n","print(tf.__version__)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n","2.3.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"r0UTg3SdaZOb","colab_type":"text"},"source":["##Paths"]},{"cell_type":"code","metadata":{"id":"2rXuc7twaYXo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590536616,"user_tz":-180,"elapsed":1090,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["project_dir_path = \"/content/drive/Shared drives/Machine_Learning_Project/\"\n","data_path = \"/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/classification_datasets\"\n","labeled_data_path = \"/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets\"\n","results_path = \"/content/drive/Shared drives/Machine_Learning_Project/Results\"\n","\n","FINISH_SOUNDS = lambda: output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/1/1d/Lala_la_lala_la_lala_la_lala.ogg\").play()')"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_JQ88mPkJqyO","colab_type":"text"},"source":["#Models"]},{"cell_type":"markdown","metadata":{"id":"xg3hDkv7ORc0","colab_type":"text"},"source":["##Parameters"]},{"cell_type":"code","metadata":{"id":"RHH-mgoPOPUM","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590539039,"user_tz":-180,"elapsed":1128,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["seed=1\n","n_splits = 10\n","smoothing = 0.6\n","random_state = 42\n","test_size = 0.4\n","EPSILON = 1e-8\n","verbose = 2\n","fill_mode='nearest'\n","class_mode='categorical'"],"execution_count":28,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QRrxj5ddGEP8","colab_type":"text"},"source":["#Arranged Forest"]},{"cell_type":"markdown","metadata":{"id":"o1JHqoISlraT","colab_type":"text"},"source":["##Distributor"]},{"cell_type":"markdown","metadata":{"id":"Bw31_XfOlv_B","colab_type":"text"},"source":["###Random Distribute\n","\n","    Randomly distribute features into trees, without replacement\n","    num_feature: number of features\n","    num_trees: number of trees\n","    feature_per_tree: number of features in one tree\n","    distributions: distributions already determined\n","    seed: random seed\n","    return: the groups of features\n","        output example [[0,1] , [1,2]]\n","        feature id is from 0 to (num_feature-1)"]},{"cell_type":"code","metadata":{"id":"aWyegStZlKwp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590543433,"user_tz":-180,"elapsed":762,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def random_distribute(num_feature, num_trees, feature_per_tree, distributions, seed):\n","  print(\"using random_distribute\")\n","  # random distribution is quick, but not necessarily gives low similarity\n","  np.random.seed(seed)\n","\n","  m = num_feature\n","  k = feature_per_tree\n","\n","  tree_to_build = num_trees - len(distributions)\n","\n","  # identify all features with array 0,1,2,...,num_feature-1\n","\n","  # in set type, used internally\n","  all_distribution_set = []\n","\n","  for i in distributions:\n","      all_distribution_set.append(set(i))\n","\n","  final_distribution = []\n","\n","  # randomly pick num_feature from all_feature\n","  # if it is in the set, try once more\n","  while len(all_distribution_set) < tree_to_build:\n","\n","      random_set = set(np.random.choice(m, k, replace=False))\n","\n","      if random_set not in all_distribution_set:\n","          all_distribution_set.append(random_set)\n","          if len(all_distribution_set) == tree_to_build:\n","              break\n","\n","  for i in all_distribution_set:\n","      final_distribution.append(list(i))\n","\n","  return final_distribution\n"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KMBZQVGzcR7G","colab_type":"text"},"source":["###Bootstrap Samples"]},{"cell_type":"markdown","metadata":{"id":"iFLPtV-uD4gS","colab_type":"text"},"source":["```\n","  Randomly distribute samples into trees, with replacement\n","  num_trees: number of trees\n","  data_x: feature values\n","  data_y: labels\n","  seed: random seed\n","  return: the groups of samples of feature values and labels\n","      labels at last column\n","      output example [[0,1] , [1,2]]\n","```"]},{"cell_type":"code","metadata":{"id":"P2CMvxBylPMP","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590547236,"user_tz":-180,"elapsed":856,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def bootstrap_samples(num_trees, data_x, data_y, seed=1):\n","  print(\"using bootstrap_samples\")\n","\n","  np.random.seed(seed)\n","  # np.random.choice\n","  # get sample row numbers\n","  num_instances = len(data_x)\n","\n","  row_sets = []\n","\n","  while len(row_sets) < num_trees:\n","\n","      random_set = np.random.choice(num_instances, num_instances, replace=True)\n","      row_sets.append(random_set)\n","\n","  # return num_trees sets of x and y\n","\n","  boot_x = []\n","  boot_y = []\n","\n","  for i in row_sets:\n","    # print(i)\n","    # print('datax - {}'.format(data_x))\n","    # print('datay - {}'.format(data_y))\n","    \n","    # print('datax[i] - {}'.format(data_x[i]))\n","    # print('datay[i] - {}'.format(data_y[i]))\n","    boot_x.append(data_x[i])\n","    boot_y.append(data_y[i])\n","\n","  return boot_x, boot_y"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bncla5IkcWxJ","colab_type":"text"},"source":["###Build Feature Matrix"]},{"cell_type":"markdown","metadata":{"id":"5bPhZmOhEcY3","colab_type":"text"},"source":["\n","\n","```\n","  Build a feature matrix\n","  m must be k*k\n","  k = p\n","  num_feature: number of features\n","  feature_per_tree: number of features in one tree\n","  return: k*k feature matrix A\n","      output example [[0,1] , [2,3]]\n","      feature id is from 0 to (num_feature-1)\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"SuOffg9KlT6M","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590552811,"user_tz":-180,"elapsed":2001,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def build_feature_matrix(num_feature, feature_per_tree):\n","  print(\"using build_feature_matrix\")\n","  \n","  m = num_feature\n","  k = feature_per_tree\n","\n","  element_count = 0\n","\n","  all_rows = []\n","\n","  current_row = []\n","\n","  for i in range(m):\n","\n","      current_row.append(i)\n","\n","      element_count += 1\n","\n","      if element_count == k:\n","          all_rows.append(current_row)\n","          current_row = []\n","          element_count = 0\n","\n","  feature_matrix = np.array(all_rows)\n","\n","  return feature_matrix"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5KUTjljmccgN","colab_type":"text"},"source":["###Build Plus Feature Matrix"]},{"cell_type":"markdown","metadata":{"id":"-MC5mMkpEmF4","colab_type":"text"},"source":["\n","\n","```\n","Build a feature matrix\n","  m must be k*k\n","  k + 1 = p\n","  e.g., build_plus_feature_matrix(25, 5)\n","  num_feature: number of features\n","  feature_per_tree: number of features in one tree\n","  return: (k+1)*(k+1) feature matrix A+\n","      output example [[0,1] , [2,3]]\n","      feature id is from 0 to (num_feature-1)\n","      note: last row and column do not represent features\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"aGXMyFNUlWXF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590561550,"user_tz":-180,"elapsed":650,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def build_plus_feature_matrix(num_feature, feature_per_tree):\n","  print(\"using build_plus_feature_matrix\")\n","  \n","  m = num_feature\n","  k = feature_per_tree\n","\n","  element_count = 0\n","\n","  all_rows = []\n","\n","  current_row = []\n","\n","  for i in range(m):\n","\n","      current_row.append(i)\n","\n","      element_count += 1\n","\n","      if element_count == k:\n","\n","          # for last column, item is 0\n","\n","          current_row.append(0)\n","\n","          all_rows.append(current_row)\n","\n","          current_row = []\n","\n","          element_count = 0\n","\n","  # add last row, all 0\n","\n","  all_rows.append(np.zeros((k+1,), dtype=int))\n","\n","  feature_matrix = np.array(all_rows)\n","\n","  return feature_matrix"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qFWchMGTcgCO","colab_type":"text"},"source":["###Diagonal Distribute"]},{"cell_type":"markdown","metadata":{"id":"Ou-CZIOuEtyh","colab_type":"text"},"source":["\n","\n","```\n","  Diagonal distribution algorithm (DDA)\n","  for k = p\n","  feature_per_tree: number of features in one tree, k\n","  feature_matrix: k*k feature matrix from 0 to m-1, A\n","  return: the k family of features\n","      output example [[0,1] , [1,2]]\n","      feature id is from 0 to (num_feature-1)\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"WztxoagmlY6-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590568732,"user_tz":-180,"elapsed":1159,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def diagonal_distribute(feature_per_tree, feature_matrix):\n","  print(\"using diagonal_distribute\")\n","  k = feature_per_tree\n","  A = feature_matrix\n","\n","  # k family subset to return, F\n","  k_family_F = []\n","\n","  F1 = []\n","\n","  for j in range(k):\n","      F1.append(list(A[j]))\n","\n","  k_family_F = k_family_F + F1\n","\n","  F2 = []\n","\n","  for j in range(k):\n","      for l in range(k):\n","          T=[]\n","          for i in range(k):\n","              # mod k for all operations\n","              col_index = (j+i*l) % k\n","              T.append(A[i][col_index])\n","          F2.append(T)\n","\n","  k_family_F = k_family_F + F2\n","\n","  return k_family_F"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Md57j1iycjBl","colab_type":"text"},"source":["###Modified Diagonal Distribute"]},{"cell_type":"markdown","metadata":{"id":"hKFeONXsFCzx","colab_type":"text"},"source":["\n","\n","```\n","  Modified diagonal distribution algorithm (MDDA)\n","  for k+1 = p\n","  feature_per_tree: number of features in one tree, k\n","  feature_matrix: k*k feature matrix from 0 to m-1, A\n","  return: the k family of features\n","      output example [[0,1] , [1,2]]\n","      feature id is from 0 to (num_feature-1)\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"l25cnG1hlch6","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590571955,"user_tz":-180,"elapsed":1120,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def modified_diagonal_distribute(feature_per_tree, feature_matrix):\n","  print(\"using modified_diagonal_distribute\")\n","  \n","  k = feature_per_tree\n","  A = feature_matrix\n","\n","  # k family subset to return, F\n","  k_family_F = []\n","\n","  F1 = []\n","\n","  for j in range(k):\n","      F1.append(list(A[j]))\n","\n","  k_family_F = k_family_F + F1\n","\n","  # now time to use A+\n","\n","  # get A+\n","  A_plus = build_plus_feature_matrix(k*k, k)\n","\n","  F2 = []\n","\n","  for j in range(k+1):\n","      for l in range(k+1):\n","          T = []\n","          for i in range(k+1):\n","              # mod k for all operations\n","              col_index = (j+i*l) % (k+1)\n","\n","              if not(l == 0 and i == k) and not(l == 0 and j == k):\n","                  T.append([i, col_index])\n","\n","          # check T for removing other non-feature items\n","\n","          for indices in T:\n","              x = indices[0]\n","              y = indices[1]\n","\n","              if x == k and y == k:\n","                  T.remove(indices)\n","              else:\n","                  if x == k:\n","                      # x_2, k in T\n","                      for indices2 in T:\n","                          if indices2[1] == k:\n","                              T.remove([k, y])\n","                              T.remove([indices2[0], k])\n","                              T.append([indices2[0], y])\n","                  elif y == k:\n","                      for indices2 in T:\n","                          if indices2[0] == k:\n","                              T.remove([x, k])\n","                              T.remove([k, indices2[1]])\n","                              T.append([x, indices2[1]])\n","\n","          # append T indices in A+ one by one\n","          T_element = []\n","          for indices in T:\n","              T_element.append(A_plus[indices[0], indices[1]])\n","\n","          if len(T_element) > 0:\n","              F2.append(T_element)\n","\n","  k_family_F = k_family_F + F2\n","\n","  return k_family_F"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u4hs2QVpcnTY","colab_type":"text"},"source":["###Get Repetition Index"]},{"cell_type":"markdown","metadata":{"id":"tiXgVyH1FOaW","colab_type":"text"},"source":["\n","\n","```\n","Count repetition index of a distribution arrangement\n","  :param distributions: distributions already determined\n","  :return: repetition index count\n","      output example 19\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"Ny5grrnmlexN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590577698,"user_tz":-180,"elapsed":1037,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def get_repetition_index(distributions):\n","  print(\"using get_repetition_index\")\n","  \n","  repetition_index = 0\n","\n","  # check each pair without permutation\n","\n","  num_distri = len(distributions)\n","\n","  for i in range(num_distri-1):\n","      for j in range(i+1, num_distri):\n","          # get count between distributions[i], distributions[j]\n","          list_ij = distributions[i] + distributions[j]\n","          set_ij = set(list_ij)\n","          repetition_ij = len(distributions[i]) + len(distributions[j]) - len(set_ij)\n","          repetition_index += repetition_ij\n","\n","  return repetition_index"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tkndLRSecu1q","colab_type":"text"},"source":["###Get Pair Repetition Index"]},{"cell_type":"markdown","metadata":{"id":"SugkGUNVFVYU","colab_type":"text"},"source":["\n","\n","```\n","Count pairwise repetition index of a distribution arrangement\n","  distributions: distributions already determined\n","  return: repetition index count matrix\n","      output example [[0,0],[0,0]]\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"9SU-oJfnlgSY","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590580815,"user_tz":-180,"elapsed":1289,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def get_pair_repetition_index(distributions):\n","  print(\"using get_pair_repetition_index\")\n","  \n","\n","  num_distri = len(distributions)\n","\n","  pair_repetition_index = np.zeros((num_distri, num_distri), int)\n","\n","  for i in range(num_distri-1):\n","      for j in range(i+1, num_distri):\n","          # get count between distributions[i], distributions[j]\n","          list_ij = distributions[i] + distributions[j]\n","          set_ij = set(list_ij)\n","          repetition_ij = len(distributions[i]) + len(distributions[j]) - len(set_ij)\n","          pair_repetition_index[i, j] = repetition_ij\n","\n","  return pair_repetition_index"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"THp5nFz1c1Z6","colab_type":"text"},"source":["### Debug Modified Diagonal Distribute"]},{"cell_type":"markdown","metadata":{"id":"sBTvdDcFFdP9","colab_type":"text"},"source":["\n","\n","```\n","DEBUG Modified diagonal distribution algorithm\n","  for k+1 = p\n","  feature_per_tree: number of features in one tree, k\n","  feature_matrix: k*k feature matrix from 0 to m-1, A\n","  return: the k family of features\n","      output example [[0,1] , [1,2]]\n","      feature id is from 0 to (num_feature-1)\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"m4rqo1WUliqu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590583377,"user_tz":-180,"elapsed":1098,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def debug_modified_diagonal_distribute(feature_per_tree, feature_matrix):\n","  print(\"using debug_modified_diagonal_distribute\")\n","  \n","  k = feature_per_tree\n","  A = feature_matrix\n","\n","  # k family subset to return, F\n","  k_family_F = []\n","\n","  F1 = []\n","\n","  for j in range(k):\n","      F1.append(list(A[j]))\n","\n","  k_family_F = k_family_F + F1\n","\n","  # now time to use A+\n","\n","  # get A+\n","  A_plus = build_plus_feature_matrix(k*k, k)\n","\n","  F2 = []\n","\n","\n","  for j in range(k+1):\n","      for l in range(k+1):\n","          T = []\n","          for i in range(k+1):\n","              # mod k for all operations\n","              col_index = (j+i*l) % (k+1)\n","\n","              if not(l == 0 and i == k) and not(l == 0 and j == k):\n","                  T.append([i, col_index])\n","\n","          # check T for removing other non-feature items\n","\n","          for indices in T:\n","              x = indices[0]\n","              y = indices[1]\n","\n","              if x == k and y == k:\n","                  T.remove(indices)\n","              else:\n","                  if x == k:\n","                      # x_2, k in T\n","                      for indices2 in T:\n","                          if indices2[1] == k:\n","                              T.remove([k, y])\n","                              T.remove([indices2[0], k])\n","                              T.append([indices2[0], y])\n","                  elif y == k:\n","                      for indices2 in T:\n","                          if indices2[0] == k:\n","                              T.remove([x, k])\n","                              T.remove([k, indices2[1]])\n","                              T.append([x, indices2[1]])\n","\n","          # append T indices in A+ one by one\n","          T_element = []\n","          for indices in T:\n","              T_element.append(A_plus[indices[0], indices[1]])\n","\n","          if len(T_element) > 0:\n","              with open('output.txt', 'a') as f:\n","                  f.write('j = ' + str(j + 1))\n","                  f.write(', l = ' + str(l + 1))\n","                  f.write(', round 2 k family number: ' + str(len(F2)+1))\n","                  f.write(', items:  [')\n","                  for e in T_element:\n","                      f.write(str(e+1))\n","                      f.write(', ')\n","                  f.write(']\\n')\n","              F2.append(T_element)\n","\n","\n","\n","\n","  k_family_F = k_family_F + F2\n","\n","  return k_family_F"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e-MxpFJAc7dk","colab_type":"text"},"source":["####Debug2"]},{"cell_type":"markdown","metadata":{"id":"b-ny2rsl_KZl","colab_type":"text"},"source":["\n","\n","```\n","DEBUG2 Modified diagonal distribution algorithm\n","  j and l loop replaced\n","  for k+1 = p\n","  :param feature_per_tree: number of features in one tree, k\n","  :param feature_matrix: k*k feature matrix from 0 to m-1, A\n","  :return: the k family of features\n","      output example [[0,1] , [1,2]]\n","      feature id is from 0 to (num_feature-1)\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"175ZENFplk2L","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590585775,"user_tz":-180,"elapsed":1005,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def debug2_modified_diagonal_distribute(feature_per_tree, feature_matrix):\n","  print(\"using debug2_modified_diagonal_distribute\")\n","  \n","  k = feature_per_tree\n","  A = feature_matrix\n","\n","  # k family subset to return, F\n","  k_family_F = []\n","\n","  F1 = []\n","\n","  for j in range(k):\n","      F1.append(list(A[j]))\n","\n","  k_family_F = k_family_F + F1\n","\n","  # now time to use A+\n","\n","  # get A+\n","  A_plus = build_plus_feature_matrix(k * k, k)\n","\n","  F2 = []\n","\n","  for l in range(k + 1):\n","      for j in range(k + 1):\n","          T = []\n","          for i in range(k + 1):\n","              # mod k for all operations\n","              col_index = (j + i * l) % (k + 1)\n","\n","              if not (l == 0 and i == k) and not (l == 0 and j == k):\n","                  T.append([i, col_index])\n","\n","          # check T for removing other non-feature items\n","\n","          for indices in T:\n","              x = indices[0]\n","              y = indices[1]\n","\n","              if x == k and y == k:\n","                  T.remove(indices)\n","              else:\n","                  if x == k:\n","                      # x_2, k in T\n","                      for indices2 in T:\n","                          if indices2[1] == k:\n","                              T.remove([k, y])\n","                              T.remove([indices2[0], k])\n","                              T.append([indices2[0], y])\n","                  elif y == k:\n","                      for indices2 in T:\n","                          if indices2[0] == k:\n","                              T.remove([x, k])\n","                              T.remove([k, indices2[1]])\n","                              T.append([x, indices2[1]])\n","\n","          # append T indices in A+ one by one\n","          T_element = []\n","          for indices in T:\n","              T_element.append(A_plus[indices[0], indices[1]])\n","\n","          if len(T_element) > 0:\n","\n","              if l > 0:\n","                  with open('output13.txt', 'a') as f:\n","                      f.write('j = ' + str(j + 1))\n","                      f.write(', l = ' + str(l + 1))\n","                      f.write(', round 2 k family number: ' + str(len(F2) + 1))\n","                      f.write(', items:  [')\n","                      for e in T_element:\n","                          f.write(str(e + 1))\n","                          f.write(', ')\n","                      f.write(']\\n')\n","                  F2.append(T_element)\n","\n","  k_family_F = k_family_F + F2\n","\n","  return F2"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zIUaGM4ydDBO","colab_type":"text"},"source":["### Debug Diagonal Distribute"]},{"cell_type":"markdown","metadata":{"id":"5hMygFV3FuZC","colab_type":"text"},"source":["\n","\n","```\n","Debug Diagonal distribution algorithm\n","    for k = p\n","    feature_per_tree: number of features in one tree, k\n","    feature_matrix: k*k feature matrix from 0 to m-1, A\n","    return: the k family of features\n","        output example [[0,1] , [1,2]]\n","        feature id is from 0 to (num_feature-1)\n","```\n","\n"]},{"cell_type":"code","metadata":{"id":"6zOSK-yQlBQ2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590590604,"user_tz":-180,"elapsed":961,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def debug_diagonal_distribute(feature_per_tree, feature_matrix):\n","  print(\"using debug_diagonal_distribute\")\n","    \n","  k = feature_per_tree\n","  A = feature_matrix\n","\n","  # k family subset to return, F\n","  k_family_F = []\n","\n","  F1 = []\n","\n","  for j in range(k):\n","      F1.append(list(A[j]))\n","\n","  k_family_F = k_family_F + F1\n","\n","  F2 = []\n","\n","  for l in range(k):\n","      for j in range(k):\n","          T=[]\n","          for i in range(k):\n","              # mod k for all operations\n","              col_index = (j+i*l) % k\n","              T.append(A[i][col_index])\n","          F2.append(T)\n","\n","          if 1 > 0:\n","\n","              if l > 0:\n","                  with open('DDAoutput.txt', 'a') as f:\n","                      f.write('j = ' + str(j + 1))\n","                      f.write(', l = ' + str(l + 1))\n","                      f.write(', round 2 k family number: ' + str(len(F2) + 1))\n","                      f.write(', items:  [')\n","                      for e in T:\n","                          f.write(str(e + 1))\n","                          f.write(', ')\n","                      f.write(']\\n')\n","\n","\n","  k_family_F = k_family_F + F2\n","\n","  return F2"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ql4mK0esmOVA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590554618,"user_tz":-180,"elapsed":3680,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":[""],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j9AasOL3mizs","colab_type":"text"},"source":["##Modded Forest Classifier"]},{"cell_type":"code","metadata":{"id":"tfcTd2wgj8Tt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590599495,"user_tz":-180,"elapsed":1288,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["class ControlledForestClassifier:\n","  # controlled forests for classifier\n","  # it has a bunch of DecisionTreeClassifier in self.tree\n","  # initialization function\n","  def __init__(self,\n","                n_estimators='warn',\n","                criterion=\"gini\",\n","                max_depth=None,\n","                min_samples_split=2,\n","                min_samples_leaf=1,\n","                min_weight_fraction_leaf=0.,\n","                max_leaf_nodes=None,\n","                min_impurity_decrease=0.,\n","                min_impurity_split=None,\n","                bootstrap=False,\n","                oob_score=False,\n","                n_jobs=None,\n","                random_state=None,\n","                verbose=0,\n","                warm_start=False,\n","                class_weight=None):\n","      self.n_estimators = n_estimators\n","      self.criterion = criterion\n","      self.max_depth = max_depth\n","      self.min_samples_split = min_samples_split\n","      self.min_samples_leaf = min_samples_leaf\n","      self.min_weight_fraction_leaf = min_weight_fraction_leaf\n","      self.max_leaf_nodes = max_leaf_nodes\n","      self.min_impurity_decrease = min_impurity_decrease\n","      self.min_impurity_split = min_impurity_split\n","      self.bootstrap = bootstrap\n","      self.oob_score = oob_score\n","      self.n_jobs = n_jobs\n","      self.random_state = random_state\n","      self.verbose = verbose\n","      self.warm_start = warm_start\n","      self.class_weight = class_weight\n","\n","      self.tree = []\n","      self.all_distribution = None\n","      self.num_tree = n_estimators\n","      self.classes_ = []\n","      self.n_classes_ = []\n","      self.n_outputs_ = None\n","\n","  def fit(self, feature_arrange, boot_x, boot_y, all_y):\n","      \"\"\"Build a forest of trees using a given feature distribution set and bootstrap sample set\n","      Parameters\n","      ----------\n","      feature_arrange : feature distribution sets for each tree\n","          e.g., f1,f2,f3 for 2 trees\n","          [[f1,f2],[f2,f3]]\n","      boot_x : bootstrap sets of input samples\n","          e.g., X1,X2 for 2 trees, [[[1,2],[2,3]],[[1,2],[2,3]]]\n","          X1,X2 array-like or sparse matrix of shape = [n_samples, n_features]\n","      boot_y : bootstrap sets of output labels\n","          e.g., y1,y2 for 2 trees, [[1,0],[1,0]]\n","          y1 array-like, shape = [n_samples]\n","          The target values (class labels in classification, real numbers in\n","          regression).\n","      all_y: original set of labels\n","      \"\"\"\n","\n","      self.all_distribution = feature_arrange\n","\n","\n","      # random_state follows generator and seed\n","      generator = check_random_state(self.random_state)\n","\n","      # loop all the trees\n","      for i in range(self.n_estimators):\n","          # get the feature distribution of this tree\n","          current_distribution = list(feature_arrange[i])\n","\n","          # need to sort the distribution before use\n","          current_distribution.sort()\n","\n","          # get the all-feature trainset from all boot sets\n","          all_train_x = boot_x[i]\n","\n","          train_y = boot_y[i]\n","\n","          # make a train set using the features\n","          train_x = all_train_x[:, current_distribution]\n","\n","          # train the tree\n","          # get a random number(will not have effects buy is needed)\n","          current_random_state = generator.randint(0, 0x7FFFFFFF)\n","\n","          # make parameters correct\n","          # max_features is all (If None, then max_features=n_features)\n","\n","          clf = DecisionTreeClassifier(criterion=self.criterion,\n","                                        splitter='best',\n","                                        max_depth=self.max_depth,\n","                                        min_samples_split=self.min_samples_split,\n","                                        min_samples_leaf=self.min_samples_leaf,\n","                                        min_weight_fraction_leaf=self.min_weight_fraction_leaf,\n","                                        max_features=None,\n","                                        random_state=current_random_state,\n","                                        max_leaf_nodes=self.max_leaf_nodes,\n","                                        min_impurity_decrease=self.min_impurity_decrease,\n","                                        min_impurity_split=self.min_impurity_split,\n","                                        class_weight=self.class_weight,\n","                                        presort=False)\n","          clf.fit(train_x, train_y, sample_weight=None, check_input=False)\n","          self.tree.append(clf)\n","\n","      # save all classes\n","      y = np.atleast_1d(all_y)\n","\n","      if y.ndim == 1:\n","          # reshape is necessary to preserve the data contiguity against vs\n","          # [:, np.newaxis] that does not.\n","          y = np.reshape(y, (-1, 1))\n","      y = np.copy(y)\n","\n","      self.classes_ = []\n","      self.n_classes_ = []\n","\n","      self.n_outputs_ = y.shape[1]\n","\n","      y_encoded = np.zeros(y.shape, dtype=np.int)\n","      for k in range(self.n_outputs_):\n","          classes_k, y_encoded[:, k] = np.unique(y[:, k],\n","                                                  return_inverse=True)\n","          self.classes_.append(classes_k)\n","          self.n_classes_.append(classes_k.shape[0])\n","\n","      self.n_classes_ = np.array(self.n_classes_, dtype=np.intp)\n","      if self.n_outputs_ == 1:\n","          self.n_classes_ = self.n_classes_[0]\n","          self.classes_ = self.classes_[0]\n","\n","\n","  def predict(self, X):\n","      \"\"\"Predict class for X.\n","      The predicted class of an input sample is a vote by the trees in\n","      the forest, weighted by their probability estimates. That is,\n","      the predicted class is the one with highest mean probability\n","      estimate across the trees.\n","      Parameters\n","      ----------\n","      X : array-like or sparse matrix of shape = [n_samples, n_features]\n","          The input samples. Internally, its dtype will be converted to\n","          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n","          converted into a sparse ``csr_matrix``.\n","      Returns\n","      -------\n","      y : array of shape = [n_samples] or [n_samples, n_outputs]\n","          The predicted classes.\n","      \"\"\"\n","      proba = self.predict_proba(X)\n","      n_samples = X.shape[0]\n","\n","      if self.n_outputs_ == 1:\n","          return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n","\n","      else:\n","          predictions = np.zeros((n_samples, self.n_outputs_))\n","\n","          for k in range(self.n_outputs_):\n","              predictions[:, k] = self.classes_[k].take(\n","                  np.argmax(proba[:, k], axis=1),\n","                  axis=0)\n","\n","          return predictions\n","\n","  def predict_proba(self, X):\n","      \"\"\"Predict class probabilities for X.\n","      The predicted class probabilities of an input sample are computed as\n","      the mean predicted class probabilities of the trees in the forest. The\n","      class probability of a single tree is the fraction of samples of the same\n","      class in a leaf.\n","      Parameters\n","      ----------\n","      X : array-like or sparse matrix of shape = [n_samples, n_features]\n","          The input samples. Internally, its dtype will be converted to\n","          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n","          converted into a sparse ``csr_matrix``.\n","      Returns\n","      -------\n","      p : array of shape = [n_samples, n_classes], or a list of n_outputs\n","          such arrays if n_outputs > 1.\n","          The class probabilities of the input samples. The order of the\n","          classes corresponds to that in the attribute `classes_`.\n","      \"\"\"\n","\n","      # get the feature distribution of this tree\n","      current_distribution = list(self.all_distribution[0])\n","\n","      # need to sort the distribution before use\n","      current_distribution.sort()\n","\n","      col_x0 = X[:, current_distribution]\n","      proba_x0 = self.tree[0].predict_proba(col_x0)\n","\n","      proba_array = proba_x0 - proba_x0\n","\n","      # for each tree, get proba using correct subsets of samples\n","      for i in range(self.num_tree):\n","          # get the feature distribution of this tree\n","          current_distribution = list(self.all_distribution[i])\n","\n","          # need to sort the distribution before use\n","          current_distribution.sort()\n","\n","          col_x_this = X[:, current_distribution]\n","          proba_x_this = self.tree[i].predict_proba(col_x_this)\n","          # if proba_x_this.shape == proba_array.shape:   \n","          # print(proba_x_this.shape)\n","          # print(proba_array.shape)       \n","          proba_array += proba_x_this\n","          # else: \n","            # proba_x_this.reshape(proba_array)\n","            # proba_array += proba_x_this\n","\n","      proba_array /= self.num_tree\n","\n","      return proba_array\n","\n","\n","class ControlledForestRegressor:\n","  # controlled forests for regression\n","  # it has a bunch of DecisionTreeRegressor in self.tree\n","  # initialization function\n","  def __init__(self,\n","                n_estimators='warn',\n","                criterion=\"mse\",\n","                max_depth=None,\n","                min_samples_split=2,\n","                min_samples_leaf=1,\n","                min_weight_fraction_leaf=0.,\n","                max_leaf_nodes=None,\n","                min_impurity_decrease=0.,\n","                min_impurity_split=None,\n","                bootstrap=False,\n","                oob_score=False,\n","                n_jobs=None,\n","                random_state=None,\n","                verbose=0,\n","                warm_start=False):\n","      self.n_estimators = n_estimators\n","      self.criterion = criterion\n","      self.max_depth = max_depth\n","      self.min_samples_split = min_samples_split\n","      self.min_samples_leaf = min_samples_leaf\n","      self.min_weight_fraction_leaf = min_weight_fraction_leaf\n","      self.max_leaf_nodes = max_leaf_nodes\n","      self.min_impurity_decrease = min_impurity_decrease\n","      self.min_impurity_split = min_impurity_split\n","      self.bootstrap = bootstrap\n","      self.oob_score = oob_score\n","      self.n_jobs = n_jobs\n","      self.random_state = random_state\n","      self.verbose = verbose\n","      self.warm_start = warm_start\n","\n","      self.tree = []\n","      self.all_distribution = None\n","      self.num_tree = n_estimators\n","      self.n_outputs_ = None\n","\n","\n","  def fit(self,feature_arrange,boot_x,boot_y,all_y):\n","      \"\"\"Build a forest of trees using a given feature distribution set and bootstrap sample set\n","      Parameters\n","      ----------\n","      feature_arrange : feature distribution sets for each tree\n","          e.g., f1,f2,f3 for 2 trees\n","          [[f1,f2],[f2,f3]]\n","      boot_x : bootstrap sets of input samples\n","          e.g., X1,X2 for 2 trees, [[[1,2],[2,3]],[[1,2],[2,3]]]\n","          X1,X2 array-like or sparse matrix of shape = [n_samples, n_features]\n","      boot_y : bootstrap sets of output labels\n","          e.g., y1,y2 for 2 trees, [[1,0],[1,0]]\n","          y1 array-like, shape = [n_samples]\n","          The target values (class labels in classification, real numbers in\n","          regression).\n","      all_y: original set of labels\n","      \"\"\"\n","\n","      self.all_distribution = feature_arrange\n","\n","      # random_state follows generator and seed\n","      generator = check_random_state(self.random_state)\n","\n","      # loop all the trees\n","      for i in range(self.n_estimators):\n","          # get the feature distribution of this tree\n","          current_distribution = list(feature_arrange[i])\n","\n","          # need to sort the distribution before use\n","          current_distribution.sort()\n","\n","          # get the all-feature trainset from all boot sets\n","          all_train_x = boot_x[i]\n","\n","          train_y = boot_y[i]\n","\n","          # make a train set using the features\n","          train_x = all_train_x[:, current_distribution]\n","\n","          # train the tree\n","          # get a random number(will not have effects buy is needed)\n","          current_random_state = generator.randint(0, 0x7FFFFFFF)\n","\n","          # make parameters correct\n","          # max_features is all (If None, then max_features=n_features)\n","\n","          reg = DecisionTreeRegressor(criterion=self.criterion,\n","                                      splitter='best',\n","                                      max_depth=self.max_depth,\n","                                      min_samples_split=self.min_samples_split,\n","                                      min_samples_leaf=self.min_samples_leaf,\n","                                      min_weight_fraction_leaf=self.min_weight_fraction_leaf,\n","                                      max_features=None,\n","                                      random_state=current_random_state,\n","                                      max_leaf_nodes=self.max_leaf_nodes,\n","                                      min_impurity_decrease=self.min_impurity_decrease,\n","                                      min_impurity_split=self.min_impurity_split,\n","                                      presort=False)\n","          reg.fit(train_x, train_y, sample_weight=None, check_input=False)\n","\n","          self.tree.append(reg)\n","\n","      y = np.atleast_1d(all_y)\n","\n","      if y.ndim == 1:\n","          # reshape is necessary to preserve the data contiguity against vs\n","          # [:, np.newaxis] that does not.\n","          y = np.reshape(y, (-1, 1))\n","\n","      self.n_outputs_ = y.shape[1]\n","\n","  def predict(self, X):\n","      \"\"\"Predict regression target for X.\n","      The predicted regression target of an input sample is computed as the\n","      mean predicted regression targets of the trees in the forest.\n","      Parameters\n","      ----------\n","      X : array-like or sparse matrix of shape = [n_samples, n_features]\n","          The input samples. Internally, its dtype will be converted to\n","          ``dtype=np.float32``. If a sparse matrix is provided, it will be\n","          converted into a sparse ``csr_matrix``.\n","      Returns\n","      -------\n","      y : array of shape = [n_samples] or [n_samples, n_outputs]\n","          The predicted values.\n","      \"\"\"\n","      # avoid storing the output of every estimator by summing them here\n","      if self.n_outputs_ > 1:\n","          y_hat = np.zeros((X.shape[0], self.n_outputs_), dtype=np.float64)\n","      else:\n","          y_hat = np.zeros((X.shape[0]), dtype=np.float64)\n","\n","      # count sum\n","      # for each tree\n","      for i in range(self.num_tree):\n","          col_x_this = X[:, self.all_distribution[i]]\n","          y_this = self.tree[i].predict(col_x_this)\n","          y_hat += y_this\n","\n","      y_hat /= self.num_tree\n","\n","      return y_hat"],"execution_count":51,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4pQpAMaVm5A2","colab_type":"text"},"source":["##Arranged Forest Example"]},{"cell_type":"code","metadata":{"id":"CfSNby6ym-Vw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"error","timestamp":1597606851741,"user_tz":-180,"elapsed":629,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"9b9b0f1b-ecc5-44de-82bc-53ec8f602480"},"source":["def example():\n","    # build arranged forests using ControlledForestClassifier with k-family and bootstrap\n","\n","    # the dataset is from The UCI Machine Learning Repository\n","    # https://archive.ics.uci.edu/ml/datasets/Parkinson%27s+Disease+Classification\n","\n","    # load data into numpy\n","\n","    all_set = np.genfromtxt('/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/pd_speech_features/pd_speech_features.csv', delimiter=',', skip_header=2)\n","\n","    # all set includes train and test set\n","\n","    print(all_set)\n","\n","    row_all = len(all_set)\n","\n","    print(\"row_all = \", row_all)\n","\n","    column_all = np.size(all_set, 1)\n","\n","    print(\"column_all = \", column_all)\n","\n","    # delete the ID\n","\n","    all_set = np.delete(all_set, 0, 1)\n","\n","    column_all = np.size(all_set, 1)\n","\n","    print(\"column_all = \", column_all)\n","\n","    # use only 529 features\n","    columns_to_remove = range(529, 753)\n","\n","    all_set = np.delete(all_set, columns_to_remove, 1)\n","\n","    column_all = np.size(all_set, 1)\n","\n","    print(\"column_all = \", column_all)\n","\n","    # get first 528 rows (70%) as train set\n","    # the rest as test set\n","\n","    train = all_set[0:528]\n","    test = all_set[528:]\n","\n","    print(train)\n","\n","    row_train = len(train)\n","    print(\"row_train = \", row_train)\n","\n","    row_test = len(test)\n","\n","    print(\"row_test = \", row_test)\n","\n","    # get input and labels\n","\n","    train_x = train[:, 0:-1]\n","    train_y = train[:, -1]\n","\n","    test_x = test[:, 0:-1]\n","    test_y = test[:, -1]\n","\n","    boot_train_x, boot_train_y = bootstrap_samples(552, train_x, train_y, seed=1)\n","\n","    feature_matrix = build_feature_matrix(num_feature=529, feature_per_tree=23)\n","\n","    k_family_F = diagonal_distribute(feature_per_tree=23, feature_matrix=feature_matrix)\n","\n","    print(get_repetition_index(k_family_F))\n","\n","    arranged_clf = ControlledForestClassifier(n_estimators=552)\n","    arranged_clf.fit(k_family_F, boot_train_x, boot_train_y, train_y)\n","\n","    predict_y = arranged_clf.predict(test_x)\n","\n","    arranged_report = classification_report(test_y, predict_y, output_dict=False)\n","\n","    print(arranged_report)\n","\n","\n","example()"],"execution_count":41,"outputs":[{"output_type":"stream","text":["[[  0.        1.        0.85247 ...   3.0004   18.9405    1.     ]\n"," [  0.        1.        0.76686 ...   6.3431   45.178     1.     ]\n"," [  0.        1.        0.85083 ...   3.1495    4.7666    1.     ]\n"," ...\n"," [251.        0.        0.88389 ...   3.3545    5.0424    0.     ]\n"," [251.        0.        0.83782 ...   2.8332    3.7131    0.     ]\n"," [251.        0.        0.81304 ...   2.6217    3.1527    0.     ]]\n","row_all =  756\n","column_all =  755\n","column_all =  754\n","column_all =  530\n","[[ 1.0000e+00  8.5247e-01  7.1826e-01 ... -1.3372e-02  5.6236e-02\n","   1.0000e+00]\n"," [ 1.0000e+00  7.6686e-01  6.9481e-01 ... -9.8891e-03  4.5866e-03\n","   1.0000e+00]\n"," [ 1.0000e+00  8.5083e-01  6.7604e-01 ...  4.3489e-03 -4.8027e-03\n","   1.0000e+00]\n"," ...\n"," [ 0.0000e+00  8.4122e-01  5.6511e-01 ...  1.0616e-04 -1.7337e-04\n","   1.0000e+00]\n"," [ 0.0000e+00  8.5899e-01  6.0622e-01 ... -7.1546e-04  1.4731e-04\n","   1.0000e+00]\n"," [ 0.0000e+00  8.4824e-01  5.5586e-01 ... -2.3316e-04  2.4076e-04\n","   1.0000e+00]]\n","row_train =  528\n","row_test =  228\n","using bootstrap_samples\n","using build_feature_matrix\n","using diagonal_distribute\n","using get_repetition_index\n","146004\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-bf592d23ac40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m \u001b[0mexample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-41-bf592d23ac40>\u001b[0m in \u001b[0;36mexample\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0marranged_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mControlledForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m552\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0marranged_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_family_F\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboot_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboot_train_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mpredict_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marranged_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-40-29351635f62d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, feature_arrange, boot_x, boot_y, all_y)\u001b[0m\n\u001b[1;32m    104\u001b[0m                                         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                                         presort=False)\n\u001b[0;32m--> 106\u001b[0;31m           \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"VnWweQQzIxVz","colab_type":"text"},"source":["#Load Paths"]},{"cell_type":"markdown","metadata":{"id":"o8dHBUbHV4kY","colab_type":"text"},"source":["Create a Data-Sets Dictionary called 'data_dic'\n","> data_dic **keys** are the names of the data sets\n","\n","> data_dic **values** are the data sets\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"6yxuhHGKitBn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1597590627741,"user_tz":-180,"elapsed":26663,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"3307c8f5-3786-4cd4-87ae-3105c00a449b"},"source":["i=0\n","data_dic = {}\n","for dir_path, dir_name ,dir_files in os.walk(labeled_data_path):\n","  for file_name in dir_files:\n","    file_path = dir_path + \"/\" + file_name\n","    data = pd.read_csv(file_path)\n","    data_dic[file_name] = data\n","    print(file_path)\n","    print(data)\n","    # if i==1:\n","    #   break\n","    # i+=1\n","    \n","      \n","   \n","\n","\n"],"execution_count":52,"outputs":[{"output_type":"stream","text":["/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/analcatdata_lawsuit.csv\n","     Unnamed: 0  Length.of.service  CAP  PA.normalized  Minority  Laid.off\n","0             0               3.17    7           3.33         1         1\n","1             1               4.47    8           3.33         1         1\n","2             2               0.69   11           4.44         1         1\n","3             3               1.52   16           1.11         1         1\n","4             4               7.43    6          13.32         1         1\n","..          ...                ...  ...            ...       ...       ...\n","259         259              10.57   60          30.00         0         0\n","260         260              14.62   60          28.89         0         0\n","261         261              26.01   59          26.67         0         0\n","262         262              15.38   60          30.00         0         0\n","263         263              21.20   59          30.00         0         0\n","\n","[264 rows x 6 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/baseball.csv\n","      Unnamed: 0  Number_seasons  ...  Position  Hall_of_Fame\n","0              0              23  ...  0.174107             1\n","1              1              13  ...  0.126866             0\n","2              2              13  ...  0.171642             0\n","3              3              14  ...  0.070866             0\n","4              4              17  ...  0.224000             0\n","...          ...             ...  ...       ...           ...\n","1335        1335              11  ...  0.164045             0\n","1336        1336              19  ...  0.065502             0\n","1337        1337              12  ...  0.088710             0\n","1338        1338              13  ...  0.090226             0\n","1339        1339              13  ...  0.182232             0\n","\n","[1340 rows x 18 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/bodyfat.csv\n","     Unnamed: 0  Density  Age  Weight  ...  Biceps  Forearm  Wrist  binaryClass\n","0             0   1.0708   23  154.25  ...    32.0     27.4   17.1            1\n","1             1   1.0853   22  173.25  ...    30.5     28.9   18.2            1\n","2             2   1.0414   22  154.00  ...    28.8     25.2   16.6            0\n","3             3   1.0751   26  184.75  ...    32.4     29.4   18.2            1\n","4             4   1.0340   24  184.25  ...    32.2     27.7   17.7            0\n","..          ...      ...  ...     ...  ...     ...      ...    ...          ...\n","247         247   1.0736   70  134.25  ...    25.6     25.7   18.5            1\n","248         248   1.0236   72  201.00  ...    35.2     28.6   20.1            0\n","249         249   1.0328   72  186.75  ...    31.3     27.2   18.0            0\n","250         250   1.0399   72  190.75  ...    30.5     29.4   19.8            0\n","251         251   1.0271   74  207.50  ...    33.7     30.0   20.9            0\n","\n","[252 rows x 16 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/analcatdata_asbestos.csv\n","    Unnamed: 0  Ventilation  Duration  Exposure  Task\n","0            0     0.608696       184  0.717949     1\n","1            1     0.622222        30  0.107143     0\n","2            2     0.659091       116  0.037037     0\n","3            3     0.651163       133  0.725000     1\n","4            4     0.200000       184  0.107143     0\n","..         ...          ...       ...       ...   ...\n","78          78     0.613636       260  0.682927     1\n","79          79     0.172414       184  0.717949     0\n","80          80     0.156250        60  0.068966     1\n","81          81     0.200000        79  0.499638     0\n","82          82     0.622222       247  0.690476     1\n","\n","[83 rows x 5 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/analcatdata_broadwaymult.csv\n","     Unnamed: 0      Show      Type  ...  Week_1_attendance     Award  Count\n","0             0  2.002473  2.000000  ...              87.13  4.309524      2\n","1             1  2.839890  1.952381  ...              87.13  1.313953      0\n","2             2  1.160110  1.953020  ...              87.13  0.390244      4\n","3             3  1.996109  2.027211  ...             100.00  4.282353      6\n","4             4  1.996109  2.027211  ...             100.00  1.310345      0\n","..          ...       ...       ...  ...                ...       ...    ...\n","280         280  1.999382  2.137931  ...              54.05  1.269231      2\n","281         281  2.000000  2.000000  ...              54.05  0.441860      2\n","282         282  1.579435  1.933333  ...              99.15  4.220930      3\n","283         283  1.579435  2.022222  ...              99.15  1.258824      3\n","284         284  2.839890  2.000000  ...              99.15  0.465909      0\n","\n","[285 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/fri_c0_250_5.csv\n","     Unnamed: 0       oz1       oz2       oz3       oz4       oz5  binaryClass\n","0             0 -0.884043  0.751601  0.756124 -1.521581  0.203984            1\n","1             1 -1.516162 -0.778852 -0.935525  0.361520 -1.306545            1\n","2             2  1.276350  0.022499 -0.374163  1.502670 -0.609227            0\n","3             3  1.282011  1.030213 -0.326553 -1.538950  0.474845            1\n","4             4 -0.619048  1.560539  1.435116 -0.297633 -0.120658            0\n","..          ...       ...       ...       ...       ...       ...          ...\n","245         245 -0.502347  1.120583 -0.212220 -0.750066 -0.441486            1\n","246         246 -0.940008  0.279920  1.613556  0.631651 -0.395655            0\n","247         247 -0.368071 -0.593283 -1.434136 -0.569653  0.861619            0\n","248         248 -1.700857  0.135705 -0.857281  1.592884 -0.724478            1\n","249         249 -0.205241 -0.971258  1.566781  0.065888 -0.262271            0\n","\n","[250 rows x 7 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/diabetes.csv\n","     Unnamed: 0  preg  plas  pres  skin  insu  mass   pedi  age  class\n","0             0     6   148    72    35     0  33.6  0.627   50      1\n","1             1     1    85    66    29     0  26.6  0.351   31      0\n","2             2     8   183    64     0     0  23.3  0.672   32      1\n","3             3     1    89    66    23    94  28.1  0.167   21      0\n","4             4     0   137    40    35   168  43.1  2.288   33      1\n","..          ...   ...   ...   ...   ...   ...   ...    ...  ...    ...\n","763         763    10   101    76    48   180  32.9  0.171   63      0\n","764         764     2   122    70    27     0  36.8  0.340   27      0\n","765         765     5   121    72    23   112  26.2  0.245   30      0\n","766         766     1   126    60     0     0  30.1  0.349   47      1\n","767         767     1    93    70    31     0  30.4  0.315   23      0\n","\n","[768 rows x 10 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/cloud.csv\n","     Unnamed: 0    SEEDED    TE    TW    NC    SC   NWC  binaryClass\n","0             0  0.306122  1.69  3.73  1.65  1.80  3.33            0\n","1             1  0.295455  0.74  0.78  1.09  0.79  1.59            0\n","2             2  0.276596  0.81  0.86  2.39  0.36  2.06            0\n","3             3  0.291667  1.44  2.01  2.96  1.27  4.05            0\n","4             4  0.291667  2.48  4.61  4.16  2.16  6.00            0\n","..          ...       ...   ...   ...   ...   ...   ...          ...\n","103         103  0.295455  1.36  3.43  1.38  1.86  2.91            1\n","104         104  0.291667  1.17  1.65  1.22  2.28  1.58            1\n","105         105  0.295455  2.37  1.94  2.46  2.47  2.39            1\n","106         106  0.291667  0.02  0.08  0.05  0.02  0.09            1\n","107         107  0.265306  0.92  2.09  0.61  0.87  1.35            1\n","\n","[108 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/lowbwt.csv\n","     Unnamed: 0  LOW  AGE  LWT  RACE  SMOKE  PTL  HT  UI  FTV  binaryClass\n","0             0    0   19  182     2      0    0   0   1    0            1\n","1             1    0   33  155     3      0    0   0   0    3            1\n","2             2    0   20  105     1      1    0   0   0    1            1\n","3             3    0   21  108     1      1    0   0   1    2            1\n","4             4    0   18  107     1      1    0   0   1    0            1\n","..          ...  ...  ...  ...   ...    ...  ...  ..  ..  ...          ...\n","184         184    1   28   95     1      1    0   0   0    2            1\n","185         185    1   14  100     3      0    0   0   0    2            1\n","186         186    1   23   94     3      1    0   0   0    0            1\n","187         187    1   17  142     2      0    0   1   0    0            1\n","188         188    1   21  130     1      1    0   1   0    3            1\n","\n","[189 rows x 11 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/diggle_table_a2.csv\n","     Unnamed: 0  col_1  col_2  col_3  ...   col_6   col_7   col_8  binaryClass\n","0             0     76     33     33  ...  1.1718  5.5683  5.7268            1\n","1             1     76     34     34  ...  1.1815  5.5568  5.7236            1\n","2             2     76     35     35  ...  1.1907  5.5491  5.7236            1\n","3             3     76     36     36  ...  1.1679  5.5683  5.7236            1\n","4             4     76     37     37  ...  1.1591  5.5759  5.7236            1\n","..          ...    ...    ...    ...  ...     ...     ...     ...          ...\n","305         305     84     20    436  ...  1.5879  6.2046  6.6670            0\n","306         306     84     21    437  ...  1.5879  6.2046  6.6670            0\n","307         307     84     22    438  ...  1.5815  6.2086  6.6670            0\n","308         308     84     25    441  ...  1.5847  6.2066  6.6670            0\n","309         309     84     26    442  ...  1.5752  6.2126  6.6670            0\n","\n","[310 rows x 10 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/chatfield_4.csv\n","     Unnamed: 0  col_1  col_2  col_3  ...  col_10  col_11  col_12  binaryClass\n","0             0   1749   58.0   62.6  ...    75.9    75.5   158.6            0\n","1             1   1750   73.3   75.9  ...    91.2    65.7    63.3            0\n","2             2   1751   70.0   43.5  ...    23.5    23.2    28.5            1\n","3             3   1752   35.0   50.0  ...    27.1    46.6    37.6            1\n","4             4   1753   44.0   32.0  ...    28.0    25.0    20.0            1\n","..          ...    ...    ...    ...  ...     ...     ...     ...          ...\n","230         230   1979  166.6  137.5  ...   188.4   186.2   183.3            0\n","231         231   1980  159.6  155.0  ...   155.0   164.7   147.9            0\n","232         232   1981  114.0  141.3  ...   167.3   162.4   137.5            0\n","233         233   1982  111.2  163.6  ...   118.8    94.7    98.1            0\n","234         234   1983   84.3   51.0  ...    50.3    55.8    33.3            1\n","\n","[235 rows x 14 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/no2.csv\n","     Unnamed: 0  no2_concentration  ...  hour_of_day  binaryClass\n","0             0            3.71844  ...           20            0\n","1             1            3.10009  ...           14            1\n","2             2            3.31419  ...            4            0\n","3             3            4.38826  ...           23            1\n","4             4            4.34640  ...           11            1\n","..          ...                ...  ...          ...          ...\n","495         495            4.30946  ...           11            1\n","496         496            2.94444  ...           10            1\n","497         497            4.17439  ...           14            1\n","498         498            2.95491  ...            7            0\n","499         499            4.03247  ...           17            1\n","\n","[500 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/disclosure_z.csv\n","     Unnamed: 0       Age      Civil     Can/US  binaryClass\n","0             0  31.00364  23.266880   7.230798            0\n","1             1  58.36153  17.760060   4.480846            1\n","2             2  49.43488  14.583990   7.632419            0\n","3             3  40.87560  16.545360   9.448964            0\n","4             4  30.38650  14.092690  10.828120            0\n","..          ...       ...        ...        ...          ...\n","657         657  71.77202  19.986267   5.172107            0\n","658         658  63.04903  12.468170   6.701814            0\n","659         659  36.01423  10.861040   9.542739            1\n","660         660  51.99702  22.303720   8.912320            0\n","661         661  59.85363  25.385640   8.548289            0\n","\n","[662 rows x 5 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/kidney.csv\n","    Unnamed: 0  patient  time  status  age       sex  disease_type  binaryClass\n","0            0        1     8       1   28  0.352941      0.545455            0\n","1            1        1    16       1   28  0.437500      0.571429            0\n","2            2        2    23       1   48  0.568627      0.625000            0\n","3            3        2    13       0   48  0.560000      0.588235            0\n","4            4        3    22       1   32  0.444444      0.560000            0\n","..         ...      ...   ...     ...  ...       ...           ...          ...\n","71          71       36    16       0   42  0.580000      0.500000            1\n","72          72       37     6       0   52  0.571429      0.333380            0\n","73          73       37    78       1   52  0.591837      0.285725            0\n","74          74       38    63       1   60  0.437500      0.285725            0\n","75          75       38     8       0   60  0.388889      0.285725            0\n","\n","[76 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/lupus.csv\n","    Unnamed: 0  TIME  DURATION  LOG(1+DURATION)  STATUS\n","0            0   157       1.0             0.69       0\n","1            1   268      10.0             2.40       0\n","2            2   209       2.0             1.10       1\n","3            3   134       0.1             0.10       0\n","4            4    21       0.1             0.10       1\n","..         ...   ...       ...              ...     ...\n","82          82     4      34.0             3.56       1\n","83          83    65       0.1             0.10       1\n","84          84    62       8.0             2.20       1\n","85          85    89       0.1             0.10       0\n","86          86    44      77.0             4.36       1\n","\n","[87 rows x 5 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/kc3.csv\n","     Unnamed: 0  LOC_BLANK  BRANCH_COUNT  ...  PERCENT_COMMENTS  LOC_TOTAL  c\n","0             0          0             1  ...              0.00          3  0\n","1             1          1             5  ...              0.00         11  0\n","2             2          0             1  ...              0.00          3  0\n","3             3          0             1  ...              0.00          3  0\n","4             4          5            18  ...              3.33         58  0\n","..          ...        ...           ...  ...               ...        ... ..\n","453         453          1             8  ...              0.00         24  0\n","454         454          2             1  ...              8.33         11  0\n","455         455          7            12  ...              2.78         36  0\n","456         456          1             1  ...              0.00          4  0\n","457         457         22            43  ...              9.86        131  0\n","\n","[458 rows x 41 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/pm10.csv\n","     Unnamed: 0  pm10_concentration  ...  hour_of_day  binaryClass\n","0             0             3.66356  ...           19            1\n","1             1             3.04452  ...            9            0\n","2             2             3.71357  ...            3            1\n","3             3             2.94444  ...           22            1\n","4             4             4.06044  ...            7            1\n","..          ...                 ...  ...          ...          ...\n","495         495             2.30259  ...            1            0\n","496         496             4.11087  ...           10            1\n","497         497             3.40120  ...           24            1\n","498         498             3.68888  ...           19            1\n","499         499             4.17439  ...           15            0\n","\n","[500 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/meta.csv\n","     Unnamed: 0  DS_Name    T    N  ...    EnAtr  NSRatio  Alg_Name  binaryClass\n","0             0      1.0  690  690  ...  8.77168  19.3646  0.952381            1\n","1             1      1.0  690  690  ...  8.77168  19.3646  0.952381            1\n","2             2      1.0  690  690  ...  8.77168  19.3646  0.904762            1\n","3             3      1.0  690  690  ...  8.77168  19.3646  0.842105            1\n","4             4      1.0  690  690  ...  8.77168  19.3646  1.000000            1\n","..          ...      ...  ...  ...  ...      ...      ...       ...          ...\n","523         523      1.0  846  846  ...  5.64698  11.0045  0.950000            1\n","524         524      1.0  846  846  ...  5.64698  11.0045  1.000000            1\n","525         525      1.0  846  846  ...  5.64698  11.0045  0.944444            1\n","526         526      1.0  846  846  ...  5.64698  11.0045  1.000000            1\n","527         527      1.0  846  846  ...  5.64698  11.0045  1.000000            1\n","\n","[528 rows x 23 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/newton_hema.csv\n","     Unnamed: 0        id  weeks  cells_percentage  binaryClass\n","0             0  0.562500   11.0                33            0\n","1             1  0.500000   13.0                49            1\n","2             2  0.500000   19.0                46            1\n","3             3  0.500000   25.0                42            1\n","4             4  0.500000   28.0                68            1\n","..          ...       ...    ...               ...          ...\n","135         135  0.999364  142.0                32            0\n","136         136  0.982777    0.0                58            1\n","137         137  0.982777   15.0                58            1\n","138         138  0.982777   91.0                48            1\n","139         139  0.982777   95.0                51            1\n","\n","[140 rows x 5 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/mfeat-karhunen.csv\n","      Unnamed: 0       att1       att2  ...     att63     att64  class\n","0              0 -10.297008 -11.666789  ... -1.351353 -0.473910      0\n","1              1  -5.036009 -12.885333  ...  0.642451  0.613107      0\n","2              2  -9.639157  -6.655898  ...  0.827182 -1.767840      0\n","3              3  -6.650375  -7.043851  ... -0.771735  0.304992      0\n","4              4 -10.664524 -10.974133  ... -0.943213  1.149847      0\n","...          ...        ...        ...  ...       ...       ...    ...\n","1995        1995  -2.415248  -6.619806  ... -0.068411 -1.049052      9\n","1996        1996   5.892684  -8.185875  ...  0.925637  1.798053      9\n","1997        1997   1.881613  -9.650881  ...  0.287013 -0.420793      9\n","1998        1998  -1.530886 -10.183775  ...  0.435514 -0.225426      9\n","1999        1999  11.251634  -5.959691  ...  0.763971  0.040369      9\n","\n","[2000 rows x 66 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/elusage.csv\n","    Unnamed: 0  average_temperature  month  binaryClass\n","0            0                   73      8            1\n","1            1                   67      9            1\n","2            2                   57     10            1\n","3            3                   43     11            0\n","4            4                   26     12            0\n","5            5                   41      1            0\n","6            6                   38      2            0\n","7            7                   46      3            0\n","8            8                   54      4            0\n","9            9                   60      5            1\n","10          10                   71      6            1\n","11          11                   75      7            1\n","12          12                   74      8            1\n","13          13                   66      9            1\n","14          14                   61     10            1\n","15          15                   49     11            0\n","16          16                   41     12            0\n","17          17                   35      1            0\n","18          18                   41      2            0\n","19          19                   42      3            1\n","20          20                   56      4            1\n","21          21                   69      5            1\n","22          22                   73      6            1\n","23          23                   77      7            1\n","24          24                   74      8            1\n","25          25                   66      9            1\n","26          26                   56     10            1\n","27          27                   47     11            1\n","28          28                   38     12            0\n","29          29                   34      1            0\n","30          30                   37      2            0\n","31          31                   39      3            0\n","32          32                   51      4            0\n","33          33                   60      5            1\n","34          34                   70      6            1\n","35          35                   73      7            1\n","36          36                   71      8            1\n","37          37                   66      9            1\n","38          38                   54     10            0\n","39          39                   45     11            0\n","40          40                   36     12            0\n","41          41                   34      1            0\n","42          42                   32      2            0\n","43          43                   39      3            0\n","44          44                   55      4            1\n","45          45                   64      5            1\n","46          46                   72      6            1\n","47          47                   79      7            1\n","48          48                   75      8            1\n","49          49                   65      9            1\n","50          50                   54     10            1\n","51          51                   48     11            1\n","52          52                   35     12            0\n","53          53                   24      1            0\n","54          54                   32      2            0\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/schizo.csv\n","     Unnamed: 0   ID    target  ...  gain_ratio_11       sex  class\n","0             0    7  0.477778  ...          0.883  0.358974      0\n","1             1    7  0.461111  ...          0.879  0.349593      0\n","2             2    7  0.500000  ...          0.795  0.368000      0\n","3             3    7  0.462963  ...          0.722  0.358974      0\n","4             4    7  0.483516  ...          0.845  0.352459      0\n","..          ...  ...       ...  ...            ...       ...    ...\n","335         335  275  0.438596  ...          0.745  0.559322      1\n","336         336  276  0.480447  ...          0.637  0.559140      1\n","337         337  276  0.470588  ...          0.828  0.559783      1\n","338         338  276  0.477273  ...          0.937  0.552486      1\n","339         339  276  0.448276  ...          0.766  0.552486      1\n","\n","[340 rows x 16 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/squash-unstored.csv\n","    Unnamed: 0      site  ...  heat_input_flower  Acceptability\n","0            0  1.428571  ...                332              2\n","1            1  1.428571  ...                332              1\n","2            2  1.400000  ...                332              2\n","3            3  1.428571  ...                332              1\n","4            4  1.384615  ...                442              2\n","5            5  1.428571  ...                442              2\n","6            6  1.357143  ...                442              2\n","7            7  1.384615  ...                442              1\n","8            8  1.357143  ...                531              2\n","9            9  1.533333  ...                531              0\n","10          10  1.400000  ...                531              2\n","11          11  1.384615  ...                531              2\n","12          12  1.500000  ...                612              2\n","13          13  1.500000  ...                612              0\n","14          14  1.500000  ...                612              2\n","15          15  1.500000  ...                612              0\n","16          16  1.285714  ...                342              1\n","17          17  1.307692  ...                342              1\n","18          18  1.230769  ...                342              1\n","19          19  1.214286  ...                342              1\n","20          20  1.266667  ...                393              1\n","21          21  1.266667  ...                393              1\n","22          22  1.266667  ...                393              1\n","23          23  1.230769  ...                393              1\n","24          24  1.307692  ...                446              2\n","25          25  1.307692  ...                446              0\n","26          26  1.230769  ...                446              2\n","27          27  1.153846  ...                446              1\n","28          28  1.214286  ...                508              2\n","29          29  1.285714  ...                508              1\n","30          30  1.153846  ...                508              2\n","31          31  1.153846  ...                508              2\n","32          32  1.437500  ...                260              2\n","33          33  1.437500  ...                260              1\n","34          34  1.500000  ...                260              2\n","35          35  1.444444  ...                260              2\n","36          36  1.473684  ...                310              1\n","37          37  1.470588  ...                310              1\n","38          38  1.444444  ...                310              1\n","39          39  1.500000  ...                310              1\n","40          40  1.500000  ...                366              1\n","41          41  1.473684  ...                366              1\n","42          42  1.500000  ...                366              1\n","43          43  1.437500  ...                366              2\n","44          44  1.388889  ...                379              2\n","45          45  1.437500  ...                379              1\n","46          46  1.421053  ...                379              2\n","47          47  1.444444  ...                379              1\n","48          48  1.470588  ...                438              1\n","49          49  1.470588  ...                438              2\n","50          50  1.444444  ...                438              2\n","51          51  1.388889  ...                438              2\n","\n","[52 rows x 25 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/plasma_retinol.csv\n","     Unnamed: 0  AGE       SEX  ...  RETDIET  BETAPLASMA  binaryClass\n","0             0   64  0.601660  ...      890         200            0\n","1             1   76  0.607287  ...      451         124            0\n","2             2   38  0.605691  ...      660         328            0\n","3             3   40  0.601660  ...      864         153            0\n","4             4   72  0.595918  ...     1209          92            0\n","..          ...  ...       ...  ...      ...         ...          ...\n","310         310   46  0.601626  ...     1261         164            1\n","311         311   45  0.607287  ...      465          80            1\n","312         312   49  0.600806  ...      520         300            1\n","313         313   31  0.600806  ...      644         121            0\n","314         314   45  0.595918  ...      554         233            0\n","\n","[315 rows x 15 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/rmftsa_sleepdata.csv\n","      Unnamed: 0  heart_rate  sleep_state  binaryClass\n","0              0         152            4            0\n","1              1         156            4            0\n","2              2         147            4            0\n","3              3         145            4            0\n","4              4         129            4            0\n","...          ...         ...          ...          ...\n","1019        1019         180            4            0\n","1020        1020         174            4            0\n","1021        1021         153            4            0\n","1022        1022         175            4            0\n","1023        1023         161            4            0\n","\n","[1024 rows x 4 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/mfeat-morphological.csv\n","      Unnamed: 0  att1  att2  ...      att5         att6  binaryClass\n","0              0     1     0  ...  1.311693  1620.221779            1\n","1              1     1     0  ...  1.302745  1609.334822            1\n","2              2     1     0  ...  1.319031  1568.978435            1\n","3              3     1     0  ...  1.270878  1695.055281            1\n","4              4     1     0  ...  1.329637  1647.720235            1\n","...          ...   ...   ...  ...       ...          ...          ...\n","1995        1995     1     1  ...  1.655794  5326.025889            0\n","1996        1996     1     1  ...  1.620345  5243.267754            0\n","1997        1997     1     1  ...  1.541987  3766.763222            0\n","1998        1998     1     1  ...  1.426381  4118.327320            0\n","1999        1999     1     1  ...  1.564621  3808.021317            0\n","\n","[2000 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/prnn_synth.csv\n","     Unnamed: 0        xs        ys  yc\n","0             0  0.051008  0.160862   0\n","1             1 -0.748074  0.089040   0\n","2             2 -0.772934  0.263172   0\n","3             3  0.218374  0.127061   0\n","4             4  0.372683  0.496562   0\n","..          ...       ...       ...  ..\n","245         245  0.268878  0.445592   1\n","246         246 -0.492549  1.014434   1\n","247         247  0.076160  0.637952   1\n","248         248  0.492262  0.468762   1\n","249         249 -0.402496  0.713011   1\n","\n","[250 rows x 4 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/solar-flare.csv\n","      Unnamed: 0  ...  X-class_flares_production_by_this_region\n","0              0  ...                                         0\n","1              1  ...                                         0\n","2              2  ...                                         0\n","3              3  ...                                         0\n","4              4  ...                                         0\n","...          ...  ...                                       ...\n","1061        1061  ...                                         0\n","1062        1062  ...                                         0\n","1063        1063  ...                                         0\n","1064        1064  ...                                         0\n","1065        1065  ...                                         0\n","\n","[1066 rows x 13 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/socmob.csv\n","      Unnamed: 0  ...  binaryClass\n","0              0  ...            0\n","1              1  ...            0\n","2              2  ...            0\n","3              3  ...            1\n","4              4  ...            1\n","...          ...  ...          ...\n","1151        1151  ...            1\n","1152        1152  ...            1\n","1153        1153  ...            1\n","1154        1154  ...            1\n","1155        1155  ...            1\n","\n","[1156 rows x 7 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/squash-stored.csv\n","    Unnamed: 0      site  daf  ...  heat_input_emerg  heat_input_flower  binaryClass\n","0            0  0.642857   30  ...               847                458            1\n","1            1  0.642857   30  ...               721                458            1\n","2            2  0.642857   30  ...               847                458            0\n","3            3  0.642857   30  ...               847                458            0\n","4            4  0.642857   40  ...               968                568            0\n","5            5  0.538462   40  ...               968                568            1\n","6            6  0.642857   40  ...               968                568            1\n","7            7  0.642857   40  ...               968                568            0\n","8            8  0.642857   50  ...              1087                531            1\n","9            9  0.642857   50  ...              1087                657            0\n","10          10  0.642857   50  ...              1087                657            0\n","11          11  0.642857   50  ...              1087                657            1\n","12          12  0.538462   60  ...              1023                738            1\n","13          13  0.600000   60  ...              1023                738            1\n","14          14  0.642857   60  ...              1023                738            1\n","15          15  0.538462   60  ...              1023                738            1\n","16          16  0.500000   30  ...               797                468            0\n","17          17  0.571429   30  ...               797                468            0\n","18          18  0.461538   30  ...               797                468            0\n","19          19  0.571429   30  ...               797                468            0\n","20          20  0.500000   40  ...               860                519            0\n","21          21  0.500000   40  ...               860                519            1\n","22          22  0.533333   40  ...               860                519            0\n","23          23  0.466667   40  ...               860                519            1\n","24          24  0.461538   50  ...               923                572            0\n","25          25  0.461538   50  ...               923                572            1\n","26          26  0.461538   50  ...               923                572            1\n","27          27  0.466667   50  ...               923                572            1\n","28          28  0.500000   60  ...              1000                634            1\n","29          29  0.461538   60  ...              1000                634            1\n","30          30  0.461538   60  ...              1000                634            1\n","31          31  0.533333   60  ...              1000                634            0\n","32          32  0.250000   30  ...               798                386            0\n","33          33  0.263158   30  ...               798                386            0\n","34          34  0.263158   30  ...               798                386            0\n","35          35  0.277778   30  ...               798                386            0\n","36          36  0.263158   40  ...               822                436            0\n","37          37  0.277778   40  ...               822                436            0\n","38          38  0.250000   40  ...               822                436            0\n","39          39  0.166667   40  ...               822                436            1\n","40          40  0.250000   50  ...               863                492            0\n","41          41  0.222222   50  ...               863                492            0\n","42          42  0.250000   50  ...               863                492            0\n","43          43  0.250000   50  ...               863                492            0\n","44          44  0.277778   60  ...               900                505            0\n","45          45  0.277778   60  ...               900                505            0\n","46          46  0.250000   60  ...               900                505            0\n","47          47  0.263158   60  ...               900                505            0\n","48          48  0.222222   70  ...               905                564            1\n","49          49  0.250000   70  ...               905                564            1\n","50          50  0.250000   70  ...               905                564            1\n","51          51  0.166667   70  ...               905                564            1\n","\n","[52 rows x 26 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/sleuth_case2002.csv\n","     Unnamed: 0  FM  LC  BK  SS  AG  YR  binaryClass\n","0             0   0   1   1   0  59  39            0\n","1             1   0   0   0   0  61  42            1\n","2             2   0   0   1   0  59  36            1\n","3             3   1   1   1   0  60  38            1\n","4             4   1   0   1   0  60  36            0\n","..          ...  ..  ..  ..  ..  ..  ..          ...\n","142         142   0   0   1   0  52  28            0\n","143         143   0   0   1   1  52  30            0\n","144         144   0   1   0   1  43  19            1\n","145         145   0   0   0   0  43  25            0\n","146         146   0   0   0   1  42  17            1\n","\n","[147 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/schlvote.csv\n","    Unnamed: 0  vote  tax_rate  ...  budget_change  tax_rate_change  binaryClass\n","0            0     1     47.18  ...            4.0             6.30            1\n","1            1     1     21.64  ...            3.3             4.10            1\n","2            2     1     24.05  ...            3.4             2.50            1\n","3            3     1     20.93  ...            9.4             7.50            1\n","4            4     1     19.32  ...           11.1             5.20            1\n","5            5     1     26.20  ...            4.5            -0.23            1\n","6            6     1     20.09  ...            4.7             1.70            1\n","7            7     0     42.16  ...            5.9             4.90            1\n","8            8     1     29.11  ...            3.0             3.50            0\n","9            9     0     45.96  ...            3.8             3.70            1\n","10          10     1     21.56  ...            1.9             3.80            1\n","11          11     1     15.55  ...            6.6             8.10            1\n","12          12     1     23.77  ...            6.0             8.10            1\n","13          13     1     27.64  ...            4.8             7.50            1\n","14          14     0     28.12  ...            8.9             7.70            0\n","15          15     0     36.74  ...            3.6             5.30            1\n","16          16     1     40.48  ...            0.0             1.90            1\n","17          17     1     21.83  ...            5.5             4.00            1\n","18          18     1     20.05  ...            8.3            10.40            1\n","19          19     1     20.86  ...            4.4             4.50            1\n","20          20     1     19.99  ...            2.9             3.50            1\n","21          21     1     11.74  ...            4.3             4.40            0\n","22          22     1     17.71  ...            4.9             3.60            0\n","23          23     1      6.35  ...            1.9             4.60            1\n","24          24     1     41.79  ...            4.2             4.50            1\n","25          25     1     28.25  ...            5.0             6.20            1\n","26          26     0     36.18  ...            4.6             5.90            0\n","27          27     1     80.70  ...            4.8             6.60            1\n","28          28     0     99.56  ...            7.4             8.60            1\n","29          29     0     87.97  ...            9.9            29.30            1\n","30          30     1     71.57  ...           -0.2            -0.20            1\n","31          31     1     87.53  ...            4.0             3.80            1\n","32          32     1      5.07  ...           18.9             1.60            0\n","33          33     1      7.71  ...            3.5             4.90            1\n","34          34     1     15.49  ...            5.9            17.50            0\n","35          35     1     13.40  ...            6.6             4.70            0\n","36          36     1     28.07  ...            4.8             3.80            0\n","37          37     0     30.23  ...            9.6             7.00            0\n","\n","[38 rows x 7 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/tae.csv\n","     Unnamed: 0  ...  binaryClass\n","0             0  ...            1\n","1             1  ...            1\n","2             2  ...            1\n","3             3  ...            1\n","4             4  ...            1\n","..          ...  ...          ...\n","146         146  ...            0\n","147         147  ...            0\n","148         148  ...            0\n","149         149  ...            0\n","150         150  ...            0\n","\n","[151 rows x 7 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/teachingAssistant.csv\n","     Unnamed: 0  EnglishSepaker  courseInstructor  ...  summer  classSize  class\n","0             0               1                23  ...       1         19      2\n","1             1               2                15  ...       1         17      2\n","2             2               1                23  ...       2         49      2\n","3             3               1                 5  ...       2         33      2\n","4             4               2                 7  ...       2         55      2\n","..          ...             ...               ...  ...     ...        ...    ...\n","146         146               2                 3  ...       2         26      0\n","147         147               2                10  ...       2         12      0\n","148         148               1                18  ...       2         48      0\n","149         149               2                22  ...       2         51      0\n","150         150               2                 2  ...       2         27      0\n","\n","[151 rows x 7 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/rabe_131.csv\n","    Unnamed: 0  col_1  col_2  col_3  col_4  col_5  binaryClass\n","0            0      1    508    235   3944    325            1\n","1            1      2    564    231   4578    323            1\n","2            2      3    322    270   4011    328            1\n","3            3      4    846    261   5233    305            1\n","4            4      5    871    300   4780    303            1\n","5            5      6    774    317   5889    307            1\n","6            6      7    856    387   5663    301            1\n","7            7      8    889    285   5759    310            1\n","8            8      9    715    300   4894    300            1\n","9            9     10    753    221   5012    324            1\n","10          10     11    649    264   4908    329            1\n","11          11     12    830    308   5753    320            1\n","12          12     13    738    379   5439    337            1\n","13          13     14    659    342   4634    328            1\n","14          14     15    664    378   4921    330            1\n","15          15     16    572    232   4869    318            1\n","16          16     17    701    231   4672    309            1\n","17          17     18    443    246   4782    333            1\n","18          18     19    446    230   4296    330            1\n","19          19     20    615    268   4827    318            1\n","20          20     21    661    337   5057    304            1\n","21          21     22    772    344   5540    328            0\n","22          22     23    766    330   5331    323            0\n","23          23     24    631    261   4715    317            0\n","24          24     25    390    214   3828    310            0\n","25          25     26    450    245   4120    321            0\n","26          26     27    476    233   3817    342            0\n","27          27     28    603    250   4243    339            0\n","28          28     29    805    243   4647    287            0\n","29          29     30    523    216   3967    325            0\n","30          30     31    588    212   3946    315            0\n","31          31     32    584    208   3724    332            0\n","32          32     33    445    215   3448    358            0\n","33          33     34    500    221   3680    320            0\n","34          34     35    661    244   3825    355            0\n","35          35     36    680    234   4189    306            0\n","36          36     37    797    269   4336    335            0\n","37          37     38    534    302   4418    335            0\n","38          38     39    541    268   4323    344            0\n","39          39     40    605    323   4813    331            0\n","40          40     41    785    304   5046    324            0\n","41          41     42    698    317   3764    366            0\n","42          42     43    796    332   4504    340            0\n","43          43     44    804    315   4005    378            0\n","44          44     45    809    291   5560    330            0\n","45          45     46    726    312   4989    313            0\n","46          46     47    671    316   4697    305            0\n","47          47     48    909    332   5438    307            0\n","48          48     49    484    546   5613    386            0\n","49          49     50    831    311   5309    333            0\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/visualizing_livestock.csv\n","     Unnamed: 0  livestocktype   country  binaryClass\n","0             0       0.909091  0.998684            1\n","1             1       0.958333  0.993523            1\n","2             2       0.916667  0.750415            1\n","3             3       0.913043  0.750358            1\n","4             4       0.913043  0.750358            1\n","..          ...            ...       ...          ...\n","125         125       0.875000  0.998684            1\n","126         126       0.916667  0.750358            0\n","127         127       0.956522  0.671672            0\n","128         128       0.956522  0.253761            0\n","129         129       0.875000  0.671672            1\n","\n","[130 rows x 4 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/veteran.csv\n","     Unnamed: 0  treatment  celltype  status  ...  months  age  therapy  binaryClass\n","0             0          1         1       1  ...       7   69        0            1\n","1             1          1         1       1  ...       5   64       10            0\n","2             2          1         1       1  ...       3   38        0            0\n","3             3          1         1       1  ...       9   63       10            0\n","4             4          1         1       1  ...      11   65       10            1\n","..          ...        ...       ...     ...  ...     ...  ...      ...          ...\n","132         132          2         4       1  ...       1   65        0            0\n","133         133          2         4       1  ...       5   64        0            1\n","134         134          2         4       1  ...      18   67       10            0\n","135         135          2         4       1  ...       4   65        0            0\n","136         136          2         4       1  ...       3   37        0            1\n","\n","[137 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/transplant.csv\n","     Unnamed: 0       e   z  binaryClass\n","0             0   0.057   0            1\n","1             1   0.064   0            1\n","2             2   0.064   0            1\n","3             3   0.066   1            1\n","4             4   0.462   0            1\n","..          ...     ...  ..          ...\n","126         126   7.002   3            0\n","127         127   7.851   9            0\n","128         128   9.573   7            0\n","129         129  12.050  18            0\n","130         130  12.131  17            0\n","\n","[131 rows x 4 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/triazines.csv\n","     Unnamed: 0  p1_polar  p1_size  ...  p6_sigma  p6_branch  binaryClass\n","0             0      0.58    0.233  ...     0.633      0.633            0\n","1             1      0.10    0.100  ...     0.100      0.100            1\n","2             2      0.26    0.100  ...     0.100      0.100            0\n","3             3      0.42    0.500  ...     0.100      0.100            0\n","4             4      0.58    0.233  ...     0.100      0.100            0\n","..          ...       ...      ...  ...       ...        ...          ...\n","181         181      0.58    0.233  ...     0.900      0.100            0\n","182         182      0.58    0.233  ...     0.633      0.633            0\n","183         183      0.42    0.767  ...     0.100      0.100            1\n","184         184      0.26    0.100  ...     0.100      0.100            0\n","185         185      0.26    0.100  ...     0.633      0.633            1\n","\n","[186 rows x 60 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/vote.csv\n","     Unnamed: 0  ...  Class\n","0             0  ...      1\n","1             1  ...      1\n","2             2  ...      0\n","3             3  ...      0\n","4             4  ...      0\n","..          ...  ...    ...\n","430         430  ...      1\n","431         431  ...      0\n","432         432  ...      1\n","433         433  ...      1\n","434         434  ...      1\n","\n","[435 rows x 18 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/white-clover.csv\n","    Unnamed: 0    strata      plot  ...  Weeds-94  strata-combined  binaryClass\n","0            0  0.285729  0.833333  ...      8.33                1            0\n","1            1  0.999997  0.631579  ...     50.00                1            1\n","2            2  0.999982  0.578947  ...     11.76                1            1\n","3            3  0.714281  0.750000  ...     16.67                1            1\n","4            4  0.749999  0.631579  ...     30.33                4            1\n","..         ...       ...       ...  ...       ...              ...          ...\n","58          58  0.285728  0.777778  ...     22.78                4            1\n","59          59  0.375002  0.722222  ...      9.15                4            1\n","60          60  0.285728  0.722222  ...      3.85                1            1\n","61          61  0.500001  0.833333  ...     27.96                4            0\n","62          62  0.285729  0.833333  ...      2.17                1            1\n","\n","[63 rows x 33 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/acute-inflammation.csv\n","     Unnamed: 0       f1        f2  ...        f5        f6  clase\n","0             0 -1.77236 -0.562162  ... -0.979364 -0.841625      0\n","1             1 -1.55248 -0.562162  ...  1.012560  1.178280      1\n","2             2 -1.55248 -0.562162  ... -0.979364 -0.841625      0\n","3             3 -1.49751 -0.562162  ...  1.012560  1.178280      1\n","4             4 -1.49751 -0.562162  ... -0.979364 -0.841625      0\n","..          ...      ...       ...  ...       ...       ...    ...\n","115         115  1.47094 -0.562162  ... -0.979364  1.178280      0\n","116         116  1.52591 -0.562162  ... -0.979364 -0.841625      0\n","117         117  1.52591  1.764020  ...  1.012560 -0.841625      0\n","118         118  1.52591 -0.562162  ... -0.979364  1.178280      0\n","119         119  1.52591 -0.562162  ... -0.979364  1.178280      0\n","\n","[120 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/acute-nephritis.csv\n","     Unnamed: 0       f1        f2  ...        f6        f7  clase\n","0             0 -1.77236 -0.562162  ... -0.841625 -0.979364      0\n","1             1 -1.55248 -0.562162  ...  1.178280  1.012560      0\n","2             2 -1.55248 -0.562162  ... -0.841625 -0.979364      0\n","3             3 -1.49751 -0.562162  ...  1.178280  1.012560      0\n","4             4 -1.49751 -0.562162  ... -0.841625 -0.979364      0\n","..          ...      ...       ...  ...       ...       ...    ...\n","115         115  1.47094 -0.562162  ...  1.178280 -0.979364      1\n","116         116  1.52591 -0.562162  ... -0.841625 -0.979364      0\n","117         117  1.52591  1.764020  ... -0.841625 -0.979364      1\n","118         118  1.52591 -0.562162  ...  1.178280 -0.979364      1\n","119         119  1.52591 -0.562162  ...  1.178280 -0.979364      1\n","\n","[120 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/annealing.csv\n","     Unnamed: 0            f1        f2  ...       f30           f31  clase\n","0             0 -2.234250e-01 -0.205931  ... -0.220071 -1.040750e-01      2\n","1             1 -2.234250e-01 -0.871245  ... -0.220071 -1.040750e-01      2\n","2             2 -2.234250e-01 -0.871245  ... -0.220071 -1.040750e-01      2\n","3             3 -2.234250e-01 -0.205931  ... -0.220071 -1.040750e-01      2\n","4             4 -2.234250e-01 -0.205931  ... -0.220071 -1.040750e-01      2\n","..          ...           ...       ...  ...       ...           ...    ...\n","893         893 -3.730000e-16 -0.750000  ... -1.000000 -1.560000e-17      1\n","894         894 -3.730000e-16 -0.750000  ... -1.000000 -1.560000e-17      1\n","895         895 -3.730000e-16  1.000000  ... -1.000000 -1.560000e-17      1\n","896         896 -3.730000e-16 -0.500000  ... -1.000000 -1.560000e-17      4\n","897         897 -3.730000e-16 -0.500000  ... -0.333333 -1.560000e-17      4\n","\n","[898 rows x 33 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/balance-scale.csv\n","     Unnamed: 0       f1       f2       f3        f4  clase\n","0             0 -1.41308 -1.41308 -1.41308 -1.413080      0\n","1             1 -1.41308 -1.41308 -1.41308 -0.706541      2\n","2             2 -1.41308 -1.41308 -1.41308  0.000000      2\n","3             3 -1.41308 -1.41308 -1.41308  0.706541      2\n","4             4 -1.41308 -1.41308 -1.41308  1.413080      2\n","..          ...      ...      ...      ...       ...    ...\n","620         620  1.41308  1.41308  1.41308 -1.413080      1\n","621         621  1.41308  1.41308  1.41308 -0.706541      1\n","622         622  1.41308  1.41308  1.41308  0.000000      1\n","623         623  1.41308  1.41308  1.41308  0.706541      1\n","624         624  1.41308  1.41308  1.41308  1.413080      0\n","\n","[625 rows x 6 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/bank.csv\n","      Unnamed: 0        f1        f2  ...       f15       f16  clase\n","0              0 -1.056150 -1.154780  ... -0.320377 -0.441355      0\n","1              1 -0.772497  1.402470  ...  2.041510  2.110260      0\n","2              2 -0.583394 -0.870645  ...  0.270094  2.110260      0\n","3              3 -1.056150 -0.870645  ... -0.320377 -0.441355      0\n","4              4  1.685850  0.265913  ... -0.320377 -0.441355      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","4516        4516 -0.772497  1.402470  ... -0.320377 -0.441355      0\n","4517        4517  1.496750  0.550053  ... -0.320377 -0.441355      0\n","4518        4518  1.496750  1.118330  ... -0.320377 -0.441355      0\n","4519        4519 -1.245260  0.265913  ...  1.451040  0.834454      0\n","4520        4520  0.267573 -0.302366  ...  3.812920  0.834454      0\n","\n","[4521 rows x 18 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/blood.csv\n","     Unnamed: 0        f1        f2        f3        f4  clase\n","0             0 -0.927278  7.618250  7.618250  2.613880      1\n","1             1 -1.174330  1.281880  1.281880 -0.257708      1\n","2             2 -1.050810  1.795640  1.795640  0.029451      1\n","3             3 -0.927278  2.480650  2.480650  0.439678      1\n","4             4 -1.050810  3.165670  3.165670  1.752410      0\n","..          ...       ...       ...       ...       ...    ...\n","743         743  1.666790 -0.601905 -0.601905  0.152519      0\n","744         744  1.419730 -0.601905 -0.601905  0.726838      0\n","745         745  1.666790 -0.430651 -0.430651  1.137070      0\n","746         746  3.643220 -0.773158 -0.773158  0.193542      0\n","747         747  7.719610 -0.773158 -0.773158  1.547290      0\n","\n","[748 rows x 6 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/breast-cancer.csv\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0 -1.644900  0.912871  ... -0.130877  0.557527      0\n","1             1 -0.656576  0.912871  ...  0.700918  0.557527      0\n","2             2 -0.656576  0.912871  ... -0.130877  0.557527      0\n","3             3  1.320060 -0.912871  ... -0.962672  0.557527      0\n","4             4 -0.656576  0.912871  ...  1.532710  0.557527      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","281         281 -1.644900  0.912871  ... -0.962672  0.557527      1\n","282         282 -1.644900  0.912871  ... -0.962672 -1.787360      1\n","283         283  1.320060 -0.912871  ... -0.962672  0.557527      1\n","284         284 -0.656576 -0.912871  ... -0.130877  0.557527      1\n","285         285  0.331744 -0.912871  ... -0.130877  0.557527      1\n","\n","[286 rows x 11 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/breast-cancer-wisc.csv\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0  0.206788 -0.699494  ... -0.611387 -0.343666      0\n","1             1  0.206788  0.283642  ... -0.283909 -0.343666      0\n","2             2 -0.503505 -0.699494  ... -0.611387 -0.343666      0\n","3             3  0.561934  1.594490  ...  1.353480 -0.343666      0\n","4             4 -0.148359 -0.699494  ... -0.611387 -0.343666      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","694         694 -0.503505 -0.699494  ... -0.611387 -0.343666      0\n","695         695 -0.858651 -0.699494  ... -0.611387 -0.343666      0\n","696         696  0.206788  2.249910  ...  2.335920  0.239398      1\n","697         697 -0.148359  1.594490  ...  1.026010 -0.343666      1\n","698         698 -0.148359  1.594490  ...  0.371049 -0.343666      1\n","\n","[699 rows x 11 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/breast-cancer-wisc-diag.csv\n","     Unnamed: 0        f1        f2  ...       f29       f30  clase\n","0             0  1.096100 -2.071510  ...  2.748200  1.935310      1\n","1             1  1.828210 -0.353322  ... -0.243675  0.280943      1\n","2             2  1.578500  0.455786  ...  1.151240  0.201214      1\n","3             3 -0.768233  0.253509  ...  6.040730  4.930670      1\n","4             4  1.748760 -1.150800  ... -0.867590 -0.396751      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","564         564  2.109140  0.720838  ... -1.358960 -0.708467      1\n","565         565  1.703360  2.083300  ... -0.531387 -0.973122      1\n","566         566  0.701667  2.043780  ... -1.103580 -0.318129      1\n","567         567  1.836720  2.334400  ...  1.917400  2.217680      1\n","568         568 -1.806810  1.220720  ... -0.048096 -0.750546      0\n","\n","[569 rows x 32 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/breast-cancer-wisc-prog.csv\n","     Unnamed: 0        f1        f2  ...       f32       f33  clase\n","0             0 -0.456501  0.192201  ...  1.110710  0.340583      0\n","1             1  0.414001  0.182712  ...  0.078704 -0.210660      0\n","2             2  2.009920  1.251770  ... -0.179299 -0.578156      0\n","3             3  2.213040 -1.895300  ... -0.437302 -0.578156      0\n","4             4 -0.572568  0.910175  ...  0.336707 -0.578156      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","193         193 -1.065850  1.615500  ...  1.626720 -0.210660      0\n","194         194 -1.123890 -0.623822  ... -0.695304 -0.578156      0\n","195         195 -1.007820 -0.076644  ...  0.439908 -0.578156      0\n","196         196 -1.268970  1.267580  ...  0.078704 -0.578156      1\n","197         197 -1.181920 -0.225299  ...  0.336707 -0.578156      0\n","\n","[198 rows x 35 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/breast-tissue.csv\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0 -0.344131  0.981334  ...  0.297980 -0.332639      0\n","1             1 -0.602496  1.556360  ... -0.372984 -0.537880      0\n","2             2 -0.308207  1.637780  ...  0.480254 -0.201658      0\n","3             3 -0.536178  1.759910  ... -0.339265 -0.415371      0\n","4             4 -0.558950  1.174700  ... -0.346612 -0.505678      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","101         101  1.612510 -0.191614  ...  1.719750  1.674940      5\n","102         102  2.408310  1.172160  ...  4.472140  2.429750      5\n","103         103  1.081970 -0.703029  ...  1.463900  0.871188      5\n","104         104  2.010410 -1.094860  ... -0.645952  2.188610      5\n","105         105  2.408310 -0.731017  ...  3.103300  2.273580      5\n","\n","[106 rows x 11 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/car.csv\n","      Unnamed: 0       f1       f2        f3       f4       f5       f6  clase\n","0              0 -1.34125 -1.34125 -1.520840 -1.22439 -1.22439 -1.22439      1\n","1              1 -1.34125 -1.34125 -1.520840 -1.22439 -1.22439  0.00000      1\n","2              2 -1.34125 -1.34125 -1.520840 -1.22439 -1.22439  1.22439      1\n","3              3 -1.34125 -1.34125 -1.520840 -1.22439  0.00000 -1.22439      1\n","4              4 -1.34125 -1.34125 -1.520840 -1.22439  0.00000  0.00000      1\n","...          ...      ...      ...       ...      ...      ...      ...    ...\n","1723        1723  1.34125  1.34125  0.506946  1.22439  0.00000  0.00000      3\n","1724        1724  1.34125  1.34125  0.506946  1.22439  0.00000  1.22439      0\n","1725        1725  1.34125  1.34125  0.506946  1.22439  1.22439 -1.22439      1\n","1726        1726  1.34125  1.34125  0.506946  1.22439  1.22439  0.00000      3\n","1727        1727  1.34125  1.34125  0.506946  1.22439  1.22439  1.22439      0\n","\n","[1728 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/cardiotocography-3clases.csv\n","      Unnamed: 0        f1        f2  ...       f20       f21  clase\n","0              0 -1.351900 -0.822195  ...  1.870130  1.112720      1\n","1              1 -0.132494  0.729961  ... -0.234943 -0.524402      0\n","2              2 -0.030877 -0.046117  ... -0.200434 -0.524402      0\n","3              3  0.070740 -0.046117  ... -0.200434  1.112720      0\n","4              4 -0.132494  0.988654  ... -0.269452  1.112720      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","2121        2121  0.680444 -0.822195  ... -0.580037 -0.524402      1\n","2122        2122  0.680444 -0.563502  ... -0.545527  1.112720      1\n","2123        2123  0.680444 -0.563502  ... -0.511018  1.112720      1\n","2124        2124  0.680444 -0.563502  ... -0.511018  1.112720      1\n","2125        2125  0.883679 -0.304810  ... -0.614546 -0.524402      0\n","\n","[2126 rows x 23 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/cardiotocography-10clases.csv\n","      Unnamed: 0        f1        f2  ...       f20       f21  clase\n","0              0 -1.351900 -0.822195  ...  1.870130  1.112720      8\n","1              1 -0.132494  0.729961  ... -0.234943 -0.524402      5\n","2              2 -0.030877 -0.046117  ... -0.200434 -0.524402      5\n","3              3  0.070740 -0.046117  ... -0.200434  1.112720      5\n","4              4 -0.132494  0.988654  ... -0.269452  1.112720      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","2121        2121  0.680444 -0.822195  ... -0.580037 -0.524402      4\n","2122        2122  0.680444 -0.563502  ... -0.545527  1.112720      4\n","2123        2123  0.680444 -0.563502  ... -0.511018  1.112720      4\n","2124        2124  0.680444 -0.563502  ... -0.511018  1.112720      4\n","2125        2125  0.883679 -0.304810  ... -0.614546 -0.524402      0\n","\n","[2126 rows x 23 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/chess-krvkp.csv\n","      Unnamed: 0        f1        f2  ...       f35       f36  clase\n","0              0 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","1              1 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","2              2 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","3              3 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","4              4 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","3191        3191  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","3192        3192  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","3193        3193  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","3194        3194  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","3195        3195  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","\n","[3196 rows x 38 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/congressional-voting.csv\n","     Unnamed: 0        f1        f2  ...       f15      f16  clase\n","0             0 -0.168237 -0.351775  ... -0.261988 -0.55989      1\n","1             1 -0.168237 -0.351775  ... -0.261988  1.78196      1\n","2             2  5.930340 -0.351775  ... -0.261988 -0.55989      0\n","3             3 -0.168237 -0.351775  ... -0.261988 -0.55989      0\n","4             4 -0.168237 -0.351775  ... -0.261988 -0.55989      0\n","..          ...       ...       ...  ...       ...      ...    ...\n","430         430 -0.168237 -0.351775  ... -0.261988 -0.55989      1\n","431         431 -0.168237 -0.351775  ... -0.261988 -0.55989      0\n","432         432 -0.168237  2.836190  ... -0.261988 -0.55989      1\n","433         433 -0.168237 -0.351775  ... -0.261988 -0.55989      1\n","434         434 -0.168237 -0.351775  ...  3.808190 -0.55989      1\n","\n","[435 rows x 18 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/conn-bench-sonar-mines-rocks.csv\n","     Unnamed: 0        f1        f2  ...       f59       f60  clase\n","0             0 -0.398590 -0.040550  ...  0.171265 -0.657361      1\n","1             1  0.701845  0.420616  ... -0.443484 -0.418842      1\n","2             2 -0.128918  0.599621  ...  0.252153  0.256962      1\n","3             3 -0.833544 -0.647348  ... -0.637616  1.032150      1\n","4             4  2.045850  0.854476  ...  0.446284  0.574988      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","203         203 -0.455134 -0.116400  ...  1.837560  1.827210      0\n","204         204  0.136404 -0.859727  ... -0.281708  0.038320      0\n","205         205  1.001960  0.159693  ... -0.039044 -0.677238      0\n","206         206  0.049413 -0.095162  ... -0.702326 -0.339335      0\n","207         207 -0.137617 -0.064822  ... -0.297886  0.992396      0\n","\n","[208 rows x 62 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/contrac.csv\n","      Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0              0 -1.037810 -0.944427  ... -0.137007 -0.282591      0\n","1              1  1.514680 -1.929650  ...  0.887415 -0.282591      0\n","2              2  1.271590 -0.944427  ...  0.887415 -0.282591      0\n","3              3  1.150040  0.040800  ... -0.137007 -0.282591      0\n","4              4  0.420754  0.040800  ... -1.161430 -0.282591      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1468        1468  0.056112  1.026030  ...  0.887415 -0.282591      2\n","1469        1469  0.056112  1.026030  ...  0.887415 -0.282591      2\n","1470        1470  0.785396  0.040800  ...  0.887415 -0.282591      2\n","1471        1471  0.056112  0.040800  ... -1.161430 -0.282591      2\n","1472        1472 -1.888650  0.040800  ...  0.887415 -0.282591      2\n","\n","[1473 rows x 11 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/conn-bench-vowel-deterding.csv\n","     Unnamed: 0        f1        f2  ...       f10       f11  clase\n","0             0 -0.999053 -0.493029  ... -0.977895 -1.301820      0\n","1             1 -0.999053 -0.167339  ... -0.569557 -0.720006      1\n","2             2 -0.999053  1.092620  ... -0.872986  0.063479      2\n","3             3 -0.999053  0.918295  ...  0.285856 -1.267910      3\n","4             4 -0.999053  0.593649  ...  0.879803 -0.555813      4\n","..          ...       ...       ...  ...       ...       ...    ...\n","985         985  1.153450 -0.090104  ... -1.192290 -1.024020      6\n","986         986  1.153450 -1.527750  ... -0.424604 -0.861515      7\n","987         987  1.153450 -1.304120  ... -1.103210  0.595375      8\n","988         988  1.153450 -2.417890  ... -1.901680 -0.262509      9\n","989         989  1.153450  0.291066  ... -1.976180  0.842913     10\n","\n","[990 rows x 13 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/credit-approval.csv\n","     Unnamed: 0        f1        f2  ...       f14       f15  clase\n","0             0  0.681488 -0.015070  ...  0.123309 -0.195272      0\n","1             1 -1.495490  2.202890  ... -0.790640 -0.087788      0\n","2             2 -1.495490 -0.519369  ...  0.571662 -0.037117      0\n","3             3  0.681488 -0.254074  ... -0.462998 -0.194696      0\n","4             4  0.681488 -0.864332  ... -0.348035 -0.195272      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","685         685  0.681488 -0.791834  ...  0.456700 -0.195272      1\n","686         686 -1.495490 -0.665162  ...  0.111813 -0.119649      1\n","687         687 -1.495490 -0.459618  ...  0.111813 -0.195080      1\n","688         688  0.681488 -1.043580  ...  0.571662 -0.051321      1\n","689         689  0.681488  0.317146  ... -1.037810 -0.195272      1\n","\n","[690 rows x 17 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/cylinder-bands.csv\n","     Unnamed: 0        f1        f2  ...       f34       f35  clase\n","0             0  1.173460 -0.185139  ...  0.281940  0.111585      0\n","1             1  1.173460 -0.185139  ...  0.281940  0.111585      1\n","2             2  1.173460 -0.185139  ...  0.194359  0.111585      1\n","3             3  1.173460 -0.185139  ...  0.519108  0.111585      1\n","4             4 -0.887640 -0.185139  ...  0.411375  0.111585      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","507         507  0.142908  5.390800  ... -0.345857  0.111585      0\n","508         508  0.142908  5.390800  ... -0.345857  0.111585      0\n","509         509  0.142908  5.390800  ... -0.345857  0.111585      0\n","510         510  0.142908  5.390800  ... -0.345857  0.111585      0\n","511         511  0.142908  5.390800  ... -0.345857  0.111585      0\n","\n","[512 rows x 37 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/dermatology.csv\n","     Unnamed: 0        f1        f2  ...       f33       f34  clase\n","0             0 -0.102754  0.292103  ... -0.501529  1.213990      1\n","1             1  1.401560  1.717560  ... -0.501529 -1.712450      0\n","2             2 -0.102754 -1.133360  ...  2.211170 -0.591685      2\n","3             3 -0.102754  0.292103  ... -0.501529  0.280021      0\n","4             4 -0.102754  1.717560  ...  2.211170  0.591345      2\n","..          ...       ...       ...  ...       ...       ...    ...\n","361         361 -0.102754 -1.133360  ... -0.501529 -0.653950      3\n","362         362  1.401560  0.292103  ... -0.501529  0.030962      3\n","363         363  1.401560  0.292103  ...  2.211170 -0.467156      2\n","364         364 -0.102754 -1.133360  ...  2.211170  0.902668      2\n","365         365  1.401560  0.292103  ... -0.501529 -0.031302      0\n","\n","[366 rows x 36 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/echocardiogram.csv\n","     Unnamed: 0        f1        f2  ...       f9       f10  clase\n","0             0  0.725400 -0.471791  ... -0.62609 -0.471791      0\n","1             1  0.793939 -0.471791  ... -0.62609 -0.471791      0\n","2             2 -0.371225 -0.471791  ... -0.62609 -0.471791      0\n","3             3 -0.028530 -0.471791  ... -0.62609 -0.471791      0\n","4             4 -0.234147 -0.471791  ... -0.62609 -0.471791      1\n","..          ...       ...       ...  ...      ...       ...    ...\n","126         126  0.245627 -0.471791  ... -1.92796 -0.471791      1\n","127         127  0.245627 -0.471791  ... -1.92796 -0.471791      0\n","128         128  0.588322 -0.471791  ... -1.92796 -0.471791      0\n","129         129 -0.234147 -0.471791  ... -1.92796 -0.471791      0\n","130         130  0.108549 -0.471791  ... -1.92796 -0.471791      0\n","\n","[131 rows x 12 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/energy-y1.csv\n","     Unnamed: 0       f1       f2        f3  ...        f6       f7       f8  clase\n","0             0  2.04045 -1.78471 -0.561586  ... -1.340770 -1.75930 -1.81339      0\n","1             1  2.04045 -1.78471 -0.561586  ... -0.446922 -1.75930 -1.81339      0\n","2             2  2.04045 -1.78471 -0.561586  ...  0.446922 -1.75930 -1.81339      0\n","3             3  2.04045 -1.78471 -0.561586  ...  1.340770 -1.75930 -1.81339      0\n","4             4  1.28414 -1.22844  0.000000  ... -1.340770 -1.75930 -1.81339      1\n","..          ...      ...      ...       ...  ...       ...      ...      ...    ...\n","763         763 -1.17385  1.27479  0.561586  ...  1.340770  1.24324  1.41042      1\n","764         764 -1.36292  1.55293  1.123170  ... -1.340770  1.24324  1.41042      0\n","765         765 -1.36292  1.55293  1.123170  ... -0.446922  1.24324  1.41042      0\n","766         766 -1.36292  1.55293  1.123170  ...  0.446922  1.24324  1.41042      0\n","767         767 -1.36292  1.55293  1.123170  ...  1.340770  1.24324  1.41042      0\n","\n","[768 rows x 10 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/energy-y2.csv\n","     Unnamed: 0       f1       f2        f3  ...        f6       f7       f8  clase\n","0             0  2.04045 -1.78471 -0.561586  ... -1.340770 -1.75930 -1.81339      0\n","1             1  2.04045 -1.78471 -0.561586  ... -0.446922 -1.75930 -1.81339      0\n","2             2  2.04045 -1.78471 -0.561586  ...  0.446922 -1.75930 -1.81339      0\n","3             3  2.04045 -1.78471 -0.561586  ...  1.340770 -1.75930 -1.81339      0\n","4             4  1.28414 -1.22844  0.000000  ... -1.340770 -1.75930 -1.81339      1\n","..          ...      ...      ...       ...  ...       ...      ...      ...    ...\n","763         763 -1.17385  1.27479  0.561586  ...  1.340770  1.24324  1.41042      0\n","764         764 -1.36292  1.55293  1.123170  ... -1.340770  1.24324  1.41042      0\n","765         765 -1.36292  1.55293  1.123170  ... -0.446922  1.24324  1.41042      0\n","766         766 -1.36292  1.55293  1.123170  ...  0.446922  1.24324  1.41042      0\n","767         767 -1.36292  1.55293  1.123170  ...  1.340770  1.24324  1.41042      0\n","\n","[768 rows x 10 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/fertility.csv\n","    Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0            0 -0.315165  0.173098  ...  0.432779  2.538690      0\n","1            1 -0.315165  2.233790  ...  1.669290 -0.519327      1\n","2            2 -0.315165 -1.393030  ... -0.803732  0.500013      0\n","3            3 -0.315165  0.667664  ... -0.803732 -0.143780      0\n","4            4 -0.315165  0.008243  ... -0.803732  0.500013      1\n","..         ...       ...       ...  ...       ...       ...    ...\n","95          95 -1.156110  0.008243  ... -0.803732  0.500013      0\n","96          96 -1.156110 -0.486323  ...  0.432779  0.500013      0\n","97          97 -1.156110  0.008243  ... -0.803732 -0.519327      0\n","98          98 -1.156110 -0.239040  ...  0.432779 -1.163120      0\n","99          99 -1.156110  0.173098  ... -0.803732 -1.163120      0\n","\n","[100 rows x 11 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/glass.csv\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0  0.870826  0.284287  ... -0.352051 -0.585079      0\n","1             1 -0.248750  0.590433  ... -0.352051 -0.585079      0\n","2             2 -0.719631  0.149582  ... -0.352051 -0.585079      0\n","3             3 -0.232286 -0.242285  ... -0.352051 -0.585079      0\n","4             4 -0.311315 -0.168810  ... -0.352051 -0.585079      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","209         209 -0.703166  0.896579  ...  1.779800 -0.585079      5\n","210         210 -0.499008  1.851750  ...  2.845730 -0.585079      5\n","211         211  0.752282  1.165990  ...  2.946290 -0.585079      5\n","212         212 -0.610966  1.190480  ...  2.805510 -0.585079      5\n","213         213 -0.413394  1.006790  ...  3.006630 -0.585079      5\n","\n","[214 rows x 11 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/haberman-survival.csv\n","     Unnamed: 0       f1        f2        f3  clase\n","0             0 -2.07874  0.353006 -0.420903      0\n","1             1 -2.07874 -0.262492 -0.142725      0\n","2             2 -2.07874  0.660755 -0.559991      0\n","3             3 -1.98617 -1.185740 -0.281814      0\n","4             4 -1.98617  0.660755 -0.003636      0\n","..          ...      ...       ...       ...    ...\n","301         301  2.08660 -0.262492 -0.420903      0\n","302         302  2.17916  1.276250 -0.559991      0\n","303         303  2.27173  0.660755 -0.142725      0\n","304         304  2.36429  0.660755 -0.420903      1\n","305         305  2.82710 -1.493490 -0.281814      1\n","\n","[306 rows x 5 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/heart-cleveland.csv\n","     Unnamed: 0        f1        f2  ...       f12       f13  clase\n","0             0  0.947160  0.685069  ... -0.709957  0.658044      0\n","1             1  1.389700  0.685069  ...  2.500740 -0.863997      2\n","2             2  1.389700  0.685069  ...  1.430510  1.165390      1\n","3             3 -1.929370  0.685069  ... -0.709957 -0.863997      0\n","4             4 -1.486830 -1.454890  ... -0.709957 -0.863997      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","298         298 -1.044290  0.685069  ... -0.709957  1.165390      1\n","299         299  1.500340  0.685069  ...  1.430510  1.165390      2\n","300         300  0.283345  0.685069  ...  0.360277  1.165390      3\n","301         301  0.283345 -1.454890  ...  0.360277 -0.863997      1\n","302         302 -1.818740  0.685069  ... -0.709957 -0.863997      0\n","\n","[303 rows x 15 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/heart-hungarian.csv\n","     Unnamed: 0        f1       f2  ...      f11       f12  clase\n","0             0 -2.538020  0.61562  ... -0.72110 -0.310615      0\n","1             1 -2.410010  0.61562  ... -0.72110 -0.310615      0\n","2             2 -2.410010  0.61562  ... -0.72110 -0.310615      0\n","3             3 -2.282000 -1.61885  ... -0.72110  3.157260      0\n","4             4 -2.153990 -1.61885  ... -0.72110 -0.310615      0\n","..          ...       ...      ...  ...      ...       ...    ...\n","289         289  0.534251  0.61562  ... -0.72110 -0.310615      1\n","290         290  0.790274 -1.61885  ...  1.43122 -0.310615      1\n","291         291  1.046300  0.61562  ...  1.43122 -0.310615      1\n","292         292  1.302320 -1.61885  ...  1.43122  3.735240      1\n","293         293  2.198400  0.61562  ...  1.43122 -0.310615      1\n","\n","[294 rows x 14 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/heart-switzerland.csv\n","     Unnamed: 0       f1       f2        f3  ...       f10      f11       f12  clase\n","0             0 -2.58158  0.29627 -3.919100  ... -0.649444 -0.19567 -1.058550      1\n","1             1 -2.36014  0.29627  0.436767  ... -0.649444 -0.19567 -1.058550      1\n","2             2 -2.24943  0.29627  0.436767  ... -1.824170 -0.19567  1.158990      3\n","3             3 -2.13871  0.29627  0.436767  ...  0.525285 -0.19567  0.842203      1\n","4             4 -1.91728 -3.34785  0.436767  ... -0.649444 -0.19567 -1.058550      2\n","..          ...      ...      ...       ...  ...       ...      ...       ...    ...\n","118         118  1.62564  0.29627  0.436767  ...  0.525285 -0.19567  1.158990      1\n","119         119  1.62564  0.29627  0.436767  ...  0.525285 -0.19567  1.158990      3\n","120         120  1.84707  0.29627 -1.015190  ...  0.525285  5.82119 -1.058550      0\n","121         121  1.95779 -3.34785 -1.015190  ... -0.649444 -0.19567 -0.108173      1\n","122         122  2.06850  0.29627 -2.467140  ... -0.649444 -0.19567 -1.058550      1\n","\n","[123 rows x 14 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/heart-va.csv\n","     Unnamed: 0        f1        f2  ...       f11       f12  clase\n","0             0  0.467248  0.175423  ...  0.818974 -0.440715      2\n","1             1 -1.965000  0.175423  ... -0.896155 -0.440715      0\n","2             2  0.083209  0.175423  ...  1.676540 -0.440715      2\n","3             3 -0.556857  0.175423  ... -0.038590 -0.440715      1\n","4             4  0.851287  0.175423  ...  0.818974 -0.440715      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","195         195 -0.684870 -5.672010  ... -0.896155 -0.440715      1\n","196         196  0.339235  0.175423  ... -0.896155 -0.440715      0\n","197         197 -0.556857  0.175423  ... -0.896155  2.030580      2\n","198         198 -0.172818  0.175423  ... -0.896155 -0.440715      0\n","199         199  0.339235  0.175423  ... -0.896155 -0.440715      1\n","\n","[200 rows x 14 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/hepatitis.csv\n","     Unnamed: 0        f1        f2  ...       f18       f19  clase\n","0             0 -0.891303  2.937930  ... -0.996996 -0.904553      1\n","1             1  0.700309 -0.338179  ... -0.996996 -0.904553      1\n","2             2  2.928570 -0.338179  ... -0.996996 -0.904553      1\n","3             3 -0.811722 -0.338179  ...  1.274320 -0.904553      1\n","4             4 -0.572980 -0.338179  ... -0.996996 -0.904553      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","150         150  0.381987 -0.338179  ...  0.422574  1.098390      0\n","151         151  0.222826 -0.338179  ... -0.996996  1.098390      1\n","152         152  1.575700 -0.338179  ... -0.996996  1.098390      1\n","153         153  0.939051  2.937930  ...  0.365791  1.098390      1\n","154         154  0.143245 -0.338179  ...  0.195443  1.098390      0\n","\n","[155 rows x 21 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/hayes-roth.csv\n","     Unnamed: 0       f1        f2        f3  clase\n","0             0 -1.00692 -1.006920  0.047948      0\n","1             1 -1.00692  1.102810  0.047948      1\n","2             2 -1.00692  2.157680 -1.006920      2\n","3             3  2.15768  0.047948  0.047948      2\n","4             4 -1.00692  1.102810  2.157680      2\n","..          ...      ...       ...       ...    ...\n","155         155  3.00000  1.000000  2.000000      1\n","156         156  1.00000  1.000000  1.000000      0\n","157         157  2.00000  2.000000  2.000000      1\n","158         158  3.00000  3.000000  3.000000      0\n","159         159  4.00000  4.000000  4.000000      2\n","\n","[160 rows x 5 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/hill-valley.csv\n","      Unnamed: 0            f1           f2  ...          f99         f100  clase\n","0              0     -0.441300    -0.443197  ...    -0.441577    -0.444649      0\n","1              1     -0.443363    -0.445144  ...    -0.443563    -0.446745      1\n","2              2      3.339170     3.256770  ...     3.300560     3.752260      1\n","3              3      2.047070     1.748470  ...     1.827630     1.773500      0\n","4              4     -0.443149    -0.444938  ...    -0.443342    -0.446509      0\n","...          ...           ...          ...  ...          ...          ...    ...\n","1207        1207     13.000000    12.870000  ...    13.870000    13.510000      1\n","1208        1208     48.660000    50.110000  ...    47.430000    47.770000      0\n","1209        1209  10160.600000  9048.630000  ...  8997.600000  9305.770000      1\n","1210        1210     34.810000    35.070000  ...    32.830000    34.820000      1\n","1211        1211   8489.430000  7672.980000  ...  8389.310000  8712.800000      0\n","\n","[1212 rows x 102 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/horse-colic.csv\n","     Unnamed: 0       f1        f2  ...           f24       f25  clase\n","0             0  1.22289 -0.294392  ... -1.389020e-01  0.700639      1\n","1             1 -0.79286 -0.294392  ... -1.389020e-01  0.700639      1\n","2             2  1.22289 -0.294392  ... -1.389020e-01 -1.422510      1\n","3             3 -0.79286  3.385510  ... -1.389020e-01 -1.422510      0\n","4             4  1.22289 -0.294392  ... -1.389020e-01  0.700639      1\n","..          ...      ...       ...  ...           ...       ...    ...\n","363         363  2.00000  1.000000  ... -1.480000e-18  2.000000      0\n","364         364  2.00000  1.000000  ... -1.480000e-18  2.000000      1\n","365         365  1.00000  1.000000  ... -1.480000e-18  2.000000      0\n","366         366  2.00000  1.000000  ... -1.480000e-18  2.000000      1\n","367         367  2.00000  1.000000  ... -1.480000e-18  2.000000      0\n","\n","[368 rows x 27 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/ilpd-indian-liver.csv\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0  1.251020 -0.418518  ...  0.198798 -0.123691      0\n","1             1  1.065720  1.224120  ...  0.073094 -0.611552      0\n","2             2  1.065720  0.644365  ...  0.198798 -0.154182      0\n","3             3  0.818653 -0.370206  ...  0.324502  0.181222      0\n","4             4  1.683390  0.096819  ... -0.932539 -1.648260      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","578         578  0.942188 -0.450727  ... -1.938170 -1.739730      1\n","579         579 -0.293156 -0.434623  ...  0.073094  0.486135      0\n","580         580  0.448050 -0.402414  ...  0.073094  0.181222      0\n","581         581 -0.849060 -0.321893  ...  0.324502  0.181222      0\n","582         582 -0.416690 -0.370206  ...  1.581540  1.705790      1\n","\n","[583 rows x 11 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/image-segmentation.csv\n","      Unnamed: 0          f1          f2  ...       f17       f18  clase\n","0              0    0.207173    0.038577  ...  0.538437  0.140168      0\n","1              1    0.854911    0.176177  ...  0.507405  0.266499      0\n","2              2   -0.265136    0.279376  ...  0.481222  0.240125      0\n","3              3   -1.223250    0.244977  ...  0.661596  0.382278      0\n","4              4   -1.155780   -0.202222  ...  0.614466  0.105569      0\n","...          ...         ...         ...  ...       ...       ...    ...\n","2305        2305   32.000000  158.000000  ...  0.520578 -1.982830      3\n","2306        2306    8.000000  162.000000  ...  0.484805 -2.044950      3\n","2307        2307  128.000000  161.000000  ...  0.540918 -1.996310      3\n","2308        2308  150.000000  158.000000  ...  0.503086 -1.943450      3\n","2309        2309  124.000000  162.000000  ...  0.479931 -2.029310      3\n","\n","[2310 rows x 20 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/ionosphere.csv\n","     Unnamed: 0        f1        f2  ...       f32       f33  clase\n","0             0  0.347937  0.711357  ... -0.311776 -0.998170      1\n","1             1  0.347937  0.720619  ... -0.931276 -0.083167      0\n","2             2  0.347937  0.720619  ...  0.403867 -0.847381      1\n","3             3  0.347937  0.720619  ... -1.287990  2.104300      0\n","4             4  0.347937  0.720619  ... -0.756593 -1.433690      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","346         346  0.347937  0.389261  ...  1.063970 -0.122882      1\n","347         347  0.347937  0.622429  ...  1.081890  0.069693      1\n","348         348  0.347937  0.614151  ...  1.105120 -0.043238      1\n","349         349  0.347937  0.531914  ...  1.003830 -0.377741      1\n","350         350  0.347937  0.413411  ...  0.972474 -0.162255      1\n","\n","[351 rows x 35 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/iris.csv\n","     Unnamed: 0        f1        f2        f3        f4  clase\n","0             0 -0.897674  1.028610 -1.336790 -1.308590      0\n","1             1 -1.139200 -0.124540 -1.336790 -1.308590      0\n","2             2 -1.380730  0.336720 -1.393470 -1.308590      0\n","3             3 -1.501490  0.106090 -1.280120 -1.308590      0\n","4             4 -1.018440  1.259240 -1.336790 -1.308590      0\n","..          ...       ...       ...       ...       ...    ...\n","145         145  1.034540 -0.124540  0.816888  1.443120      2\n","146         146  0.551486 -1.277690  0.703536  0.918985      2\n","147         147  0.793012 -0.124540  0.816888  1.050020      2\n","148         148  0.430722  0.797981  0.930239  1.443120      2\n","149         149  0.068433 -0.124540  0.760212  0.787951      2\n","\n","[150 rows x 6 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/led-display.csv\n","     Unnamed: 0       f1        f2  ...        f6        f7  clase\n","0             0  0.55397 -1.206460  ...  0.452343  0.717382      7\n","1             1  0.55397 -1.206460  ... -2.208500 -1.392560      7\n","2             2  0.55397 -1.206460  ... -2.208500 -1.392560      2\n","3             3  0.55397  0.828042  ...  0.452343  0.717382      5\n","4             4  0.55397  0.828042  ...  0.452343  0.717382      0\n","..          ...      ...       ...  ...       ...       ...    ...\n","995         995  0.55397  0.828042  ...  0.452343  0.717382      9\n","996         996 -1.80335 -1.206460  ...  0.452343  0.717382      3\n","997         997  0.55397  0.828042  ... -2.208500 -1.392560      0\n","998         998  0.55397  0.828042  ...  0.452343  0.717382      8\n","999         999  0.55397  0.828042  ...  0.452343  0.717382      8\n","\n","[1000 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/lenses.csv\n","    Unnamed: 0       f1        f2        f3        f4  clase\n","0            0 -1.19896 -0.978945 -0.978945 -0.978945      2\n","1            1 -1.19896 -0.978945 -0.978945  0.978945      1\n","2            2 -1.19896 -0.978945  0.978945 -0.978945      2\n","3            3 -1.19896 -0.978945  0.978945  0.978945      0\n","4            4 -1.19896  0.978945 -0.978945 -0.978945      2\n","5            5 -1.19896  0.978945 -0.978945  0.978945      1\n","6            6 -1.19896  0.978945  0.978945 -0.978945      2\n","7            7 -1.19896  0.978945  0.978945  0.978945      0\n","8            8  0.00000 -0.978945 -0.978945 -0.978945      2\n","9            9  0.00000 -0.978945 -0.978945  0.978945      1\n","10          10  0.00000 -0.978945  0.978945 -0.978945      2\n","11          11  0.00000 -0.978945  0.978945  0.978945      0\n","12          12  0.00000  0.978945 -0.978945 -0.978945      2\n","13          13  0.00000  0.978945 -0.978945  0.978945      1\n","14          14  0.00000  0.978945  0.978945 -0.978945      2\n","15          15  0.00000  0.978945  0.978945  0.978945      2\n","16          16  1.19896 -0.978945 -0.978945 -0.978945      2\n","17          17  1.19896 -0.978945 -0.978945  0.978945      2\n","18          18  1.19896 -0.978945  0.978945 -0.978945      2\n","19          19  1.19896 -0.978945  0.978945  0.978945      0\n","20          20  1.19896  0.978945 -0.978945 -0.978945      2\n","21          21  1.19896  0.978945 -0.978945  0.978945      1\n","22          22  1.19896  0.978945  0.978945 -0.978945      2\n","23          23  1.19896  0.978945  0.978945  0.978945      2\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/libras.csv\n","     Unnamed: 0        f1        f2  ...       f89       f90  clase\n","0             0  1.157760 -0.928219  ...  0.647092 -0.889723      0\n","1             1  0.564595 -1.508480  ... -1.420030  1.196680      0\n","2             2  0.778505 -1.706040  ...  1.281790 -0.974615      0\n","3             3 -0.009116 -1.236880  ... -0.004772 -1.156560      0\n","4             4  0.525684 -0.915844  ...  0.175311 -0.634995      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","355         355  0.467318  1.257190  ...  0.218237  0.299025     14\n","356         356  0.370091  0.874434  ...  0.123871  0.153504     14\n","357         357  0.224250  1.084320  ... -0.210663  0.274763     14\n","358         358  0.467318  1.257190  ...  0.218237  0.299025     14\n","359         359  0.370091  0.874434  ...  0.123871  0.153504     14\n","\n","[360 rows x 92 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/lung-cancer.csv\n","    Unnamed: 0        f1        f2  ...       f55       f56  clase\n","0            0 -0.176777  1.129010  ...  0.472819  0.615692      0\n","1            1 -0.176777  1.129010  ...  0.472819  0.615692      0\n","2            2 -0.176777  1.129010  ... -2.048880  0.615692      0\n","3            3 -0.176777 -0.677408  ...  0.472819  0.615692      0\n","4            4 -0.176777  1.129010  ...  0.472819  0.615692      0\n","5            5 -0.176777  1.129010  ... -2.048880  0.615692      0\n","6            6 -0.176777  1.129010  ... -2.048880  0.615692      0\n","7            7 -0.176777 -0.677408  ...  0.472819  0.615692      0\n","8            8 -0.176777  1.129010  ...  0.472819  0.615692      0\n","9            9 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","10          10 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","11          11 -0.176777 -0.677408  ...  0.472819 -1.573430      1\n","12          12 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","13          13 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","14          14  5.480080  1.129010  ...  0.472819 -1.573430      1\n","15          15 -0.176777  1.129010  ...  0.472819  0.615692      1\n","16          16 -0.176777  1.129010  ...  0.472819  0.615692      1\n","17          17 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","18          18 -0.176777 -0.677408  ... -2.048880  0.615692      1\n","19          19 -0.176777 -2.483830  ...  0.472819 -1.573430      1\n","20          20 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","21          21 -0.176777  1.129010  ... -2.048880  0.615692      1\n","22          22 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","23          23 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","24          24 -0.176777  1.129010  ...  0.472819 -1.573430      2\n","25          25 -0.176777 -0.677408  ... -2.048880  0.615692      2\n","26          26 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","27          27 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","28          28 -0.176777  1.129010  ...  0.472819  0.615692      2\n","29          29 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","30          30 -0.176777 -0.677408  ...  0.472819  0.615692      2\n","31          31 -0.176777 -0.677408  ...  0.472819  0.615692      2\n","\n","[32 rows x 58 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/lymphography.csv\n","     Unnamed: 0        f1        f2  ...       f17       f18  clase\n","0             0  1.537300  0.894114  ...  0.512998 -0.315666      2\n","1             1  0.314072  0.894114  ...  0.512998 -0.315666      1\n","2             2  0.314072  0.894114  ...  0.512998  2.308970      2\n","3             3  0.314072 -1.110870  ...  0.512998  1.784050      2\n","4             4  0.314072 -1.110870  ...  0.512998 -0.840594      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","143         143  0.314072  0.894114  ...  0.512998  0.734190      2\n","144         144 -0.909156 -1.110870  ...  0.512998 -0.840594      1\n","145         145 -0.909156  0.894114  ...  0.512998  0.734190      2\n","146         146 -0.909156 -1.110870  ...  0.512998 -0.840594      1\n","147         147 -0.909156  0.894114  ...  0.512998  1.784050      1\n","\n","[148 rows x 20 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/mammographic.csv\n","     Unnamed: 0        f1        f2        f3        f4        f5  clase\n","0             0  0.368698  0.787565  0.278795  1.425410  0.368642      1\n","1             1 -0.189284 -0.814093 -1.243490 -1.007660 -3.093230      1\n","2             2  0.368698  0.186943  1.039940  1.425410  0.368642      1\n","3             3 -0.189284 -1.815130 -1.243490 -1.007660  0.368642      0\n","4             4  0.368698  1.254720 -1.243490  1.425410 -3.093230      1\n","..          ...       ...       ...       ...       ...       ...    ...\n","956         956 -0.189284 -0.547150 -0.482347 -1.007660  0.368642      0\n","957         957 -0.189284  0.053472  1.039940  1.425410  0.368642      1\n","958         958 -0.189284  0.587358  1.039940  1.425410  0.368642      0\n","959         959  0.368698  0.720829  1.039940  1.425410  0.368642      1\n","960         960 -0.189284  0.453886  0.278795  0.208874  0.368642      0\n","\n","[961 rows x 7 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/molec-biol-promoter.csv\n","     Unnamed: 0        f1        f2  ...       f56       f57  clase\n","0             0  1.148310 -1.186670  ...  0.403468  1.143730      0\n","1             1  1.148310  0.513155  ... -1.378520 -1.399670      0\n","2             2  0.320277  1.363070  ... -0.487524  0.295929      0\n","3             3 -1.335790 -1.186670  ...  1.294460 -0.551868      0\n","4             4  1.148310 -0.336758  ... -1.378520  0.295929      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","101         101 -0.507757 -0.336758  ... -1.378520  1.143730      1\n","102         102  0.320277  1.363070  ...  1.294460  0.295929      1\n","103         103 -0.507757  0.513155  ... -0.487524 -0.551868      1\n","104         104 -0.507757  1.363070  ... -1.378520 -0.551868      1\n","105         105  1.148310 -1.186670  ... -0.487524  1.143730      1\n","\n","[106 rows x 59 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/molec-biol-splice.csv\n","      Unnamed: 0        f1        f2  ...       f59       f60  clase\n","0              0 -0.462236 -0.434755  ...  1.383240  0.436385      0\n","1              1 -1.383240  0.472288  ...  0.476802 -0.491661      0\n","2              2  0.458771 -1.341800  ...  1.383240  0.436385      0\n","3              3  0.458771  0.472288  ... -0.429633 -0.491661      0\n","4              4  0.458771 -0.434755  ... -0.429633  1.364430      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","3185        3185  1.379780 -0.434755  ...  1.383240  1.364430      2\n","3186        3186  0.458771 -1.341800  ...  1.383240  0.436385      2\n","3187        3187  1.379780 -0.434755  ...  1.383240 -0.491661      2\n","3188        3188 -1.383240  1.379330  ... -1.336070 -1.419710      2\n","3189        3189 -1.383240  0.472288  ...  1.383240  1.364430      2\n","\n","[3190 rows x 62 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/monks-1.csv\n","     Unnamed: 0       f1        f2  ...        f5        f6  clase\n","0             0  0.45421  0.381467  ...  1.736100  0.740391      1\n","1             1  0.45421  0.381467  ...  1.736100  2.073090      1\n","2             2  0.45421  0.381467  ...  0.970018  0.740391      1\n","3             3  0.45421  0.381467  ...  1.736100  2.073090      1\n","4             4  0.45421  0.381467  ...  0.970018  0.740391      1\n","..          ...      ...       ...  ...       ...       ...    ...\n","551         551  1.22333  1.223330  ... -0.446696  0.998842      1\n","552         552  1.22333  1.223330  ...  0.446696 -0.998842      1\n","553         553  1.22333  1.223330  ...  0.446696  0.998842      1\n","554         554  1.22333  1.223330  ...  1.340090 -0.998842      1\n","555         555  1.22333  1.223330  ...  1.340090  0.998842      1\n","\n","[556 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/monks-2.csv\n","     Unnamed: 0        f1        f2  ...        f5        f6  clase\n","0             0  0.202573  0.209001  ...  0.743270  1.768840      0\n","1             1  0.202573  0.209001  ...  2.183150  0.516154      0\n","2             2  0.202573  0.209001  ...  0.023331  0.516154      0\n","3             3  0.202573  0.209001  ...  0.023331  1.768840      0\n","4             4  0.202573  0.209001  ...  0.743270  0.516154      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","596         596  1.223330  1.223330  ... -0.446696  0.998842      0\n","597         597  1.223330  1.223330  ...  0.446696 -0.998842      0\n","598         598  1.223330  1.223330  ...  0.446696  0.998842      0\n","599         599  1.223330  1.223330  ...  1.340090 -0.998842      0\n","600         600  1.223330  1.223330  ...  1.340090  0.998842      0\n","\n","[601 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/monks-3.csv\n","     Unnamed: 0        f1        f2  ...        f5        f6  clase\n","0             0  0.490585  0.428121  ...  0.237339  2.143340      1\n","1             1  0.490585  0.428121  ...  1.026040  0.779683      1\n","2             2  0.490585  0.428121  ...  1.026040  2.143340      1\n","3             3  0.490585  0.428121  ...  1.814730  0.779683      0\n","4             4  0.490585  0.428121  ...  2.603430  0.779683      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","549         549  1.223330  1.223330  ... -0.446696  0.998842      0\n","550         550  1.223330  1.223330  ...  0.446696 -0.998842      0\n","551         551  1.223330  1.223330  ...  0.446696  0.998842      0\n","552         552  1.223330  1.223330  ...  1.340090 -0.998842      0\n","553         553  1.223330  1.223330  ...  1.340090  0.998842      0\n","\n","[554 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/mushroom.csv\n","      Unnamed: 0        f1        f2  ...       f20       f21  clase\n","0              0 -0.545748  1.065600  ... -0.514358  0.307792      1\n","1              1 -0.545748  1.065600  ... -1.313030 -1.272800      0\n","2              2 -2.764800  1.065600  ... -1.313030 -0.482506      0\n","3              3 -0.545748  0.217879  ... -0.514358  0.307792      1\n","4              4 -0.545748  1.065600  ... -2.910370 -1.272800      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","8119        8119  1.673300  1.065600  ... -2.111700 -0.877655      0\n","8120        8120 -0.545748  1.065600  ...  0.284312 -0.877655      0\n","8121        8121  0.563776  1.065600  ... -2.111700 -0.877655      0\n","8122        8122  1.673300  0.217879  ...  0.284312 -0.877655      1\n","8123        8123 -0.545748  1.065600  ... -2.111700 -0.877655      0\n","\n","[8124 rows x 23 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/musk-1.csv\n","     Unnamed: 0        f1        f2  ...      f165      f166  clase\n","0             0  0.180723 -0.881600  ...  0.555801 -0.068543      1\n","1             1  0.180723 -0.802337  ...  0.538563 -0.068543      1\n","2             2  0.180723 -0.802337  ...  0.538563 -0.050089      1\n","3             3  0.180723 -0.881600  ...  0.555801 -0.068543      1\n","4             4  0.180723 -0.881600  ...  0.693711 -0.142359      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","471         471  0.567721 -0.892923  ...  0.193790 -0.806699      0\n","472         472 -0.040419 -0.032352  ...  0.521324  0.743429      0\n","473         473  0.236008  0.205437  ...  0.124835 -1.286500      0\n","474         474  0.014867  0.703662  ...  0.504085  0.743429      0\n","475         475  0.733577 -0.009706  ...  0.659233  1.149410      0\n","\n","[476 rows x 168 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/oocytes_merluccius_nucleus_4d.csv\n","      Unnamed: 0       f1       f2       f3  ...      f39      f40      f41  clase\n","0              0 -0.66583  0.87068  0.20516  ...  0.84426  0.82785  0.84868      1\n","1              1 -0.57054  0.43110 -0.03807  ...  0.36387  0.28662  0.26291      1\n","2              2 -0.35195  0.85706  1.09299  ...  0.99675  1.06345  1.09860      1\n","3              3  5.14385 -2.05174 -1.04042  ... -1.60085 -1.56880 -1.55293      1\n","4              4 -0.52017  0.69792  0.26792  ...  0.64029  0.65730  0.69135      1\n","...          ...      ...      ...      ...  ...      ...      ...      ...    ...\n","1017        1017 -0.67901  1.36021  1.58665  ...  1.61590  1.60920  1.59639      1\n","1018        1018  3.85452 -1.74393 -0.90185  ... -1.33751 -1.30136 -1.28101      1\n","1019        1019 -0.71009  1.30292  1.42301  ...  1.44609  1.48844  1.50363      1\n","1020        1020  0.60817 -0.80616 -0.81323  ... -1.25243 -1.23426 -1.22974      1\n","1021        1021  0.16332 -0.88682 -0.88774  ... -0.83327 -0.80755 -0.77084      0\n","\n","[1022 rows x 43 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/oocytes_merluccius_states_2f.csv\n","      Unnamed: 0        f1        f2  ...       f24       f25  clase\n","0              0 -1.179380 -2.187880  ... -0.118442  0.762846      2\n","1              1 -1.392120 -1.153970  ... -0.380753  0.419105      2\n","2              2  0.496807 -0.239263  ...  1.874060  0.965877      2\n","3              3 -2.020400 -1.050940  ... -0.589791 -1.725570      1\n","4              4 -0.949725 -1.428900  ...  0.514058  0.740187      2\n","...          ...       ...       ...  ...       ...       ...    ...\n","1017        1017  0.849184  0.046527  ...  1.116800  1.400070      2\n","1018        1018 -1.689340  0.049266  ... -0.371318 -1.583980      1\n","1019        1019  0.764456  0.560675  ...  0.991325  1.416910      2\n","1020        1020 -1.396220 -0.027077  ... -0.393457 -0.412658      1\n","1021        1021 -0.296385  0.284011  ... -0.664495 -0.903268      0\n","\n","[1022 rows x 27 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/oocytes_trisopterus_nucleus_2f.csv\n","     Unnamed: 0        f1        f2  ...       f24       f25  clase\n","0             0  1.069570  1.026090  ... -0.238559 -0.100345      1\n","1             1  0.865225  1.007010  ... -0.549728 -0.960983      1\n","2             2  0.470672  0.831544  ... -0.553146 -1.392640      0\n","3             3  0.693030  0.440988  ...  0.880447  0.750328      1\n","4             4 -0.036550 -0.069342  ...  2.072160  1.947350      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","907         907 -2.240880 -2.084740  ... -0.083684  0.984030      1\n","908         908 -2.249550 -2.436180  ... -0.169517  0.888902      1\n","909         909 -2.274820 -2.574890  ... -0.501495 -0.179252      1\n","910         910 -2.228770 -2.109480  ... -0.540793 -0.676919      0\n","911         911 -2.324960 -2.361930  ... -0.302064  0.837900      1\n","\n","[912 rows x 27 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/oocytes_trisopterus_states_5b.csv\n","     Unnamed: 0        f1        f2  ...       f31       f32  clase\n","0             0 -0.060327 -0.364650  ... -0.882776 -0.887593      1\n","1             1  0.421689 -0.791496  ... -0.855251 -0.871742      0\n","2             2  0.531289 -1.042850  ... -0.927451 -0.930379      0\n","3             3 -0.636291  0.825897  ...  0.579962  0.607756      2\n","4             4 -0.860368  1.868300  ...  2.439090  2.387320      2\n","..          ...       ...       ...  ...       ...       ...    ...\n","907         907 -0.715138  0.713209  ...  0.430934  0.436670      2\n","908         908 -0.743102  0.839040  ...  0.678978  0.667884      2\n","909         909  0.601100 -0.964491  ... -0.989797 -0.936246      2\n","910         910  1.936950 -1.632370  ... -1.334850 -1.286000      0\n","911         911 -0.636921  0.455490  ... -0.077408 -0.057329      2\n","\n","[912 rows x 34 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/ozone.csv\n","      Unnamed: 0        f1        f2  ...       f71       f72  clase\n","0              0 -0.495591  0.305248  ... -1.582260 -0.282034      0\n","1              1  1.034600  1.386190  ... -1.582260 -0.282034      0\n","2              2  1.111110  1.077350  ... -1.149770 -0.282034      0\n","3              3  2.488270  1.849450  ... -1.149770  1.297310      0\n","4              4  0.881577  0.536878  ...  0.003524  0.158360      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","2531        2531 -0.878138 -0.775693  ...  1.877630 -0.282034      0\n","2532        2532 -0.342572 -0.003593  ...  0.436011 -0.282034      0\n","2533        2533 -0.495591 -0.466853  ... -1.005610 -0.282034      0\n","2534        2534 -0.113044 -0.389643  ... -0.861448 -0.244069      0\n","2535        2535  0.039974 -0.080803  ... -0.717286 -0.282034      0\n","\n","[2536 rows x 74 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/parkinsons.csv\n","     Unnamed: 0        f1        f2  ...       f21       f22  clase\n","0             0 -0.827171 -0.435045  ... -0.209990  0.866655      1\n","1             1 -0.768992 -0.529611  ...  0.274371  1.798970      1\n","2             2 -0.907141 -0.721312  ... -0.103363  1.399060      1\n","3             3 -0.907286 -0.647425  ...  0.061985  1.802310      1\n","4             4 -0.923281 -0.604689  ... -0.129692  2.261260      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","190         190  0.482226  0.370232  ...  0.720090 -0.815604      0\n","191         191  1.335760  0.611117  ...  1.051430 -0.417853      0\n","192         192  0.494306  0.468897  ...  0.778335 -0.830273      0\n","193         193  1.075990  2.184420  ... -0.635368 -0.923727      0\n","194         194  1.451080  0.690469  ...  0.453635 -0.643399      0\n","\n","[195 rows x 24 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/pima.csv\n","     Unnamed: 0        f1        f2  ...        f7        f8  clase\n","0             0  0.639530  0.847771  ...  0.468187  1.425070      1\n","1             1 -0.844335 -1.122660  ... -0.364823 -0.190548      0\n","2             2  1.233080  1.942460  ...  0.604004 -0.105515      1\n","3             3 -0.844335 -0.997558  ... -0.920163 -1.040870      0\n","4             4 -1.141110  0.503727  ...  5.481340 -0.020483      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","763         763  1.826620 -0.622237  ... -0.908090  2.530490      0\n","764         764 -0.547562  0.034576  ... -0.398023 -0.530677      0\n","765         765  0.342757  0.003299  ... -0.684747 -0.275580      0\n","766         766 -0.844335  0.159683  ... -0.370859  1.169970      1\n","767         767 -0.844335 -0.872451  ... -0.473476 -0.870806      0\n","\n","[768 rows x 10 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/pittsburg-bridges-MATERIAL.csv\n","     Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0             0  0.503814 -1.627760  ... -0.201322 -1.454630      0\n","1             1 -0.831293 -0.039967  ... -0.201322 -1.454630      0\n","2             2 -0.831293  0.970444  ... -0.912659 -1.454630      0\n","3             3 -0.831293  0.248722  ... -0.201322 -1.454630      0\n","4             4  0.503814 -0.184311  ... -0.201322 -1.454630      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","101         101 -0.831293  0.537411  ...  1.221350  0.574195      2\n","102         102  0.503814 -1.194720  ...  1.221350  0.574195      2\n","103         103 -0.831293 -0.112139  ...  2.644030  0.574195      2\n","104         104  1.838920  1.331310  ...  2.644030  0.574195      2\n","105         105  0.503814 -1.339070  ...  2.644030  0.574195      2\n","\n","[106 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/pittsburg-bridges-REL-L.csv\n","     Unnamed: 0        f1        f2  ...        f6       f7  clase\n","0             0  0.521950 -1.633560  ... -0.137463 -1.42413      0\n","1             1 -0.822072 -0.041248  ... -0.137463 -1.42413      0\n","2             2 -0.822072  0.972039  ... -0.924055 -1.42413      0\n","3             3 -0.822072  0.248262  ... -0.137463 -1.42413      0\n","4             4  0.521950 -0.186004  ... -0.137463 -1.42413      0\n","..          ...       ...       ...  ...       ...      ...    ...\n","98           98  1.865970  1.189170  ... -1.710650  0.58526      2\n","99           99  1.865970  1.551060  ... -0.137463  0.58526      2\n","100         100  0.521950 -1.778310  ...  3.008910  0.58526      2\n","101         101 -0.822072  0.537773  ...  1.435720  0.58526      1\n","102         102  0.521950 -1.199290  ...  1.435720  0.58526      2\n","\n","[103 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/pittsburg-bridges-SPAN.csv\n","    Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0            0  0.566922 -1.646160  ... -0.056886 -1.337370      0\n","1            1 -0.805626 -0.028532  ... -0.056886 -1.337370      0\n","2            2 -0.805626  1.000870  ... -0.929132 -1.337370      0\n","3            3 -0.805626  0.265582  ... -0.056886 -1.337370      0\n","4            4  0.566922 -0.175589  ... -0.056886 -1.337370      0\n","..         ...       ...       ...  ...       ...       ...    ...\n","87          87 -0.805626  1.037630  ...  1.687610  0.615613      1\n","88          88 -0.805626  1.052340  ... -0.056886  0.615613      1\n","89          89 -0.805626  0.964104  ... -0.056886 -1.337370      1\n","90          90  1.939470  1.662630  ... -0.056886  0.615613      2\n","91          91 -2.178170  1.956740  ... -1.801380  0.615613      1\n","\n","[92 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/pittsburg-bridges-T-OR-D_R.csv\n","     Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0             0  0.525186 -1.649010  ... -0.124053 -1.413820      0\n","1             1 -0.814039 -0.053125  ... -0.124053 -1.413820      0\n","2             2 -0.814039  0.962439  ... -0.914891 -1.413820      0\n","3             3 -0.814039  0.237036  ... -0.124053 -1.413820      0\n","4             4  0.525186 -0.198206  ... -0.124053 -1.413820      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","97           97 -0.814039  0.817358  ...  1.457620 -1.413820      1\n","98           98  1.864410  1.180060  ... -1.705730  0.589094      0\n","99           99  1.864410  1.542760  ... -0.124053  0.589094      0\n","100         100  0.525186 -1.794090  ...  3.039300  0.589094      0\n","101         101 -0.814039  0.527197  ...  1.457620  0.589094      1\n","\n","[102 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/pittsburg-bridges-TYPE.csv\n","     Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0             0  0.495178 -1.618130  ... -0.218542 -1.444530      0\n","1             1 -0.837993 -0.030717  ... -0.218542 -1.444530      0\n","2             2 -0.837993  0.979454  ... -0.935635 -1.444530      0\n","3             3 -0.837993  0.257903  ... -0.218542 -1.444530      0\n","4             4  0.495178 -0.175028  ... -0.218542 -1.444530      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","100         100 -0.837993  0.546524  ...  1.215640  0.577813      5\n","101         101  0.495178 -1.185200  ...  1.215640  0.577813      5\n","102         102 -0.837993 -0.102873  ...  2.649830  0.577813      3\n","103         103  1.828350  1.340230  ...  2.649830  0.577813      3\n","104         104  0.495178 -1.329510  ...  2.649830  0.577813      3\n","\n","[105 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/planning.csv\n","     Unnamed: 0        f1        f2  ...       f11       f12  clase\n","0             0 -0.351883 -0.530606  ... -0.002265 -0.987931      0\n","1             1 -0.284001 -0.421044  ... -0.063014  0.212911      0\n","2             2 -0.252349  1.358370  ...  0.243928  1.901720      1\n","3             3  1.364870  1.099500  ...  1.048220  1.723690      0\n","4             4 -0.821941  0.308253  ... -0.381211  0.564927      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","177         177 -1.119760  0.728321  ... -0.005490 -0.288244      1\n","178         178 -1.604360  0.671821  ... -0.072911  1.999710      0\n","179         179  0.638549 -0.459284  ...  0.705566 -1.152280      1\n","180         180 -0.763609 -1.353420  ...  0.009971  1.437280      0\n","181         181  0.805012 -0.112679  ...  0.492909  1.480980      1\n","\n","[182 rows x 14 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/plant-margin.csv\n","      Unnamed: 0        f1        f2  ...       f63       f64  clase\n","0              0 -0.689954 -0.635367  ... -0.394050 -0.471823      0\n","1              1 -0.590266 -0.381682  ...  1.091280 -0.471823      0\n","2              2 -0.291153 -0.686098  ... -0.493065 -0.471823      0\n","3              3 -0.191465 -0.432414  ...  0.101078 -0.471823      0\n","4              4 -0.490579 -0.483145  ... -0.592080 -0.471823      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1595        1595  0.905148 -0.026534  ... -1.087210 -0.471823     99\n","1596        1596 -0.091778 -0.483145  ... -1.087210  1.299270     99\n","1597        1597 -0.191465 -0.584635  ... -0.790111  0.635155     99\n","1598        1598 -0.091778 -0.330950  ... -1.087210  0.635155     99\n","1599        1599  0.107597 -0.381682  ... -0.988193  3.070370     99\n","\n","[1600 rows x 66 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/plant-shape.csv\n","      Unnamed: 0        f1        f2  ...       f63       f64  clase\n","0              0 -0.585385 -0.402099  ... -0.326183 -0.430958      1\n","1              1 -0.394504 -0.205486  ... -0.117370 -0.232506      1\n","2              2 -0.446232 -0.377145  ... -0.365449 -0.474701      1\n","3              3 -0.459702 -0.550768  ... -0.337773 -0.473350      1\n","4              4 -0.508869 -0.614494  ... -0.351146 -0.504975      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","1595        1595  0.013754  0.010231  ...  0.384563  0.042139     99\n","1596        1596 -0.240470 -0.244899  ... -0.271644 -0.248787     99\n","1597        1597 -0.133489 -0.276309  ... -0.307267 -0.247512     99\n","1598        1598 -0.103172  0.230818  ... -0.068607 -0.099591     99\n","1599        1599  0.419450  0.205410  ...  0.422434  0.253647     99\n","\n","[1600 rows x 66 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/plant-texture.csv\n","      Unnamed: 0        f1        f2  ...       f63       f64  clase\n","0              0  0.097574  0.057117  ... -0.664316  0.321163      0\n","1              1 -0.400858  0.391199  ... -0.664316 -0.743886      0\n","2              2 -0.068570  0.112817  ... -0.664316 -0.616110      0\n","3              3  0.334905  0.669581  ... -0.664316  0.108144      0\n","4              4  0.406117  0.168459  ... -0.664316 -0.190073      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1594        1594 -0.377137 -0.555289  ...  1.127100 -0.530911     99\n","1595        1595 -0.495790 -0.555289  ... -0.664316 -0.701308     99\n","1596        1596 -0.210993 -0.388249  ... -0.377707 -0.488290     99\n","1597        1597 -0.495790 -0.555289  ... -0.664316 -0.317892     99\n","1598        1598 -0.258459  0.335500  ... -0.377707 -0.317892     99\n","\n","[1599 rows x 66 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/post-operative.csv\n","    Unnamed: 0        f1        f2  ...        f7        f8  clase\n","0            0  0.111882 -1.337670  ... -0.031621  1.471360      0\n","1            1  0.111882  1.598680  ... -0.031621 -0.192238      2\n","2            2  1.790110 -1.337670  ... -1.454570 -0.192238      0\n","3            3  0.111882 -1.337670  ... -1.454570  1.471360      0\n","4            4  0.111882  0.130505  ... -0.031621 -0.192238      0\n","..         ...       ...       ...  ...       ...       ...    ...\n","85          85  0.111882  0.130505  ... -0.031621 -0.192238      0\n","86          86  0.111882  0.130505  ... -0.031621  1.471360      2\n","87          87  0.111882  0.130505  ... -0.031621  1.471360      0\n","88          88  0.111882  0.130505  ... -0.031621 -0.192238      0\n","89          89  0.111882  0.130505  ... -0.031621  1.471360      2\n","\n","[90 rows x 10 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/seeds.csv\n","     Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0             0  0.141759  0.214949  ... -0.983801 -0.382663      0\n","1             1  0.011161  0.008204  ... -1.783900 -0.919816      0\n","2             2 -0.191609 -0.359342  ... -0.665888 -1.186360      0\n","3             3 -0.346264 -0.474200  ... -0.958528 -1.227050      0\n","4             4  0.444196  0.329807  ... -1.559770 -0.474223      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","205         205 -0.913333 -1.040830  ... -0.046025 -1.094800      2\n","206         206 -1.243260 -1.285860  ...  0.415547 -0.824186      2\n","207         207 -0.566218 -0.688602  ...  3.069250 -0.716349      2\n","208         208 -1.033620 -1.033180  ... -0.067973 -0.740765      2\n","209         209 -0.875528 -0.933633  ...  1.288140 -0.702106      2\n","\n","[210 rows x 9 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/semeion.csv\n","      Unnamed: 0        f1        f2  ...      f255      f256  clase\n","0              0 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","1              1 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","2              2 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","3              3 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","4              4 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1588        1588 -0.324678 -0.426189  ...  3.112100 -0.206186      9\n","1589        1589 -0.324678 -0.426189  ... -0.321124 -0.206186      9\n","1590        1590 -0.324678 -0.426189  ... -0.321124 -0.206186      9\n","1591        1591 -0.324678  2.344910  ... -0.321124 -0.206186      9\n","1592        1592 -0.324678 -0.426189  ... -0.321124 -0.206186      9\n","\n","[1593 rows x 258 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/soybean.csv\n","     Unnamed: 0            f1            f2  ...           f34           f35  clase\n","0             0  1.441970e+00 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","1             1  2.800680e-01 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","2             2 -3.008840e-01 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","3             3 -3.008840e-01 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","4             4  1.441970e+00 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","..          ...           ...           ...  ...           ...           ...    ...\n","678         678 -5.470000e-16 -1.610000e-16  ...  4.870000e-16 -3.490000e-17      0\n","679         679 -5.470000e-16  1.000000e+00  ...  4.870000e-16  1.000000e+00     17\n","680         680  2.000000e+00  1.000000e+00  ...  4.870000e-16  1.000000e+00     17\n","681         681 -5.470000e-16  1.000000e+00  ...  4.870000e-16  1.000000e+00     17\n","682         682  2.000000e+00  1.000000e+00  ...  4.870000e-16  1.000000e+00     17\n","\n","[683 rows x 37 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/spambase.csv\n","      Unnamed: 0        f1        f2  ...       f56       f57  clase\n","0              0 -0.342396  0.330849  ...  0.045293 -0.008723      1\n","1              1  0.345322  0.051904  ...  0.250536  1.228190      1\n","2              2 -0.145906 -0.165054  ...  2.220860  3.258380      1\n","3              3 -0.342396 -0.165054  ... -0.062459 -0.152205      1\n","4              4 -0.342396 -0.165054  ... -0.062459 -0.152205      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","4596        4596  0.672807 -0.165054  ... -0.252309 -0.322075      0\n","4597        4597 -0.342396 -0.165054  ... -0.247178 -0.444117      0\n","4598        4598  0.640058 -0.165054  ... -0.236916 -0.272598      0\n","4599        4599  2.801460 -0.165054  ... -0.242047 -0.338567      0\n","4600        4600 -0.342396 -0.165054  ... -0.242047 -0.401237      0\n","\n","[4601 rows x 59 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/spect.csv\n","     Unnamed: 0            f1            f2  ...           f21           f22  clase\n","0             0  9.811510e-01 -7.362540e-01  ... -5.397650e-01 -5.591580e-01      0\n","1             1  9.811510e-01 -7.362540e-01  ... -5.397650e-01 -5.591580e-01      1\n","2             2  9.811510e-01  1.341030e+00  ... -5.397650e-01 -5.591580e-01      0\n","3             3  9.811510e-01 -7.362540e-01  ...  1.829210e+00  1.765760e+00      1\n","4             4  9.811510e-01 -7.362540e-01  ... -5.397650e-01 -5.591580e-01      0\n","..          ...           ...           ...  ...           ...           ...    ...\n","260         260  2.250000e-17 -3.930000e-17  ... -9.560000e-17 -2.700000e-16      0\n","261         261  2.250000e-17 -3.930000e-17  ... -9.560000e-17 -2.700000e-16      0\n","262         262  2.250000e-17  1.000000e+00  ... -9.560000e-17 -2.700000e-16      0\n","263         263  2.250000e-17  1.000000e+00  ... -9.560000e-17 -2.700000e-16      0\n","264         264  2.250000e-17  1.000000e+00  ... -9.560000e-17 -2.700000e-16      0\n","\n","[265 rows x 24 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/spectf.csv\n","     Unnamed: 0        f1        f2  ...       f43       f44  clase\n","0             0  0.865112  0.683281  ...  1.398350  1.527330      1\n","1             1  1.244660  0.979054  ...  1.119050  1.210880      1\n","2             2  1.215470  0.979054  ...  0.944490  0.788953      1\n","3             3  1.157070  1.245250  ...  1.223790  1.386690      1\n","4             4  1.186270  1.097360  ...  0.874666  0.613150      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","262         262  0.989924  0.513293  ...  0.215094  0.557168      0\n","263         263  0.766758 -0.274283  ...  0.364899  0.225774      0\n","264         264  1.101510  0.907082  ...  1.188820  1.485070      0\n","265         265 -0.683817 -0.175836  ...  1.413530  1.418790      0\n","266         266 -0.125903  0.217952  ...  0.439801  0.358331      0\n","\n","[267 rows x 46 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/statlog-australian-credit.csv\n","     Unnamed: 0        f1        f2  ...       f13       f14  clase\n","0             0 -0.800471  1.346130  ...  0.037353 -0.894654      1\n","1             1 -0.750696  0.450221  ... -0.195272 -0.894654      0\n","2             2 -0.167735 -0.604384  ... -0.195272 -0.894654      0\n","3             3 -0.835061  1.354170  ... -0.195272  1.116130      0\n","4             4 -0.961608  0.685248  ... -0.164946  1.116130      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","685         685  0.000152  1.153290  ... -0.195272  1.116130      1\n","686         686 -0.919426 -0.872556  ... -0.186827 -0.894654      1\n","687         687 -1.074660  0.960450  ... -0.195272  1.116130      0\n","688         688 -0.349963  1.956800  ... -0.193160  1.116130      0\n","689         689  0.795712 -0.947885  ... -0.195272  1.116130      1\n","\n","[690 rows x 16 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/statlog-german-credit.csv\n","     Unnamed: 0        f1        f2  ...      f23       f24  clase\n","0             0 -1.253940 -1.235860  ... -0.49975  0.765973      0\n","1             1 -0.458797  2.247070  ... -0.49975  0.765973      1\n","2             2  1.131490 -0.738298  ...  1.99900 -1.304220      0\n","3             3 -1.253940  1.749510  ... -0.49975  0.765973      0\n","4             4 -1.253940  0.256825  ... -0.49975  0.765973      1\n","..          ...       ...       ...  ...      ...       ...    ...\n","995         995  1.131490 -0.738298  ...  1.99900 -1.304220      0\n","996         996 -1.253940  0.754386  ... -0.49975 -1.304220      0\n","997         997  1.131490 -0.738298  ... -0.49975  0.765973      0\n","998         998 -1.253940  1.998290  ... -0.49975  0.765973      1\n","999         999 -0.458797  1.998290  ... -0.49975  0.765973      0\n","\n","[1000 rows x 26 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/statlog-heart_.csv\n","     Unnamed: 0        f1        f2  ...       f12       f13  clase\n","0             0  1.708920  0.688222  ...  2.468100 -0.874083      1\n","1             1  1.379580 -1.447640  ... -0.710216  1.187070      0\n","2             2  0.281771  0.688222  ... -0.710216  1.187070      1\n","3             3  1.050240  0.688222  ...  0.349222  1.187070      0\n","4             4  2.148040 -1.447640  ...  0.349222 -0.874083      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","265         265 -0.267133  0.688222  ... -0.710216  1.187070      0\n","266         266 -1.145380  0.688222  ... -0.710216  1.187070      0\n","267         267  0.171990 -1.447640  ... -0.710216 -0.874083      0\n","268         268  0.281771  0.688222  ... -0.710216  0.671784      0\n","269         269  1.379580  0.688222  ...  2.468100 -0.874083      1\n","\n","[270 rows x 15 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/statlog-image.csv\n","      Unnamed: 0        f1        f2  ...       f17       f18  clase\n","0              0  1.275910  0.949531  ... -0.472589 -0.438518      5\n","1              1 -0.163301  0.114514  ...  2.510220 -0.492034      2\n","2              2  1.056600 -1.433750  ... -0.996657 -0.606354      1\n","3              3 -1.273550  0.862550  ... -0.700712 -0.411536      5\n","4              4 -0.876054  1.280060  ... -0.542984 -0.426689      5\n","...          ...       ...       ...  ...       ...       ...    ...\n","2305        2305 -1.300960 -0.372580  ... -0.200752 -0.124374      0\n","2306        2306  0.247903 -1.729480  ... -1.127840 -0.638279      1\n","2307        2307 -0.615625 -0.894465  ... -0.491818 -0.470658      3\n","2308        2308 -0.368903  0.166702  ...  2.510220 -0.492034      2\n","2309        2309 -1.451740  0.410249  ...  1.254150 -0.072959      0\n","\n","[2310 rows x 20 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/statlog-vehicle.csv\n","     Unnamed: 0        f1        f2  ...       f17       f18  clase\n","0             0  0.160485  0.508649  ... -0.313537  0.183849      3\n","1             1 -0.325277 -0.625897  ...  0.010931  0.452709      3\n","2             2  1.253450  0.832805  ... -0.151303  0.049418      2\n","3             3 -0.082396 -0.625897  ...  1.633270  1.528150      3\n","4             4 -1.053920 -0.139663  ... -1.449170 -1.698180      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","841         841 -0.082396 -0.950053  ... -0.151303 -0.085012      2\n","842         842 -0.568159  0.184493  ... -0.475770  0.183849      3\n","843         843  1.496330  1.481120  ... -0.313537  0.721570      2\n","844         844 -0.932481 -1.436290  ...  0.173164 -0.085012      2\n","845         845 -1.053920 -1.436290  ... -0.475770 -0.757164      3\n","\n","[846 rows x 20 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/steel-plates.csv\n","      Unnamed: 0        f1        f2  ...       f26       f27  clase\n","0              0 -1.016220 -1.141340  ... -1.075470 -0.009487      0\n","1              1  0.141858  0.066386  ... -0.297747 -0.845541      0\n","2              2  0.495235  0.436141  ...  0.057170 -1.091230      0\n","3              3  0.541327  0.486379  ... -0.171375 -0.189189      0\n","4              4  1.378680  1.382630  ... -0.456385  1.221320      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1936        1936 -0.618671 -0.685180  ...  0.900100  0.412369      6\n","1937        1937 -0.820326 -0.890153  ...  0.491407  0.683100      6\n","1938        1938 -0.818405 -0.892162  ...  0.917577  0.360816      6\n","1939        1939 -0.833770 -0.900201  ...  0.767678  1.197460      6\n","1940        1940  1.324900  1.332390  ...  0.116995 -0.164443      6\n","\n","[1941 rows x 29 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/synthetic-control.csv\n","     Unnamed: 0        f1        f2  ...       f59       f60  clase\n","0             0 -0.354718  0.853862  ... -0.291262 -0.277970      0\n","1             1 -1.467260 -1.243980  ...  0.134039 -0.224873      0\n","2             2  0.394101 -0.067707  ... -0.029786 -0.053001      0\n","3             3 -1.215020 -0.093058  ... -0.169434 -0.314574      0\n","4             4 -0.812849 -0.400055  ...  0.070275  0.055547      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","595         595 -0.113208 -1.301130  ... -0.599440 -0.390918      5\n","596         596 -0.745734 -1.326650  ... -1.283800 -1.259920      5\n","597         597  1.681550 -1.020090  ... -0.764354 -0.822167      5\n","598         598 -1.568530 -1.595330  ... -1.090340 -0.823126      5\n","599         599  1.234240  0.005868  ... -1.173640 -1.296730      5\n","\n","[600 rows x 62 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/teaching.csv\n","     Unnamed: 0        f1        f2        f3       f4        f5  clase\n","0             0 -2.044270  1.370920 -0.726939 -2.35125 -0.687740      2\n","1             1  0.485933  0.198895 -0.726939 -2.35125 -0.842854      2\n","2             2 -2.044270  1.370920 -0.726939  0.42249  1.638970      2\n","3             3 -2.044270 -1.266140 -0.869310  0.42249  0.398057      2\n","4             4  0.485933 -0.973132  0.412027  0.42249  2.104310      2\n","..          ...       ...       ...       ...      ...       ...    ...\n","146         146  0.485933 -1.559150 -0.869310  0.42249 -0.144841      0\n","147         147  0.485933 -0.533622 -0.726939  0.42249 -1.230640      0\n","148         148 -2.044270  0.638406 -0.157456  0.42249  1.561410      0\n","149         149  0.485933  1.224420 -1.011680  0.42249  1.794080      0\n","150         150  0.485933 -1.705650  0.269656  0.42249 -0.067284      0\n","\n","[151 rows x 7 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/tic-tac-toe.csv\n","     Unnamed: 0       f1       f2       f3  ...        f7        f8        f9  clase\n","0             0 -1.03463 -1.10625 -1.03463  ... -1.034630  1.222960  1.230910      1\n","1             1 -1.03463 -1.10625 -1.03463  ...  1.230910 -1.106250  1.230910      1\n","2             2 -1.03463 -1.10625 -1.03463  ...  1.230910  1.222960 -1.034630      1\n","3             3 -1.03463 -1.10625 -1.03463  ...  1.230910  0.058352  0.098142      1\n","4             4 -1.03463 -1.10625 -1.03463  ...  0.098142  1.222960  0.098142      1\n","..          ...      ...      ...      ...  ...       ...       ...       ...    ...\n","953         953  1.23091 -1.10625 -1.03463  ...  1.230910 -1.106250 -1.034630      0\n","954         954  1.23091 -1.10625  1.23091  ... -1.034630  1.222960 -1.034630      0\n","955         955  1.23091 -1.10625  1.23091  ... -1.034630  1.222960 -1.034630      0\n","956         956  1.23091 -1.10625  1.23091  ... -1.034630  1.222960 -1.034630      0\n","957         957  1.23091  1.22296 -1.03463  ...  1.230910 -1.106250 -1.034630      0\n","\n","[958 rows x 11 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/titanic.csv\n","      Unnamed: 0        f1       f2        f3  clase\n","0              0 -1.866520 -0.22821  0.520957      1\n","1              1 -1.866520 -0.22821  0.520957      1\n","2              2 -1.866520 -0.22821  0.520957      1\n","3              3 -1.866520 -0.22821  0.520957      1\n","4              4 -1.866520 -0.22821  0.520957      1\n","...          ...       ...      ...       ...    ...\n","2196        2196  0.965424 -0.22821 -1.918670      1\n","2197        2197  0.965424 -0.22821 -1.918670      1\n","2198        2198  0.965424 -0.22821 -1.918670      0\n","2199        2199  0.965424 -0.22821 -1.918670      0\n","2200        2200  0.965424 -0.22821 -1.918670      0\n","\n","[2201 rows x 5 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/vertebral-column-2clases.csv\n","     Unnamed: 0        f1        f2  ...        f5        f6  clase\n","0             0  0.146989  0.500302  ... -1.445490 -0.706803      0\n","1             1 -1.243700 -0.747682  ... -0.263602 -0.578738      0\n","2             2  0.483492  0.467329  ... -0.895846 -0.794133      0\n","3             3  0.510760  0.710132  ... -1.205210 -0.401682      0\n","4             4 -0.625807 -0.788648  ... -0.732153 -0.489278      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","305         305 -0.730819 -0.391971  ... -0.035333 -0.813303      1\n","306         306 -0.380392  0.317451  ... -0.266605 -0.711330      1\n","307         307  0.055321  0.514291  ...  0.581894 -0.772300      1\n","308         308 -0.884566 -0.884570  ...  0.047265 -0.694556      1\n","309         309 -1.546550 -1.246280  ...  0.452742 -0.705472      1\n","\n","[310 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/vertebral-column-3clases.csv\n","     Unnamed: 0        f1        f2  ...        f5        f6  clase\n","0             0  0.146989  0.500302  ... -1.445490 -0.706803      0\n","1             1 -1.243700 -0.747682  ... -0.263602 -0.578738      0\n","2             2  0.483492  0.467329  ... -0.895846 -0.794133      0\n","3             3  0.510760  0.710132  ... -1.205210 -0.401682      0\n","4             4 -0.625807 -0.788648  ... -0.732153 -0.489278      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","305         305 -0.730819 -0.391971  ... -0.035333 -0.813303      1\n","306         306 -0.380392  0.317451  ... -0.266605 -0.711330      1\n","307         307  0.055321  0.514291  ...  0.581894 -0.772300      1\n","308         308 -0.884566 -0.884570  ...  0.047265 -0.694556      1\n","309         309 -1.546550 -1.246280  ...  0.452742 -0.705472      1\n","\n","[310 rows x 8 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/wall-following.csv\n","      Unnamed: 0        f1       f2  ...       f23       f24  clase\n","0              0 -1.287510 -1.29706  ... -0.863407 -0.999155      1\n","1              1 -1.287510 -1.29706  ... -0.861084 -0.999155      1\n","2              2 -1.287510 -1.29706  ... -0.858761 -0.999155      1\n","3              3 -1.288760 -1.29493  ... -0.860310 -0.999155      1\n","4              4 -1.287510 -1.29706  ... -0.862633 -0.999155      1\n","...          ...       ...      ...  ...       ...       ...    ...\n","5451        5451 -0.699572  1.89552  ...  2.667510 -0.014349      0\n","5452        5452 -0.679642  1.89552  ...  2.667510 -0.428958      2\n","5453        5453 -0.665940  1.89552  ...  2.667510 -0.411574      2\n","5454        5454 -0.655975  1.22325  ...  2.667510 -0.400275      0\n","5455        5455 -0.649747  1.23318  ...  2.667510 -0.356815      2\n","\n","[5456 rows x 26 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/waveform.csv\n","      Unnamed: 0        f1        f2  ...       f20       f21  clase\n","0              0 -1.222760 -1.802050  ... -0.108477 -0.540208      2\n","1              1 -0.688173  1.984760  ...  0.224444  2.448570      1\n","2              2 -0.123889 -1.213630  ... -1.061000 -0.098912      0\n","3              3  0.846283 -0.046264  ... -1.421670  1.144740      1\n","4              4  1.143270  0.029662  ... -1.070250 -0.660561      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","4995        4995 -0.648574  0.333367  ...  0.677587 -1.402740      0\n","4996        4996 -0.024892  0.314385  ... -1.301440 -0.159089      1\n","4997        4997  0.004807 -2.210160  ...  0.788561 -0.249354      1\n","4998        4998 -0.401081  0.067625  ...  0.881039  1.395470      0\n","4999        4999  0.618589 -0.387931  ... -0.321177  0.623208      1\n","\n","[5000 rows x 23 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/waveform-noise.csv\n","      Unnamed: 0        f1        f2  ...       f39       f40  clase\n","0              0 -0.211150 -1.478890  ... -0.519709  0.263329      2\n","1              1  0.398012  0.051827  ... -0.777011  0.193526      0\n","2              2 -0.670518  0.648710  ... -1.311410  0.971331      1\n","3              3  0.417985  0.340641  ... -1.608290  0.073864      0\n","4              4 -0.790353  1.216710  ...  0.925142  0.373019      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","4995        4995  0.457930  0.225116  ...  1.429850  1.081020      0\n","4996        4996  1.196910 -0.776108  ... -0.094171  0.333132      1\n","4997        4997  0.657655  0.465794  ... -0.687945 -0.873463      2\n","4998        4998  0.198287  1.274480  ... -0.905662  0.602372      0\n","4999        4999  2.065720 -2.229810  ...  0.064169  0.582429      0\n","\n","[5000 rows x 42 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/wine.csv\n","     Unnamed: 0        f1        f2  ...       f12       f13  clase\n","0             0  1.514340 -0.560668  ...  1.842720  1.010160      0\n","1             1  0.245597 -0.498009  ...  1.110320  0.962526      0\n","2             2  0.196325  0.021171  ...  0.786369  1.391220      0\n","3             3  1.686790 -0.345835  ...  1.180740  2.328010      0\n","4             4  0.294868  0.227053  ...  0.448336 -0.037768      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","173         173  0.873810  2.966180  ... -1.227740 -0.021890      2\n","174         174  0.491955  1.408640  ... -1.481270  0.009866      2\n","175         175  0.331822  1.739840  ... -1.481270  0.279786      2\n","176         176  0.208643  0.227053  ... -1.396760  0.295664      2\n","177         177  1.391160  1.578710  ... -1.424930 -0.593486      2\n","\n","[178 rows x 15 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/wine-quality-red.csv\n","      Unnamed: 0        f1        f2  ...       f10       f11  clase\n","0              0 -0.528194  0.961576  ... -0.579025 -0.959946      2\n","1              1 -0.298454  1.966830  ...  0.128910 -0.584594      2\n","2              2 -0.298454  1.296660  ... -0.048074 -0.584594      2\n","3              3  1.654340 -1.384010  ... -0.461036 -0.584594      3\n","4              4 -0.528194  0.961576  ... -0.579025 -0.959946      2\n","...          ...       ...       ...  ...       ...       ...    ...\n","1594        1594 -1.217420  0.403103  ... -0.461036  0.072271      2\n","1595        1595 -1.389720  0.123866  ...  0.600867  0.729136      3\n","1596        1596 -1.159980 -0.099523  ...  0.541872  0.541460      3\n","1597        1597 -1.389720  0.654416  ...  0.305894 -0.209243      2\n","1598        1598 -1.332290 -1.216470  ...  0.010921  0.541460      3\n","\n","[1599 rows x 13 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/wine-quality-white.csv\n","      Unnamed: 0        f1        f2  ...       f10       f11  clase\n","0              0  0.172079 -0.081762  ... -0.349149 -1.393010      3\n","1              1 -0.657434  0.215874  ...  0.001342 -0.824192      3\n","2              2  1.475600  0.017450  ... -0.436771 -0.336633      3\n","3              3  0.409083 -0.478608  ... -0.787262 -0.499152      3\n","4              4  0.409083 -0.478608  ... -0.787262 -0.499152      3\n","...          ...       ...       ...  ...       ...       ...    ...\n","4893        4893 -0.775936 -0.677032  ...  0.088964  0.557225      3\n","4894        4894 -0.301928  0.414297  ... -0.261526 -0.742932      2\n","4895        4895 -0.420430 -0.379397  ... -0.261526 -0.905451      3\n","4896        4896 -1.605450  0.116662  ... -0.962507  1.857380      4\n","4897        4897 -1.012940 -0.677032  ... -1.488240  1.044780      3\n","\n","[4898 rows x 13 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/yeast.csv\n","      Unnamed: 0        f1        f2  ...        f7        f8  clase\n","0              0  0.581785  0.888182  ... -0.344059 -0.527741      2\n","1              1 -0.510719  1.372350  ...  0.521044 -0.527741      2\n","2              2  1.018790  0.968876  ...  0.521044 -0.527741      2\n","3              3  0.581785 -0.483623  ...  0.694064 -0.527741      1\n","4              4 -0.583552 -0.483623  ... -0.344059 -0.527741      2\n","...          ...       ...       ...  ...       ...       ...    ...\n","1479        1479  2.256960  0.968876  ...  0.521044 -0.527741      4\n","1480        1480 -0.219384 -0.564317  ... -0.344059  1.819890      1\n","1481        1481  1.237290  0.565405  ...  1.040110 -0.527741      4\n","1482        1482 -0.510719 -0.806400  ...  0.521044  1.068640      1\n","1483        1483  1.091620  0.323321  ...  0.521044 -0.527741      0\n","\n","[1484 rows x 10 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/abalon.csv\n","      Unnamed: 0        f1        f2  ...        f7        f8  class\n","0              0 -1.154210 -0.574489  ... -0.726125 -0.638140      2\n","1              1 -1.154210 -1.448810  ... -1.205080 -1.212840      0\n","2              2  0.053792  0.050027  ... -0.356647 -0.207114      1\n","3              3 -1.154210 -0.699393  ... -0.607527 -0.602222      1\n","4              4  1.261790 -1.615350  ... -1.287180 -1.320600      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","4172        4172  0.053792  0.341468  ...  0.532836  0.073053      2\n","4173        4173 -1.154210  0.549640  ...  0.309325  0.155666      1\n","4174        4174 -1.154210  0.632909  ...  0.975296  0.496895      1\n","4175        4175  0.053792  0.841081  ...  0.733540  0.410690      1\n","4176        4176 -1.154210  1.548870  ...  1.787230  1.840260      2\n","\n","[4177 rows x 10 columns]\n","/content/drive/Shared drives/Machine_Learning_Project/Classification_datasets/labeled_classification_datasets/ar4.csv\n","     Unnamed: 0  total_loc  ...  formal_parameters  label\n","0             0        103  ...                  0      0\n","1             1         53  ...                  1      0\n","2             2         25  ...                  2      0\n","3             3         73  ...                  0      0\n","4             4         69  ...                  0      0\n","..          ...        ...  ...                ...    ...\n","102         102         71  ...                  0      0\n","103         103         79  ...                  0      0\n","104         104         19  ...                  2      0\n","105         105        119  ...                  0      0\n","106         106          9  ...                  0      0\n","\n","[107 rows x 31 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"A-tHJZbojos-","colab_type":"text"},"source":["###write to csv"]},{"cell_type":"code","metadata":{"id":"-wmUw9HOjoD0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590627742,"user_tz":-180,"elapsed":11762,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["# writing list of dictionaries to csv file, with first line as keys of dictionary.\n","def write_to_csv(records_dict):\n","  csv_file = results_path +\"/results.csv\"\n","  try:\n","    with open(csv_file, 'w') as csvfile:\n","      writer = csv.DictWriter(csvfile, fieldnames=records_dict[0].keys())\n","      writer.writeheader()\n","      for data in records_dict:\n","        writer.writerow(data)\n","  except IOError:\n","    print(\"I/O error\")\n"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"id":"rVq0AOjOMzwD","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597606851744,"user_tz":-180,"elapsed":67,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2CQ2zz3E3Hik","colab_type":"text"},"source":["###Label Encoder"]},{"cell_type":"code","metadata":{"id":"8BtZOIE7eNbv","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597606851744,"user_tz":-180,"elapsed":55,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def label_encode(df_name):\n","  df = data_dic[df_name]\n","  target = pd.DataFrame(df[df.columns[-1]])\n","  le = LabelEncoder()\n","  target[target.columns[0]] = le.fit_transform(target)\n","  \n","\n","  train = df.drop([df.columns[-1]], axis=1)\n","  \n","  # if all values of a feature are the same\n","  n_unique_vals = df.nunique()\n","  single_val_indexes = n_unique_vals[n_unique_vals<=1].index\n","  index_val_indexes = n_unique_vals[n_unique_vals==df.size].index\n","  # remove the feature (no information gain)\n","  df = df.drop(single_val_indexes,axis=1)\n","  df = df.drop(index_val_indexes,axis=1)\n","  \n","  for col in df.columns.values:\n","    df[col].fillna(df[df[col].notna()][col].mode()[0], inplace=True)\n","  # cf - categorical features\n","  cf = train.columns[train.applymap(lambda x: isinstance(x, str)).all(0)]\n","\n","  # print('target')\n","  # print(target.head())\n","\n","  \n","  \n","  cf_df = df[cf].copy()\n","  enc_df = pd.DataFrame([])\n","  for df_index, enc_index in StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state).split(cf_df,target):\n","    target_enc = ce.TargetEncoder(smoothing=smoothing).fit(cf_df.iloc[df_index,:],target.iloc[df_index])\n","    enc_df = enc_df.append(target_enc.transform(cf_df.iloc[enc_index,:]),ignore_index=False)\n","  target_enc = ce.TargetEncoder(smoothing=smoothing).fit(cf_df,target)\n","  cf_df = enc_df.sort_index()\n","  df[cf] = cf_df\n","  data_dic[df_name] = df\n","  df[target.columns[0]]=target\n","  print(df.head())\n","  print()\n","  print()\n","  df.to_csv(labeled_data_path+'/'+df_name)\n","\n","\n","\n","# data_dic"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B9tzZOw423me","colab_type":"text"},"source":["###Train-Test Split"]},{"cell_type":"markdown","metadata":{"id":"kuDYc4ooRESu","colab_type":"text"},"source":["##Plots"]},{"cell_type":"code","metadata":{"id":"C7STMPKuJuwW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590627742,"user_tz":-180,"elapsed":5749,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def plt_model(model_hist, model_name: str):\n","    acc = model_hist.history['accuracy']\n","    val_acc = model_hist.history['val_accuracy']\n","    loss = model_hist.history['loss']\n","    val_loss = model_hist.history['val_loss']\n","\n","    epochs = range(1, len(acc) + 1)\n","\n","    plt.figure(figsize=(15, 6))\n","    plt.subplot(121)\n","    plt.plot(epochs, acc, color='b', marker='o', linestyle='none', label='Training Accuracy')\n","    plt.plot(epochs, val_acc, color='b', label='Validation Accuracy')\n","    plt.title('Training and Validation Accuracy')\n","    plt.legend(loc='best')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","\n","    plt.subplot(122)\n","    plt.plot(epochs, loss, color='r', marker='o', linestyle='none', label='Training Loss')\n","    plt.plot(epochs, val_loss, color='r', label='Validation Loss')\n","    plt.title('Training and Validation Loss')\n","    plt.legend(loc='best')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","\n","    plt.savefig(os.path.join(dir_path, model_name + '_Accuracy_Loss.png'))\n","    plt.show()"],"execution_count":54,"outputs":[]},{"cell_type":"code","metadata":{"id":"ccuwgr7_bs6h","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597606851745,"user_tz":-180,"elapsed":47,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8DqZfwLTYdFX","colab_type":"text"},"source":["#Run Models"]},{"cell_type":"markdown","metadata":{"id":"8dlscF2mbQBh","colab_type":"text"},"source":["example of a record\n","\n","```\n","'Dataset Name': 'dataset2',\n","'Algorithm Name': 'algo2',\n","'Cross Validation': 1,\n","'Hyper-Parameters Values': 0,\n","'Accuracy': 0.9,\n","'TPR': 0.8,\n","'FPR': 0.8,\n","'Precision': 0.8,\n","'AUC': 20,\n","'PR-Curve': 15,\n","'Training Time': 300,\n","'Inference Time': 20\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"XC6DlRjB1PB4","colab_type":"text"},"source":["#AUC"]},{"cell_type":"code","metadata":{"id":"jg8tgJqo1QcT","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597606851746,"user_tz":-180,"elapsed":35,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["data_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T_o9s_oT1JjI","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597606851747,"user_tz":-180,"elapsed":26,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["\n","for df_name in data_dict:\n","  df = data_dict[df_name]\n","  y = pd.DataFrame(df[df.columns[-1]])\n","  X = df.drop([df.columns[-1]], axis=1)\n","  # Binarize the output\n","  y = label_binarize(y, classes=[0, 1, 2])\n","  n_classes = y.shape[1]\n","\n","  # Add noisy features to make the problem harder\n","  n_samples, n_features = X.shape  \n","  random_state = np.random.RandomState(0)\n","  X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n","\n","  # shuffle and split training and test sets\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n","                                                      random_state=0)\n","\n","  # Learn to predict each class against the other\n","  classifier = OneVsRestClassifier(af.RotationForestClassifier(bootstrap=True, max_depth=8, min_samples_leaf=1, min_samples_split=5,n_estimators=100, n_features_per_subset=n_features\n","                                   ,n_jobs=8, random_state=random_state))#,verbose=verbose))\n","  y_score = classifier.fit(X_train, y_train).\n","  print(y_score)\n","  # # Compute ROC curve and ROC area for each class\n","  # fpr = dict()\n","  # tpr = dict()\n","  # roc_auc = dict()\n","  # for i in range(n_classes):\n","  #     fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n","  #     roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","  # # Compute micro-average ROC curve and ROC area\n","  # fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n","  # roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n","  # print(roc_auc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3RPjPYf33G9k","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597611620210,"user_tz":-180,"elapsed":1868,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def get_metrics(test_y, pred_y, classes):\n","  \"\"\"\n","  \n","  \"\"\"\n","  n_class = len(classes)\n","  acc = accuracy_score(pred_y, test_y)\n","\n","  # if n_class==2:\n","  #   auc = roc_auc_score(test_y,pred_y)\n","  # else:\n","  #   for clase in classes:\n","  #     auc = roc_auc_score(test_y,pred_y,average='samples',multi_class='ovr', labels=clase)\n","  # precision, recall, thresholds = precision_recall_curve(test_y, pred_y)\n","\n","  # prc = auc_score(precision, recall)\n","  prc = 0\n","  auc = prc\n","  cm = confusion_matrix(test_y, pred_y)\n","\n","  fp = cm.sum(axis=0) - np.diag(cm)\n","  fn = cm.sum(axis=1) - np.diag(cm)\n","  tp = np.diag(cm)\n","  tn = cm.sum() - (fp+fn+tp)\n","\n","  tpr = tp/(tp+fn)\n","  fpr = fp/(fp+tn)\n","\n","  precision = precision_score(test_y, pred_y, average='macro')\n","\n","  return acc, tpr, fpr, precision, auc, prc"],"execution_count":328,"outputs":[]},{"cell_type":"code","metadata":{"id":"gMAjVrzEbMAJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597598859480,"user_tz":-180,"elapsed":981,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["result_list = []\n","def add_result(dataset_name, algo_name, cross_validation, hyp_param_values, acc, tpr, fpr, precision, auc, prc, training_time, inference_time):\n","  \"\"\"\n","  Params:\n","  dataset_name, algo_name, cross_validation, hyp_param_values, acc, tpr, fpr, precision, auc, prc, training_time, inference_time\n","  \"\"\"\n","  record = {'Dataset Name': dataset_name,\n","     'Algorithm Name': algo_name,\n","     'Cross Validation': cross_validation,\n","     'Hyper-Parameters Values': hyp_param_values,\n","     'Accuracy': acc,\n","     'TPR': tpr,\n","     'FPR': fpr,\n","     'Precision': precision,\n","     'AUC': auc,\n","     'PR-Curve': prc,\n","     'Training Time': training_time,\n","     'Inference Time': inference_time}\n","  result_list.append(record)"],"execution_count":230,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z3PKg4Rc1gNJ","colab_type":"text"},"source":["##Arranged Forest"]},{"cell_type":"code","metadata":{"id":"oGXEtP0GUqj4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597611629952,"user_tz":-180,"elapsed":1023,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["\n","def arranged_forest(df_name):\n","  df = data_dic[df_name]\n","  target = pd.DataFrame(df[df.columns[-1]])\n","  train = df.drop([df.columns[-1]], axis=1)\n","  print()\n","  print(df_name)\n","  print()\n","  print(df)\n","  data = np.array(df)\n","  total_num_of_features = len(df.columns)-1\n","  print(total_num_of_features)\n","  feature_per_tree = int(math.sqrt(total_num_of_features))\n","  num_feature = feature_per_tree * feature_per_tree\n","  \n","  train_arr = np.array(train).tolist()\n","  target_arr = np.array(target).tolist()\n","  classes = np.unique(target_arr)\n","\n","  # print(data)\n","  # print(feature_per_tree)\n","  \n","  xtrain, xtest, ytrain, ytest = train_test_split(train, target, test_size=test_size, random_state=random_state)\n","\n","  train_x = np.array(xtrain.values.tolist())\n","  train_y = np.array(ytrain.values.tolist())\n","  test_x = np.array(xtest.values.tolist())\n","  test_y = np.array(ytest.values.tolist())\n","\n","\n","  # if df_name=='audiology-std.csv':\n","  # print('xtrain')\n","  # print(train_x.shape)\n","  # print('ytrain')\n","  # print(train_y.shape)\n","  # print('xtest')\n","  # print(test_x.shape)\n","  # print('ytest')\n","  # print(test_y.shape)\n","  # train_x = data[:, 0:-1]\n","  # train_y = data[:, -1]\n","\n","  \n","\n","  # test_x = test[:, 0:-1]\n","  # test_y = test[:, -1]\n","\n","  start_time = time()\n","  boot_xtrain, boot_ytrain = bootstrap_samples(feature_per_tree, train_x, train_y, seed=seed)\n","\n","  feature_matrix = build_feature_matrix(num_feature=num_feature, feature_per_tree=feature_per_tree)\n","\n","  k_family_F = modified_diagonal_distribute(feature_per_tree=feature_per_tree, feature_matrix=feature_matrix)\n","\n","  # print(k_family_F)\n","\n","  arranged_clf = ControlledForestClassifier(n_estimators=feature_per_tree)\n","\n","  arranged_clf.fit(k_family_F, boot_xtrain, boot_ytrain, train_y)\n","\n","  end_time = time()\n","\n","  \n","  pred_y = arranged_clf.predict(test_x)\n","\n","  inference_time = (1000/len(pred_y))*(time()- end_time)\n","\n","  train_time=  end_time- start_time\n","\n","  # arranged_report = classification_report(test_y, predict_y, output_dict=False)\n","\n","  acc, tpr, fpr, precision, auc, prc = get_metrics(test_y, pred_y, classes)\n","\n","  add_result(df_name,'Arranged Forest', 0, arranged_clf, acc, tpr, fpr, precision, auc, prc, train_time, inference_time)\n","\n","  # print(arranged_report)"],"execution_count":329,"outputs":[]},{"cell_type":"code","metadata":{"id":"1UHexdoFEZ-E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597611640700,"user_tz":-180,"elapsed":7891,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"341dc02d-9181-404a-d3fd-164018845f90"},"source":["for dn in data_dic:\n","  arranged_forest(dn)"],"execution_count":330,"outputs":[{"output_type":"stream","text":["\n","analcatdata_lawsuit.csv\n","\n","     Unnamed: 0  Length.of.service  CAP  PA.normalized  Minority  Laid.off\n","0             0               3.17    7           3.33         1         1\n","1             1               4.47    8           3.33         1         1\n","2             2               0.69   11           4.44         1         1\n","3             3               1.52   16           1.11         1         1\n","4             4               7.43    6          13.32         1         1\n","..          ...                ...  ...            ...       ...       ...\n","259         259              10.57   60          30.00         0         0\n","260         260              14.62   60          28.89         0         0\n","261         261              26.01   59          26.67         0         0\n","262         262              15.38   60          30.00         0         0\n","263         263              21.20   59          30.00         0         0\n","\n","[264 rows x 6 columns]\n","5\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","baseball.csv\n","\n","      Unnamed: 0  Number_seasons  ...  Position  Hall_of_Fame\n","0              0              23  ...  0.174107             1\n","1              1              13  ...  0.126866             0\n","2              2              13  ...  0.171642             0\n","3              3              14  ...  0.070866             0\n","4              4              17  ...  0.224000             0\n","...          ...             ...  ...       ...           ...\n","1335        1335              11  ...  0.164045             0\n","1336        1336              19  ...  0.065502             0\n","1337        1337              12  ...  0.088710             0\n","1338        1338              13  ...  0.090226             0\n","1339        1339              13  ...  0.182232             0\n","\n","[1340 rows x 18 columns]\n","17\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","bodyfat.csv\n","\n","     Unnamed: 0  Density  Age  Weight  ...  Biceps  Forearm  Wrist  binaryClass\n","0             0   1.0708   23  154.25  ...    32.0     27.4   17.1            1\n","1             1   1.0853   22  173.25  ...    30.5     28.9   18.2            1\n","2             2   1.0414   22  154.00  ...    28.8     25.2   16.6            0\n","3             3   1.0751   26  184.75  ...    32.4     29.4   18.2            1\n","4             4   1.0340   24  184.25  ...    32.2     27.7   17.7            0\n","..          ...      ...  ...     ...  ...     ...      ...    ...          ...\n","247         247   1.0736   70  134.25  ...    25.6     25.7   18.5            1\n","248         248   1.0236   72  201.00  ...    35.2     28.6   20.1            0\n","249         249   1.0328   72  186.75  ...    31.3     27.2   18.0            0\n","250         250   1.0399   72  190.75  ...    30.5     29.4   19.8            0\n","251         251   1.0271   74  207.50  ...    33.7     30.0   20.9            0\n","\n","[252 rows x 16 columns]\n","15\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","analcatdata_asbestos.csv\n","\n","    Unnamed: 0  Ventilation  Duration  Exposure  Task\n","0            0     0.608696       184  0.717949     1\n","1            1     0.622222        30  0.107143     0\n","2            2     0.659091       116  0.037037     0\n","3            3     0.651163       133  0.725000     1\n","4            4     0.200000       184  0.107143     0\n","..         ...          ...       ...       ...   ...\n","78          78     0.613636       260  0.682927     1\n","79          79     0.172414       184  0.717949     0\n","80          80     0.156250        60  0.068966     1\n","81          81     0.200000        79  0.499638     0\n","82          82     0.622222       247  0.690476     1\n","\n","[83 rows x 5 columns]\n","4\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","analcatdata_broadwaymult.csv\n","\n","     Unnamed: 0      Show      Type  ...  Week_1_attendance     Award  Count\n","0             0  2.002473  2.000000  ...              87.13  4.309524      2\n","1             1  2.839890  1.952381  ...              87.13  1.313953      0\n","2             2  1.160110  1.953020  ...              87.13  0.390244      4\n","3             3  1.996109  2.027211  ...             100.00  4.282353      6\n","4             4  1.996109  2.027211  ...             100.00  1.310345      0\n","..          ...       ...       ...  ...                ...       ...    ...\n","280         280  1.999382  2.137931  ...              54.05  1.269231      2\n","281         281  2.000000  2.000000  ...              54.05  0.441860      2\n","282         282  1.579435  1.933333  ...              99.15  4.220930      3\n","283         283  1.579435  2.022222  ...              99.15  1.258824      3\n","284         284  2.839890  2.000000  ...              99.15  0.465909      0\n","\n","[285 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","fri_c0_250_5.csv\n","\n","     Unnamed: 0       oz1       oz2       oz3       oz4       oz5  binaryClass\n","0             0 -0.884043  0.751601  0.756124 -1.521581  0.203984            1\n","1             1 -1.516162 -0.778852 -0.935525  0.361520 -1.306545            1\n","2             2  1.276350  0.022499 -0.374163  1.502670 -0.609227            0\n","3             3  1.282011  1.030213 -0.326553 -1.538950  0.474845            1\n","4             4 -0.619048  1.560539  1.435116 -0.297633 -0.120658            0\n","..          ...       ...       ...       ...       ...       ...          ...\n","245         245 -0.502347  1.120583 -0.212220 -0.750066 -0.441486            1\n","246         246 -0.940008  0.279920  1.613556  0.631651 -0.395655            0\n","247         247 -0.368071 -0.593283 -1.434136 -0.569653  0.861619            0\n","248         248 -1.700857  0.135705 -0.857281  1.592884 -0.724478            1\n","249         249 -0.205241 -0.971258  1.566781  0.065888 -0.262271            0\n","\n","[250 rows x 7 columns]\n","6\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","diabetes.csv\n","\n","     Unnamed: 0  preg  plas  pres  skin  insu  mass   pedi  age  class\n","0             0     6   148    72    35     0  33.6  0.627   50      1\n","1             1     1    85    66    29     0  26.6  0.351   31      0\n","2             2     8   183    64     0     0  23.3  0.672   32      1\n","3             3     1    89    66    23    94  28.1  0.167   21      0\n","4             4     0   137    40    35   168  43.1  2.288   33      1\n","..          ...   ...   ...   ...   ...   ...   ...    ...  ...    ...\n","763         763    10   101    76    48   180  32.9  0.171   63      0\n","764         764     2   122    70    27     0  36.8  0.340   27      0\n","765         765     5   121    72    23   112  26.2  0.245   30      0\n","766         766     1   126    60     0     0  30.1  0.349   47      1\n","767         767     1    93    70    31     0  30.4  0.315   23      0\n","\n","[768 rows x 10 columns]\n","9\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","cloud.csv\n","\n","     Unnamed: 0    SEEDED    TE    TW    NC    SC   NWC  binaryClass\n","0             0  0.306122  1.69  3.73  1.65  1.80  3.33            0\n","1             1  0.295455  0.74  0.78  1.09  0.79  1.59            0\n","2             2  0.276596  0.81  0.86  2.39  0.36  2.06            0\n","3             3  0.291667  1.44  2.01  2.96  1.27  4.05            0\n","4             4  0.291667  2.48  4.61  4.16  2.16  6.00            0\n","..          ...       ...   ...   ...   ...   ...   ...          ...\n","103         103  0.295455  1.36  3.43  1.38  1.86  2.91            1\n","104         104  0.291667  1.17  1.65  1.22  2.28  1.58            1\n","105         105  0.295455  2.37  1.94  2.46  2.47  2.39            1\n","106         106  0.291667  0.02  0.08  0.05  0.02  0.09            1\n","107         107  0.265306  0.92  2.09  0.61  0.87  1.35            1\n","\n","[108 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","lowbwt.csv\n","\n","     Unnamed: 0  LOW  AGE  LWT  RACE  SMOKE  PTL  HT  UI  FTV  binaryClass\n","0             0    0   19  182     2      0    0   0   1    0            1\n","1             1    0   33  155     3      0    0   0   0    3            1\n","2             2    0   20  105     1      1    0   0   0    1            1\n","3             3    0   21  108     1      1    0   0   1    2            1\n","4             4    0   18  107     1      1    0   0   1    0            1\n","..          ...  ...  ...  ...   ...    ...  ...  ..  ..  ...          ...\n","184         184    1   28   95     1      1    0   0   0    2            1\n","185         185    1   14  100     3      0    0   0   0    2            1\n","186         186    1   23   94     3      1    0   0   0    0            1\n","187         187    1   17  142     2      0    0   1   0    0            1\n","188         188    1   21  130     1      1    0   1   0    3            1\n","\n","[189 rows x 11 columns]\n","10\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","diggle_table_a2.csv\n","\n","     Unnamed: 0  col_1  col_2  col_3  ...   col_6   col_7   col_8  binaryClass\n","0             0     76     33     33  ...  1.1718  5.5683  5.7268            1\n","1             1     76     34     34  ...  1.1815  5.5568  5.7236            1\n","2             2     76     35     35  ...  1.1907  5.5491  5.7236            1\n","3             3     76     36     36  ...  1.1679  5.5683  5.7236            1\n","4             4     76     37     37  ...  1.1591  5.5759  5.7236            1\n","..          ...    ...    ...    ...  ...     ...     ...     ...          ...\n","305         305     84     20    436  ...  1.5879  6.2046  6.6670            0\n","306         306     84     21    437  ...  1.5879  6.2046  6.6670            0\n","307         307     84     22    438  ...  1.5815  6.2086  6.6670            0\n","308         308     84     25    441  ...  1.5847  6.2066  6.6670            0\n","309         309     84     26    442  ...  1.5752  6.2126  6.6670            0\n","\n","[310 rows x 10 columns]\n","9\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","chatfield_4.csv\n","\n","     Unnamed: 0  col_1  col_2  col_3  ...  col_10  col_11  col_12  binaryClass\n","0             0   1749   58.0   62.6  ...    75.9    75.5   158.6            0\n","1             1   1750   73.3   75.9  ...    91.2    65.7    63.3            0\n","2             2   1751   70.0   43.5  ...    23.5    23.2    28.5            1\n","3             3   1752   35.0   50.0  ...    27.1    46.6    37.6            1\n","4             4   1753   44.0   32.0  ...    28.0    25.0    20.0            1\n","..          ...    ...    ...    ...  ...     ...     ...     ...          ...\n","230         230   1979  166.6  137.5  ...   188.4   186.2   183.3            0\n","231         231   1980  159.6  155.0  ...   155.0   164.7   147.9            0\n","232         232   1981  114.0  141.3  ...   167.3   162.4   137.5            0\n","233         233   1982  111.2  163.6  ...   118.8    94.7    98.1            0\n","234         234   1983   84.3   51.0  ...    50.3    55.8    33.3            1\n","\n","[235 rows x 14 columns]\n","13\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","no2.csv\n","\n","     Unnamed: 0  no2_concentration  ...  hour_of_day  binaryClass\n","0             0            3.71844  ...           20            0\n","1             1            3.10009  ...           14            1\n","2             2            3.31419  ...            4            0\n","3             3            4.38826  ...           23            1\n","4             4            4.34640  ...           11            1\n","..          ...                ...  ...          ...          ...\n","495         495            4.30946  ...           11            1\n","496         496            2.94444  ...           10            1\n","497         497            4.17439  ...           14            1\n","498         498            2.95491  ...            7            0\n","499         499            4.03247  ...           17            1\n","\n","[500 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","disclosure_z.csv\n","\n","     Unnamed: 0       Age      Civil     Can/US  binaryClass\n","0             0  31.00364  23.266880   7.230798            0\n","1             1  58.36153  17.760060   4.480846            1\n","2             2  49.43488  14.583990   7.632419            0\n","3             3  40.87560  16.545360   9.448964            0\n","4             4  30.38650  14.092690  10.828120            0\n","..          ...       ...        ...        ...          ...\n","657         657  71.77202  19.986267   5.172107            0\n","658         658  63.04903  12.468170   6.701814            0\n","659         659  36.01423  10.861040   9.542739            1\n","660         660  51.99702  22.303720   8.912320            0\n","661         661  59.85363  25.385640   8.548289            0\n","\n","[662 rows x 5 columns]\n","4\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","kidney.csv\n","\n","    Unnamed: 0  patient  time  status  age       sex  disease_type  binaryClass\n","0            0        1     8       1   28  0.352941      0.545455            0\n","1            1        1    16       1   28  0.437500      0.571429            0\n","2            2        2    23       1   48  0.568627      0.625000            0\n","3            3        2    13       0   48  0.560000      0.588235            0\n","4            4        3    22       1   32  0.444444      0.560000            0\n","..         ...      ...   ...     ...  ...       ...           ...          ...\n","71          71       36    16       0   42  0.580000      0.500000            1\n","72          72       37     6       0   52  0.571429      0.333380            0\n","73          73       37    78       1   52  0.591837      0.285725            0\n","74          74       38    63       1   60  0.437500      0.285725            0\n","75          75       38     8       0   60  0.388889      0.285725            0\n","\n","[76 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","lupus.csv\n","\n","    Unnamed: 0  TIME  DURATION  LOG(1+DURATION)  STATUS\n","0            0   157       1.0             0.69       0\n","1            1   268      10.0             2.40       0\n","2            2   209       2.0             1.10       1\n","3            3   134       0.1             0.10       0\n","4            4    21       0.1             0.10       1\n","..         ...   ...       ...              ...     ...\n","82          82     4      34.0             3.56       1\n","83          83    65       0.1             0.10       1\n","84          84    62       8.0             2.20       1\n","85          85    89       0.1             0.10       0\n","86          86    44      77.0             4.36       1\n","\n","[87 rows x 5 columns]\n","4\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","kc3.csv\n","\n","     Unnamed: 0  LOC_BLANK  BRANCH_COUNT  ...  PERCENT_COMMENTS  LOC_TOTAL  c\n","0             0          0             1  ...              0.00          3  0\n","1             1          1             5  ...              0.00         11  0\n","2             2          0             1  ...              0.00          3  0\n","3             3          0             1  ...              0.00          3  0\n","4             4          5            18  ...              3.33         58  0\n","..          ...        ...           ...  ...               ...        ... ..\n","453         453          1             8  ...              0.00         24  0\n","454         454          2             1  ...              8.33         11  0\n","455         455          7            12  ...              2.78         36  0\n","456         456          1             1  ...              0.00          4  0\n","457         457         22            43  ...              9.86        131  0\n","\n","[458 rows x 41 columns]\n","40\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","pm10.csv\n","\n","     Unnamed: 0  pm10_concentration  ...  hour_of_day  binaryClass\n","0             0             3.66356  ...           19            1\n","1             1             3.04452  ...            9            0\n","2             2             3.71357  ...            3            1\n","3             3             2.94444  ...           22            1\n","4             4             4.06044  ...            7            1\n","..          ...                 ...  ...          ...          ...\n","495         495             2.30259  ...            1            0\n","496         496             4.11087  ...           10            1\n","497         497             3.40120  ...           24            1\n","498         498             3.68888  ...           19            1\n","499         499             4.17439  ...           15            0\n","\n","[500 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","meta.csv\n","\n","     Unnamed: 0  DS_Name    T    N  ...    EnAtr  NSRatio  Alg_Name  binaryClass\n","0             0      1.0  690  690  ...  8.77168  19.3646  0.952381            1\n","1             1      1.0  690  690  ...  8.77168  19.3646  0.952381            1\n","2             2      1.0  690  690  ...  8.77168  19.3646  0.904762            1\n","3             3      1.0  690  690  ...  8.77168  19.3646  0.842105            1\n","4             4      1.0  690  690  ...  8.77168  19.3646  1.000000            1\n","..          ...      ...  ...  ...  ...      ...      ...       ...          ...\n","523         523      1.0  846  846  ...  5.64698  11.0045  0.950000            1\n","524         524      1.0  846  846  ...  5.64698  11.0045  1.000000            1\n","525         525      1.0  846  846  ...  5.64698  11.0045  0.944444            1\n","526         526      1.0  846  846  ...  5.64698  11.0045  1.000000            1\n","527         527      1.0  846  846  ...  5.64698  11.0045  1.000000            1\n","\n","[528 rows x 23 columns]\n","22\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","newton_hema.csv\n","\n","     Unnamed: 0        id  weeks  cells_percentage  binaryClass\n","0             0  0.562500   11.0                33            0\n","1             1  0.500000   13.0                49            1\n","2             2  0.500000   19.0                46            1\n","3             3  0.500000   25.0                42            1\n","4             4  0.500000   28.0                68            1\n","..          ...       ...    ...               ...          ...\n","135         135  0.999364  142.0                32            0\n","136         136  0.982777    0.0                58            1\n","137         137  0.982777   15.0                58            1\n","138         138  0.982777   91.0                48            1\n","139         139  0.982777   95.0                51            1\n","\n","[140 rows x 5 columns]\n","4\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","mfeat-karhunen.csv\n","\n","      Unnamed: 0       att1       att2  ...     att63     att64  class\n","0              0 -10.297008 -11.666789  ... -1.351353 -0.473910      0\n","1              1  -5.036009 -12.885333  ...  0.642451  0.613107      0\n","2              2  -9.639157  -6.655898  ...  0.827182 -1.767840      0\n","3              3  -6.650375  -7.043851  ... -0.771735  0.304992      0\n","4              4 -10.664524 -10.974133  ... -0.943213  1.149847      0\n","...          ...        ...        ...  ...       ...       ...    ...\n","1995        1995  -2.415248  -6.619806  ... -0.068411 -1.049052      9\n","1996        1996   5.892684  -8.185875  ...  0.925637  1.798053      9\n","1997        1997   1.881613  -9.650881  ...  0.287013 -0.420793      9\n","1998        1998  -1.530886 -10.183775  ...  0.435514 -0.225426      9\n","1999        1999  11.251634  -5.959691  ...  0.763971  0.040369      9\n","\n","[2000 rows x 66 columns]\n","65\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","elusage.csv\n","\n","    Unnamed: 0  average_temperature  month  binaryClass\n","0            0                   73      8            1\n","1            1                   67      9            1\n","2            2                   57     10            1\n","3            3                   43     11            0\n","4            4                   26     12            0\n","5            5                   41      1            0\n","6            6                   38      2            0\n","7            7                   46      3            0\n","8            8                   54      4            0\n","9            9                   60      5            1\n","10          10                   71      6            1\n","11          11                   75      7            1\n","12          12                   74      8            1\n","13          13                   66      9            1\n","14          14                   61     10            1\n","15          15                   49     11            0\n","16          16                   41     12            0\n","17          17                   35      1            0\n","18          18                   41      2            0\n","19          19                   42      3            1\n","20          20                   56      4            1\n","21          21                   69      5            1\n","22          22                   73      6            1\n","23          23                   77      7            1\n","24          24                   74      8            1\n","25          25                   66      9            1\n","26          26                   56     10            1\n","27          27                   47     11            1\n","28          28                   38     12            0\n","29          29                   34      1            0\n","30          30                   37      2            0\n","31          31                   39      3            0\n","32          32                   51      4            0\n","33          33                   60      5            1\n","34          34                   70      6            1\n","35          35                   73      7            1\n","36          36                   71      8            1\n","37          37                   66      9            1\n","38          38                   54     10            0\n","39          39                   45     11            0\n","40          40                   36     12            0\n","41          41                   34      1            0\n","42          42                   32      2            0\n","43          43                   39      3            0\n","44          44                   55      4            1\n","45          45                   64      5            1\n","46          46                   72      6            1\n","47          47                   79      7            1\n","48          48                   75      8            1\n","49          49                   65      9            1\n","50          50                   54     10            1\n","51          51                   48     11            1\n","52          52                   35     12            0\n","53          53                   24      1            0\n","54          54                   32      2            0\n","3\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","schizo.csv\n","\n","     Unnamed: 0   ID    target  ...  gain_ratio_11       sex  class\n","0             0    7  0.477778  ...          0.883  0.358974      0\n","1             1    7  0.461111  ...          0.879  0.349593      0\n","2             2    7  0.500000  ...          0.795  0.368000      0\n","3             3    7  0.462963  ...          0.722  0.358974      0\n","4             4    7  0.483516  ...          0.845  0.352459      0\n","..          ...  ...       ...  ...            ...       ...    ...\n","335         335  275  0.438596  ...          0.745  0.559322      1\n","336         336  276  0.480447  ...          0.637  0.559140      1\n","337         337  276  0.470588  ...          0.828  0.559783      1\n","338         338  276  0.477273  ...          0.937  0.552486      1\n","339         339  276  0.448276  ...          0.766  0.552486      1\n","\n","[340 rows x 16 columns]\n","15\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","squash-unstored.csv\n","\n","    Unnamed: 0      site  ...  heat_input_flower  Acceptability\n","0            0  1.428571  ...                332              2\n","1            1  1.428571  ...                332              1\n","2            2  1.400000  ...                332              2\n","3            3  1.428571  ...                332              1\n","4            4  1.384615  ...                442              2\n","5            5  1.428571  ...                442              2\n","6            6  1.357143  ...                442              2\n","7            7  1.384615  ...                442              1\n","8            8  1.357143  ...                531              2\n","9            9  1.533333  ...                531              0\n","10          10  1.400000  ...                531              2\n","11          11  1.384615  ...                531              2\n","12          12  1.500000  ...                612              2\n","13          13  1.500000  ...                612              0\n","14          14  1.500000  ...                612              2\n","15          15  1.500000  ...                612              0\n","16          16  1.285714  ...                342              1\n","17          17  1.307692  ...                342              1\n","18          18  1.230769  ...                342              1\n","19          19  1.214286  ...                342              1\n","20          20  1.266667  ...                393              1\n","21          21  1.266667  ...                393              1\n","22          22  1.266667  ...                393              1\n","23          23  1.230769  ...                393              1\n","24          24  1.307692  ...                446              2\n","25          25  1.307692  ...                446              0\n","26          26  1.230769  ...                446              2\n","27          27  1.153846  ...                446              1\n","28          28  1.214286  ...                508              2\n","29          29  1.285714  ...                508              1\n","30          30  1.153846  ...                508              2\n","31          31  1.153846  ...                508              2\n","32          32  1.437500  ...                260              2\n","33          33  1.437500  ...                260              1\n","34          34  1.500000  ...                260              2\n","35          35  1.444444  ...                260              2\n","36          36  1.473684  ...                310              1\n","37          37  1.470588  ...                310              1\n","38          38  1.444444  ...                310              1\n","39          39  1.500000  ...                310              1\n","40          40  1.500000  ...                366              1\n","41          41  1.473684  ...                366              1\n","42          42  1.500000  ...                366              1\n","43          43  1.437500  ...                366              2\n","44          44  1.388889  ...                379              2\n","45          45  1.437500  ...                379              1\n","46          46  1.421053  ...                379              2\n","47          47  1.444444  ...                379              1\n","48          48  1.470588  ...                438              1\n","49          49  1.470588  ...                438              2\n","50          50  1.444444  ...                438              2\n","51          51  1.388889  ...                438              2\n","\n","[52 rows x 25 columns]\n","24\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","plasma_retinol.csv\n","\n","     Unnamed: 0  AGE       SEX  ...  RETDIET  BETAPLASMA  binaryClass\n","0             0   64  0.601660  ...      890         200            0\n","1             1   76  0.607287  ...      451         124            0\n","2             2   38  0.605691  ...      660         328            0\n","3             3   40  0.601660  ...      864         153            0\n","4             4   72  0.595918  ...     1209          92            0\n","..          ...  ...       ...  ...      ...         ...          ...\n","310         310   46  0.601626  ...     1261         164            1\n","311         311   45  0.607287  ...      465          80            1\n","312         312   49  0.600806  ...      520         300            1\n","313         313   31  0.600806  ...      644         121            0\n","314         314   45  0.595918  ...      554         233            0\n","\n","[315 rows x 15 columns]\n","14\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","rmftsa_sleepdata.csv\n","\n","      Unnamed: 0  heart_rate  sleep_state  binaryClass\n","0              0         152            4            0\n","1              1         156            4            0\n","2              2         147            4            0\n","3              3         145            4            0\n","4              4         129            4            0\n","...          ...         ...          ...          ...\n","1019        1019         180            4            0\n","1020        1020         174            4            0\n","1021        1021         153            4            0\n","1022        1022         175            4            0\n","1023        1023         161            4            0\n","\n","[1024 rows x 4 columns]\n","3\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","mfeat-morphological.csv\n","\n","      Unnamed: 0  att1  att2  ...      att5         att6  binaryClass\n","0              0     1     0  ...  1.311693  1620.221779            1\n","1              1     1     0  ...  1.302745  1609.334822            1\n","2              2     1     0  ...  1.319031  1568.978435            1\n","3              3     1     0  ...  1.270878  1695.055281            1\n","4              4     1     0  ...  1.329637  1647.720235            1\n","...          ...   ...   ...  ...       ...          ...          ...\n","1995        1995     1     1  ...  1.655794  5326.025889            0\n","1996        1996     1     1  ...  1.620345  5243.267754            0\n","1997        1997     1     1  ...  1.541987  3766.763222            0\n","1998        1998     1     1  ...  1.426381  4118.327320            0\n","1999        1999     1     1  ...  1.564621  3808.021317            0\n","\n","[2000 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","prnn_synth.csv\n","\n","     Unnamed: 0        xs        ys  yc\n","0             0  0.051008  0.160862   0\n","1             1 -0.748074  0.089040   0\n","2             2 -0.772934  0.263172   0\n","3             3  0.218374  0.127061   0\n","4             4  0.372683  0.496562   0\n","..          ...       ...       ...  ..\n","245         245  0.268878  0.445592   1\n","246         246 -0.492549  1.014434   1\n","247         247  0.076160  0.637952   1\n","248         248  0.492262  0.468762   1\n","249         249 -0.402496  0.713011   1\n","\n","[250 rows x 4 columns]\n","3\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","solar-flare.csv\n","\n","      Unnamed: 0  ...  X-class_flares_production_by_this_region\n","0              0  ...                                         0\n","1              1  ...                                         0\n","2              2  ...                                         0\n","3              3  ...                                         0\n","4              4  ...                                         0\n","...          ...  ...                                       ...\n","1061        1061  ...                                         0\n","1062        1062  ...                                         0\n","1063        1063  ...                                         0\n","1064        1064  ...                                         0\n","1065        1065  ...                                         0\n","\n","[1066 rows x 13 columns]\n","12\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","socmob.csv\n","\n","      Unnamed: 0  ...  binaryClass\n","0              0  ...            0\n","1              1  ...            0\n","2              2  ...            0\n","3              3  ...            1\n","4              4  ...            1\n","...          ...  ...          ...\n","1151        1151  ...            1\n","1152        1152  ...            1\n","1153        1153  ...            1\n","1154        1154  ...            1\n","1155        1155  ...            1\n","\n","[1156 rows x 7 columns]\n","6\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","squash-stored.csv\n","\n","    Unnamed: 0      site  daf  ...  heat_input_emerg  heat_input_flower  binaryClass\n","0            0  0.642857   30  ...               847                458            1\n","1            1  0.642857   30  ...               721                458            1\n","2            2  0.642857   30  ...               847                458            0\n","3            3  0.642857   30  ...               847                458            0\n","4            4  0.642857   40  ...               968                568            0\n","5            5  0.538462   40  ...               968                568            1\n","6            6  0.642857   40  ...               968                568            1\n","7            7  0.642857   40  ...               968                568            0\n","8            8  0.642857   50  ...              1087                531            1\n","9            9  0.642857   50  ...              1087                657            0\n","10          10  0.642857   50  ...              1087                657            0\n","11          11  0.642857   50  ...              1087                657            1\n","12          12  0.538462   60  ...              1023                738            1\n","13          13  0.600000   60  ...              1023                738            1\n","14          14  0.642857   60  ...              1023                738            1\n","15          15  0.538462   60  ...              1023                738            1\n","16          16  0.500000   30  ...               797                468            0\n","17          17  0.571429   30  ...               797                468            0\n","18          18  0.461538   30  ...               797                468            0\n","19          19  0.571429   30  ...               797                468            0\n","20          20  0.500000   40  ...               860                519            0\n","21          21  0.500000   40  ...               860                519            1\n","22          22  0.533333   40  ...               860                519            0\n","23          23  0.466667   40  ...               860                519            1\n","24          24  0.461538   50  ...               923                572            0\n","25          25  0.461538   50  ...               923                572            1\n","26          26  0.461538   50  ...               923                572            1\n","27          27  0.466667   50  ...               923                572            1\n","28          28  0.500000   60  ...              1000                634            1\n","29          29  0.461538   60  ...              1000                634            1\n","30          30  0.461538   60  ...              1000                634            1\n","31          31  0.533333   60  ...              1000                634            0\n","32          32  0.250000   30  ...               798                386            0\n","33          33  0.263158   30  ...               798                386            0\n","34          34  0.263158   30  ...               798                386            0\n","35          35  0.277778   30  ...               798                386            0\n","36          36  0.263158   40  ...               822                436            0\n","37          37  0.277778   40  ...               822                436            0\n","38          38  0.250000   40  ...               822                436            0\n","39          39  0.166667   40  ...               822                436            1\n","40          40  0.250000   50  ...               863                492            0\n","41          41  0.222222   50  ...               863                492            0\n","42          42  0.250000   50  ...               863                492            0\n","43          43  0.250000   50  ...               863                492            0\n","44          44  0.277778   60  ...               900                505            0\n","45          45  0.277778   60  ...               900                505            0\n","46          46  0.250000   60  ...               900                505            0\n","47          47  0.263158   60  ...               900                505            0\n","48          48  0.222222   70  ...               905                564            1\n","49          49  0.250000   70  ...               905                564            1\n","50          50  0.250000   70  ...               905                564            1\n","51          51  0.166667   70  ...               905                564            1\n","\n","[52 rows x 26 columns]\n","25\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","sleuth_case2002.csv\n","\n","     Unnamed: 0  FM  LC  BK  SS  AG  YR  binaryClass\n","0             0   0   1   1   0  59  39            0\n","1             1   0   0   0   0  61  42            1\n","2             2   0   0   1   0  59  36            1\n","3             3   1   1   1   0  60  38            1\n","4             4   1   0   1   0  60  36            0\n","..          ...  ..  ..  ..  ..  ..  ..          ...\n","142         142   0   0   1   0  52  28            0\n","143         143   0   0   1   1  52  30            0\n","144         144   0   1   0   1  43  19            1\n","145         145   0   0   0   0  43  25            0\n","146         146   0   0   0   1  42  17            1\n","\n","[147 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","schlvote.csv\n","\n","    Unnamed: 0  vote  tax_rate  ...  budget_change  tax_rate_change  binaryClass\n","0            0     1     47.18  ...            4.0             6.30            1\n","1            1     1     21.64  ...            3.3             4.10            1\n","2            2     1     24.05  ...            3.4             2.50            1\n","3            3     1     20.93  ...            9.4             7.50            1\n","4            4     1     19.32  ...           11.1             5.20            1\n","5            5     1     26.20  ...            4.5            -0.23            1\n","6            6     1     20.09  ...            4.7             1.70            1\n","7            7     0     42.16  ...            5.9             4.90            1\n","8            8     1     29.11  ...            3.0             3.50            0\n","9            9     0     45.96  ...            3.8             3.70            1\n","10          10     1     21.56  ...            1.9             3.80            1\n","11          11     1     15.55  ...            6.6             8.10            1\n","12          12     1     23.77  ...            6.0             8.10            1\n","13          13     1     27.64  ...            4.8             7.50            1\n","14          14     0     28.12  ...            8.9             7.70            0\n","15          15     0     36.74  ...            3.6             5.30            1\n","16          16     1     40.48  ...            0.0             1.90            1\n","17          17     1     21.83  ...            5.5             4.00            1\n","18          18     1     20.05  ...            8.3            10.40            1\n","19          19     1     20.86  ...            4.4             4.50            1\n","20          20     1     19.99  ...            2.9             3.50            1\n","21          21     1     11.74  ...            4.3             4.40            0\n","22          22     1     17.71  ...            4.9             3.60            0\n","23          23     1      6.35  ...            1.9             4.60            1\n","24          24     1     41.79  ...            4.2             4.50            1\n","25          25     1     28.25  ...            5.0             6.20            1\n","26          26     0     36.18  ...            4.6             5.90            0\n","27          27     1     80.70  ...            4.8             6.60            1\n","28          28     0     99.56  ...            7.4             8.60            1\n","29          29     0     87.97  ...            9.9            29.30            1\n","30          30     1     71.57  ...           -0.2            -0.20            1\n","31          31     1     87.53  ...            4.0             3.80            1\n","32          32     1      5.07  ...           18.9             1.60            0\n","33          33     1      7.71  ...            3.5             4.90            1\n","34          34     1     15.49  ...            5.9            17.50            0\n","35          35     1     13.40  ...            6.6             4.70            0\n","36          36     1     28.07  ...            4.8             3.80            0\n","37          37     0     30.23  ...            9.6             7.00            0\n","\n","[38 rows x 7 columns]\n","6\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","tae.csv\n","\n","     Unnamed: 0  ...  binaryClass\n","0             0  ...            1\n","1             1  ...            1\n","2             2  ...            1\n","3             3  ...            1\n","4             4  ...            1\n","..          ...  ...          ...\n","146         146  ...            0\n","147         147  ...            0\n","148         148  ...            0\n","149         149  ...            0\n","150         150  ...            0\n","\n","[151 rows x 7 columns]\n","6\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","teachingAssistant.csv\n","\n","     Unnamed: 0  EnglishSepaker  courseInstructor  ...  summer  classSize  class\n","0             0               1                23  ...       1         19      2\n","1             1               2                15  ...       1         17      2\n","2             2               1                23  ...       2         49      2\n","3             3               1                 5  ...       2         33      2\n","4             4               2                 7  ...       2         55      2\n","..          ...             ...               ...  ...     ...        ...    ...\n","146         146               2                 3  ...       2         26      0\n","147         147               2                10  ...       2         12      0\n","148         148               1                18  ...       2         48      0\n","149         149               2                22  ...       2         51      0\n","150         150               2                 2  ...       2         27      0\n","\n","[151 rows x 7 columns]\n","6\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","rabe_131.csv\n","\n","    Unnamed: 0  col_1  col_2  col_3  col_4  col_5  binaryClass\n","0            0      1    508    235   3944    325            1\n","1            1      2    564    231   4578    323            1\n","2            2      3    322    270   4011    328            1\n","3            3      4    846    261   5233    305            1\n","4            4      5    871    300   4780    303            1\n","5            5      6    774    317   5889    307            1\n","6            6      7    856    387   5663    301            1\n","7            7      8    889    285   5759    310            1\n","8            8      9    715    300   4894    300            1\n","9            9     10    753    221   5012    324            1\n","10          10     11    649    264   4908    329            1\n","11          11     12    830    308   5753    320            1\n","12          12     13    738    379   5439    337            1\n","13          13     14    659    342   4634    328            1\n","14          14     15    664    378   4921    330            1\n","15          15     16    572    232   4869    318            1\n","16          16     17    701    231   4672    309            1\n","17          17     18    443    246   4782    333            1\n","18          18     19    446    230   4296    330            1\n","19          19     20    615    268   4827    318            1\n","20          20     21    661    337   5057    304            1\n","21          21     22    772    344   5540    328            0\n","22          22     23    766    330   5331    323            0\n","23          23     24    631    261   4715    317            0\n","24          24     25    390    214   3828    310            0\n","25          25     26    450    245   4120    321            0\n","26          26     27    476    233   3817    342            0\n","27          27     28    603    250   4243    339            0\n","28          28     29    805    243   4647    287            0\n","29          29     30    523    216   3967    325            0\n","30          30     31    588    212   3946    315            0\n","31          31     32    584    208   3724    332            0\n","32          32     33    445    215   3448    358            0\n","33          33     34    500    221   3680    320            0\n","34          34     35    661    244   3825    355            0\n","35          35     36    680    234   4189    306            0\n","36          36     37    797    269   4336    335            0\n","37          37     38    534    302   4418    335            0\n","38          38     39    541    268   4323    344            0\n","39          39     40    605    323   4813    331            0\n","40          40     41    785    304   5046    324            0\n","41          41     42    698    317   3764    366            0\n","42          42     43    796    332   4504    340            0\n","43          43     44    804    315   4005    378            0\n","44          44     45    809    291   5560    330            0\n","45          45     46    726    312   4989    313            0\n","46          46     47    671    316   4697    305            0\n","47          47     48    909    332   5438    307            0\n","48          48     49    484    546   5613    386            0\n","49          49     50    831    311   5309    333            0\n","6\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","visualizing_livestock.csv\n","\n","     Unnamed: 0  livestocktype   country  binaryClass\n","0             0       0.909091  0.998684            1\n","1             1       0.958333  0.993523            1\n","2             2       0.916667  0.750415            1\n","3             3       0.913043  0.750358            1\n","4             4       0.913043  0.750358            1\n","..          ...            ...       ...          ...\n","125         125       0.875000  0.998684            1\n","126         126       0.916667  0.750358            0\n","127         127       0.956522  0.671672            0\n","128         128       0.956522  0.253761            0\n","129         129       0.875000  0.671672            1\n","\n","[130 rows x 4 columns]\n","3\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","veteran.csv\n","\n","     Unnamed: 0  treatment  celltype  status  ...  months  age  therapy  binaryClass\n","0             0          1         1       1  ...       7   69        0            1\n","1             1          1         1       1  ...       5   64       10            0\n","2             2          1         1       1  ...       3   38        0            0\n","3             3          1         1       1  ...       9   63       10            0\n","4             4          1         1       1  ...      11   65       10            1\n","..          ...        ...       ...     ...  ...     ...  ...      ...          ...\n","132         132          2         4       1  ...       1   65        0            0\n","133         133          2         4       1  ...       5   64        0            1\n","134         134          2         4       1  ...      18   67       10            0\n","135         135          2         4       1  ...       4   65        0            0\n","136         136          2         4       1  ...       3   37        0            1\n","\n","[137 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","transplant.csv\n","\n","     Unnamed: 0       e   z  binaryClass\n","0             0   0.057   0            1\n","1             1   0.064   0            1\n","2             2   0.064   0            1\n","3             3   0.066   1            1\n","4             4   0.462   0            1\n","..          ...     ...  ..          ...\n","126         126   7.002   3            0\n","127         127   7.851   9            0\n","128         128   9.573   7            0\n","129         129  12.050  18            0\n","130         130  12.131  17            0\n","\n","[131 rows x 4 columns]\n","3\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","triazines.csv\n","\n","     Unnamed: 0  p1_polar  p1_size  ...  p6_sigma  p6_branch  binaryClass\n","0             0      0.58    0.233  ...     0.633      0.633            0\n","1             1      0.10    0.100  ...     0.100      0.100            1\n","2             2      0.26    0.100  ...     0.100      0.100            0\n","3             3      0.42    0.500  ...     0.100      0.100            0\n","4             4      0.58    0.233  ...     0.100      0.100            0\n","..          ...       ...      ...  ...       ...        ...          ...\n","181         181      0.58    0.233  ...     0.900      0.100            0\n","182         182      0.58    0.233  ...     0.633      0.633            0\n","183         183      0.42    0.767  ...     0.100      0.100            1\n","184         184      0.26    0.100  ...     0.100      0.100            0\n","185         185      0.26    0.100  ...     0.633      0.633            1\n","\n","[186 rows x 60 columns]\n","59\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","vote.csv\n","\n","     Unnamed: 0  ...  Class\n","0             0  ...      1\n","1             1  ...      1\n","2             2  ...      0\n","3             3  ...      0\n","4             4  ...      0\n","..          ...  ...    ...\n","430         430  ...      1\n","431         431  ...      0\n","432         432  ...      1\n","433         433  ...      1\n","434         434  ...      1\n","\n","[435 rows x 18 columns]\n","17\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","white-clover.csv\n","\n","    Unnamed: 0    strata      plot  ...  Weeds-94  strata-combined  binaryClass\n","0            0  0.285729  0.833333  ...      8.33                1            0\n","1            1  0.999997  0.631579  ...     50.00                1            1\n","2            2  0.999982  0.578947  ...     11.76                1            1\n","3            3  0.714281  0.750000  ...     16.67                1            1\n","4            4  0.749999  0.631579  ...     30.33                4            1\n","..         ...       ...       ...  ...       ...              ...          ...\n","58          58  0.285728  0.777778  ...     22.78                4            1\n","59          59  0.375002  0.722222  ...      9.15                4            1\n","60          60  0.285728  0.722222  ...      3.85                1            1\n","61          61  0.500001  0.833333  ...     27.96                4            0\n","62          62  0.285729  0.833333  ...      2.17                1            1\n","\n","[63 rows x 33 columns]\n","32\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","acute-inflammation.csv\n","\n","     Unnamed: 0       f1        f2  ...        f5        f6  clase\n","0             0 -1.77236 -0.562162  ... -0.979364 -0.841625      0\n","1             1 -1.55248 -0.562162  ...  1.012560  1.178280      1\n","2             2 -1.55248 -0.562162  ... -0.979364 -0.841625      0\n","3             3 -1.49751 -0.562162  ...  1.012560  1.178280      1\n","4             4 -1.49751 -0.562162  ... -0.979364 -0.841625      0\n","..          ...      ...       ...  ...       ...       ...    ...\n","115         115  1.47094 -0.562162  ... -0.979364  1.178280      0\n","116         116  1.52591 -0.562162  ... -0.979364 -0.841625      0\n","117         117  1.52591  1.764020  ...  1.012560 -0.841625      0\n","118         118  1.52591 -0.562162  ... -0.979364  1.178280      0\n","119         119  1.52591 -0.562162  ... -0.979364  1.178280      0\n","\n","[120 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","acute-nephritis.csv\n","\n","     Unnamed: 0       f1        f2  ...        f6        f7  clase\n","0             0 -1.77236 -0.562162  ... -0.841625 -0.979364      0\n","1             1 -1.55248 -0.562162  ...  1.178280  1.012560      0\n","2             2 -1.55248 -0.562162  ... -0.841625 -0.979364      0\n","3             3 -1.49751 -0.562162  ...  1.178280  1.012560      0\n","4             4 -1.49751 -0.562162  ... -0.841625 -0.979364      0\n","..          ...      ...       ...  ...       ...       ...    ...\n","115         115  1.47094 -0.562162  ...  1.178280 -0.979364      1\n","116         116  1.52591 -0.562162  ... -0.841625 -0.979364      0\n","117         117  1.52591  1.764020  ... -0.841625 -0.979364      1\n","118         118  1.52591 -0.562162  ...  1.178280 -0.979364      1\n","119         119  1.52591 -0.562162  ...  1.178280 -0.979364      1\n","\n","[120 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","annealing.csv\n","\n","     Unnamed: 0            f1        f2  ...       f30           f31  clase\n","0             0 -2.234250e-01 -0.205931  ... -0.220071 -1.040750e-01      2\n","1             1 -2.234250e-01 -0.871245  ... -0.220071 -1.040750e-01      2\n","2             2 -2.234250e-01 -0.871245  ... -0.220071 -1.040750e-01      2\n","3             3 -2.234250e-01 -0.205931  ... -0.220071 -1.040750e-01      2\n","4             4 -2.234250e-01 -0.205931  ... -0.220071 -1.040750e-01      2\n","..          ...           ...       ...  ...       ...           ...    ...\n","893         893 -3.730000e-16 -0.750000  ... -1.000000 -1.560000e-17      1\n","894         894 -3.730000e-16 -0.750000  ... -1.000000 -1.560000e-17      1\n","895         895 -3.730000e-16  1.000000  ... -1.000000 -1.560000e-17      1\n","896         896 -3.730000e-16 -0.500000  ... -1.000000 -1.560000e-17      4\n","897         897 -3.730000e-16 -0.500000  ... -0.333333 -1.560000e-17      4\n","\n","[898 rows x 33 columns]\n","32\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","balance-scale.csv\n","\n","     Unnamed: 0       f1       f2       f3        f4  clase\n","0             0 -1.41308 -1.41308 -1.41308 -1.413080      0\n","1             1 -1.41308 -1.41308 -1.41308 -0.706541      2\n","2             2 -1.41308 -1.41308 -1.41308  0.000000      2\n","3             3 -1.41308 -1.41308 -1.41308  0.706541      2\n","4             4 -1.41308 -1.41308 -1.41308  1.413080      2\n","..          ...      ...      ...      ...       ...    ...\n","620         620  1.41308  1.41308  1.41308 -1.413080      1\n","621         621  1.41308  1.41308  1.41308 -0.706541      1\n","622         622  1.41308  1.41308  1.41308  0.000000      1\n","623         623  1.41308  1.41308  1.41308  0.706541      1\n","624         624  1.41308  1.41308  1.41308  1.413080      0\n","\n","[625 rows x 6 columns]\n","5\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","bank.csv\n","\n","      Unnamed: 0        f1        f2  ...       f15       f16  clase\n","0              0 -1.056150 -1.154780  ... -0.320377 -0.441355      0\n","1              1 -0.772497  1.402470  ...  2.041510  2.110260      0\n","2              2 -0.583394 -0.870645  ...  0.270094  2.110260      0\n","3              3 -1.056150 -0.870645  ... -0.320377 -0.441355      0\n","4              4  1.685850  0.265913  ... -0.320377 -0.441355      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","4516        4516 -0.772497  1.402470  ... -0.320377 -0.441355      0\n","4517        4517  1.496750  0.550053  ... -0.320377 -0.441355      0\n","4518        4518  1.496750  1.118330  ... -0.320377 -0.441355      0\n","4519        4519 -1.245260  0.265913  ...  1.451040  0.834454      0\n","4520        4520  0.267573 -0.302366  ...  3.812920  0.834454      0\n","\n","[4521 rows x 18 columns]\n","17\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","blood.csv\n","\n","     Unnamed: 0        f1        f2        f3        f4  clase\n","0             0 -0.927278  7.618250  7.618250  2.613880      1\n","1             1 -1.174330  1.281880  1.281880 -0.257708      1\n","2             2 -1.050810  1.795640  1.795640  0.029451      1\n","3             3 -0.927278  2.480650  2.480650  0.439678      1\n","4             4 -1.050810  3.165670  3.165670  1.752410      0\n","..          ...       ...       ...       ...       ...    ...\n","743         743  1.666790 -0.601905 -0.601905  0.152519      0\n","744         744  1.419730 -0.601905 -0.601905  0.726838      0\n","745         745  1.666790 -0.430651 -0.430651  1.137070      0\n","746         746  3.643220 -0.773158 -0.773158  0.193542      0\n","747         747  7.719610 -0.773158 -0.773158  1.547290      0\n","\n","[748 rows x 6 columns]\n","5\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","breast-cancer.csv\n","\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0 -1.644900  0.912871  ... -0.130877  0.557527      0\n","1             1 -0.656576  0.912871  ...  0.700918  0.557527      0\n","2             2 -0.656576  0.912871  ... -0.130877  0.557527      0\n","3             3  1.320060 -0.912871  ... -0.962672  0.557527      0\n","4             4 -0.656576  0.912871  ...  1.532710  0.557527      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","281         281 -1.644900  0.912871  ... -0.962672  0.557527      1\n","282         282 -1.644900  0.912871  ... -0.962672 -1.787360      1\n","283         283  1.320060 -0.912871  ... -0.962672  0.557527      1\n","284         284 -0.656576 -0.912871  ... -0.130877  0.557527      1\n","285         285  0.331744 -0.912871  ... -0.130877  0.557527      1\n","\n","[286 rows x 11 columns]\n","10\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","breast-cancer-wisc.csv\n","\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0  0.206788 -0.699494  ... -0.611387 -0.343666      0\n","1             1  0.206788  0.283642  ... -0.283909 -0.343666      0\n","2             2 -0.503505 -0.699494  ... -0.611387 -0.343666      0\n","3             3  0.561934  1.594490  ...  1.353480 -0.343666      0\n","4             4 -0.148359 -0.699494  ... -0.611387 -0.343666      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","694         694 -0.503505 -0.699494  ... -0.611387 -0.343666      0\n","695         695 -0.858651 -0.699494  ... -0.611387 -0.343666      0\n","696         696  0.206788  2.249910  ...  2.335920  0.239398      1\n","697         697 -0.148359  1.594490  ...  1.026010 -0.343666      1\n","698         698 -0.148359  1.594490  ...  0.371049 -0.343666      1\n","\n","[699 rows x 11 columns]\n","10\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","breast-cancer-wisc-diag.csv\n","\n","     Unnamed: 0        f1        f2  ...       f29       f30  clase\n","0             0  1.096100 -2.071510  ...  2.748200  1.935310      1\n","1             1  1.828210 -0.353322  ... -0.243675  0.280943      1\n","2             2  1.578500  0.455786  ...  1.151240  0.201214      1\n","3             3 -0.768233  0.253509  ...  6.040730  4.930670      1\n","4             4  1.748760 -1.150800  ... -0.867590 -0.396751      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","564         564  2.109140  0.720838  ... -1.358960 -0.708467      1\n","565         565  1.703360  2.083300  ... -0.531387 -0.973122      1\n","566         566  0.701667  2.043780  ... -1.103580 -0.318129      1\n","567         567  1.836720  2.334400  ...  1.917400  2.217680      1\n","568         568 -1.806810  1.220720  ... -0.048096 -0.750546      0\n","\n","[569 rows x 32 columns]\n","31\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","breast-cancer-wisc-prog.csv\n","\n","     Unnamed: 0        f1        f2  ...       f32       f33  clase\n","0             0 -0.456501  0.192201  ...  1.110710  0.340583      0\n","1             1  0.414001  0.182712  ...  0.078704 -0.210660      0\n","2             2  2.009920  1.251770  ... -0.179299 -0.578156      0\n","3             3  2.213040 -1.895300  ... -0.437302 -0.578156      0\n","4             4 -0.572568  0.910175  ...  0.336707 -0.578156      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","193         193 -1.065850  1.615500  ...  1.626720 -0.210660      0\n","194         194 -1.123890 -0.623822  ... -0.695304 -0.578156      0\n","195         195 -1.007820 -0.076644  ...  0.439908 -0.578156      0\n","196         196 -1.268970  1.267580  ...  0.078704 -0.578156      1\n","197         197 -1.181920 -0.225299  ...  0.336707 -0.578156      0\n","\n","[198 rows x 35 columns]\n","34\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","breast-tissue.csv\n","\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0 -0.344131  0.981334  ...  0.297980 -0.332639      0\n","1             1 -0.602496  1.556360  ... -0.372984 -0.537880      0\n","2             2 -0.308207  1.637780  ...  0.480254 -0.201658      0\n","3             3 -0.536178  1.759910  ... -0.339265 -0.415371      0\n","4             4 -0.558950  1.174700  ... -0.346612 -0.505678      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","101         101  1.612510 -0.191614  ...  1.719750  1.674940      5\n","102         102  2.408310  1.172160  ...  4.472140  2.429750      5\n","103         103  1.081970 -0.703029  ...  1.463900  0.871188      5\n","104         104  2.010410 -1.094860  ... -0.645952  2.188610      5\n","105         105  2.408310 -0.731017  ...  3.103300  2.273580      5\n","\n","[106 rows x 11 columns]\n","10\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","car.csv\n","\n","      Unnamed: 0       f1       f2        f3       f4       f5       f6  clase\n","0              0 -1.34125 -1.34125 -1.520840 -1.22439 -1.22439 -1.22439      1\n","1              1 -1.34125 -1.34125 -1.520840 -1.22439 -1.22439  0.00000      1\n","2              2 -1.34125 -1.34125 -1.520840 -1.22439 -1.22439  1.22439      1\n","3              3 -1.34125 -1.34125 -1.520840 -1.22439  0.00000 -1.22439      1\n","4              4 -1.34125 -1.34125 -1.520840 -1.22439  0.00000  0.00000      1\n","...          ...      ...      ...       ...      ...      ...      ...    ...\n","1723        1723  1.34125  1.34125  0.506946  1.22439  0.00000  0.00000      3\n","1724        1724  1.34125  1.34125  0.506946  1.22439  0.00000  1.22439      0\n","1725        1725  1.34125  1.34125  0.506946  1.22439  1.22439 -1.22439      1\n","1726        1726  1.34125  1.34125  0.506946  1.22439  1.22439  0.00000      3\n","1727        1727  1.34125  1.34125  0.506946  1.22439  1.22439  1.22439      0\n","\n","[1728 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","cardiotocography-3clases.csv\n","\n","      Unnamed: 0        f1        f2  ...       f20       f21  clase\n","0              0 -1.351900 -0.822195  ...  1.870130  1.112720      1\n","1              1 -0.132494  0.729961  ... -0.234943 -0.524402      0\n","2              2 -0.030877 -0.046117  ... -0.200434 -0.524402      0\n","3              3  0.070740 -0.046117  ... -0.200434  1.112720      0\n","4              4 -0.132494  0.988654  ... -0.269452  1.112720      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","2121        2121  0.680444 -0.822195  ... -0.580037 -0.524402      1\n","2122        2122  0.680444 -0.563502  ... -0.545527  1.112720      1\n","2123        2123  0.680444 -0.563502  ... -0.511018  1.112720      1\n","2124        2124  0.680444 -0.563502  ... -0.511018  1.112720      1\n","2125        2125  0.883679 -0.304810  ... -0.614546 -0.524402      0\n","\n","[2126 rows x 23 columns]\n","22\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","cardiotocography-10clases.csv\n","\n","      Unnamed: 0        f1        f2  ...       f20       f21  clase\n","0              0 -1.351900 -0.822195  ...  1.870130  1.112720      8\n","1              1 -0.132494  0.729961  ... -0.234943 -0.524402      5\n","2              2 -0.030877 -0.046117  ... -0.200434 -0.524402      5\n","3              3  0.070740 -0.046117  ... -0.200434  1.112720      5\n","4              4 -0.132494  0.988654  ... -0.269452  1.112720      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","2121        2121  0.680444 -0.822195  ... -0.580037 -0.524402      4\n","2122        2122  0.680444 -0.563502  ... -0.545527  1.112720      4\n","2123        2123  0.680444 -0.563502  ... -0.511018  1.112720      4\n","2124        2124  0.680444 -0.563502  ... -0.511018  1.112720      4\n","2125        2125  0.883679 -0.304810  ... -0.614546 -0.524402      0\n","\n","[2126 rows x 23 columns]\n","22\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","chess-krvkp.csv\n","\n","      Unnamed: 0        f1        f2  ...       f35       f36  clase\n","0              0 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","1              1 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","2              2 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","3              3 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","4              4 -0.354555 -0.275152  ...  0.602317 -0.572443      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","3191        3191  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","3192        3192  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","3193        3193  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","3194        3194  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","3195        3195  2.819560 -0.275152  ... -1.659730 -0.572443      0\n","\n","[3196 rows x 38 columns]\n","37\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","congressional-voting.csv\n","\n","     Unnamed: 0        f1        f2  ...       f15      f16  clase\n","0             0 -0.168237 -0.351775  ... -0.261988 -0.55989      1\n","1             1 -0.168237 -0.351775  ... -0.261988  1.78196      1\n","2             2  5.930340 -0.351775  ... -0.261988 -0.55989      0\n","3             3 -0.168237 -0.351775  ... -0.261988 -0.55989      0\n","4             4 -0.168237 -0.351775  ... -0.261988 -0.55989      0\n","..          ...       ...       ...  ...       ...      ...    ...\n","430         430 -0.168237 -0.351775  ... -0.261988 -0.55989      1\n","431         431 -0.168237 -0.351775  ... -0.261988 -0.55989      0\n","432         432 -0.168237  2.836190  ... -0.261988 -0.55989      1\n","433         433 -0.168237 -0.351775  ... -0.261988 -0.55989      1\n","434         434 -0.168237 -0.351775  ...  3.808190 -0.55989      1\n","\n","[435 rows x 18 columns]\n","17\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","conn-bench-sonar-mines-rocks.csv\n","\n","     Unnamed: 0        f1        f2  ...       f59       f60  clase\n","0             0 -0.398590 -0.040550  ...  0.171265 -0.657361      1\n","1             1  0.701845  0.420616  ... -0.443484 -0.418842      1\n","2             2 -0.128918  0.599621  ...  0.252153  0.256962      1\n","3             3 -0.833544 -0.647348  ... -0.637616  1.032150      1\n","4             4  2.045850  0.854476  ...  0.446284  0.574988      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","203         203 -0.455134 -0.116400  ...  1.837560  1.827210      0\n","204         204  0.136404 -0.859727  ... -0.281708  0.038320      0\n","205         205  1.001960  0.159693  ... -0.039044 -0.677238      0\n","206         206  0.049413 -0.095162  ... -0.702326 -0.339335      0\n","207         207 -0.137617 -0.064822  ... -0.297886  0.992396      0\n","\n","[208 rows x 62 columns]\n","61\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","contrac.csv\n","\n","      Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0              0 -1.037810 -0.944427  ... -0.137007 -0.282591      0\n","1              1  1.514680 -1.929650  ...  0.887415 -0.282591      0\n","2              2  1.271590 -0.944427  ...  0.887415 -0.282591      0\n","3              3  1.150040  0.040800  ... -0.137007 -0.282591      0\n","4              4  0.420754  0.040800  ... -1.161430 -0.282591      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1468        1468  0.056112  1.026030  ...  0.887415 -0.282591      2\n","1469        1469  0.056112  1.026030  ...  0.887415 -0.282591      2\n","1470        1470  0.785396  0.040800  ...  0.887415 -0.282591      2\n","1471        1471  0.056112  0.040800  ... -1.161430 -0.282591      2\n","1472        1472 -1.888650  0.040800  ...  0.887415 -0.282591      2\n","\n","[1473 rows x 11 columns]\n","10\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","conn-bench-vowel-deterding.csv\n","\n","     Unnamed: 0        f1        f2  ...       f10       f11  clase\n","0             0 -0.999053 -0.493029  ... -0.977895 -1.301820      0\n","1             1 -0.999053 -0.167339  ... -0.569557 -0.720006      1\n","2             2 -0.999053  1.092620  ... -0.872986  0.063479      2\n","3             3 -0.999053  0.918295  ...  0.285856 -1.267910      3\n","4             4 -0.999053  0.593649  ...  0.879803 -0.555813      4\n","..          ...       ...       ...  ...       ...       ...    ...\n","985         985  1.153450 -0.090104  ... -1.192290 -1.024020      6\n","986         986  1.153450 -1.527750  ... -0.424604 -0.861515      7\n","987         987  1.153450 -1.304120  ... -1.103210  0.595375      8\n","988         988  1.153450 -2.417890  ... -1.901680 -0.262509      9\n","989         989  1.153450  0.291066  ... -1.976180  0.842913     10\n","\n","[990 rows x 13 columns]\n","12\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","credit-approval.csv\n","\n","     Unnamed: 0        f1        f2  ...       f14       f15  clase\n","0             0  0.681488 -0.015070  ...  0.123309 -0.195272      0\n","1             1 -1.495490  2.202890  ... -0.790640 -0.087788      0\n","2             2 -1.495490 -0.519369  ...  0.571662 -0.037117      0\n","3             3  0.681488 -0.254074  ... -0.462998 -0.194696      0\n","4             4  0.681488 -0.864332  ... -0.348035 -0.195272      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","685         685  0.681488 -0.791834  ...  0.456700 -0.195272      1\n","686         686 -1.495490 -0.665162  ...  0.111813 -0.119649      1\n","687         687 -1.495490 -0.459618  ...  0.111813 -0.195080      1\n","688         688  0.681488 -1.043580  ...  0.571662 -0.051321      1\n","689         689  0.681488  0.317146  ... -1.037810 -0.195272      1\n","\n","[690 rows x 17 columns]\n","16\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","cylinder-bands.csv\n","\n","     Unnamed: 0        f1        f2  ...       f34       f35  clase\n","0             0  1.173460 -0.185139  ...  0.281940  0.111585      0\n","1             1  1.173460 -0.185139  ...  0.281940  0.111585      1\n","2             2  1.173460 -0.185139  ...  0.194359  0.111585      1\n","3             3  1.173460 -0.185139  ...  0.519108  0.111585      1\n","4             4 -0.887640 -0.185139  ...  0.411375  0.111585      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","507         507  0.142908  5.390800  ... -0.345857  0.111585      0\n","508         508  0.142908  5.390800  ... -0.345857  0.111585      0\n","509         509  0.142908  5.390800  ... -0.345857  0.111585      0\n","510         510  0.142908  5.390800  ... -0.345857  0.111585      0\n","511         511  0.142908  5.390800  ... -0.345857  0.111585      0\n","\n","[512 rows x 37 columns]\n","36\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","dermatology.csv\n","\n","     Unnamed: 0        f1        f2  ...       f33       f34  clase\n","0             0 -0.102754  0.292103  ... -0.501529  1.213990      1\n","1             1  1.401560  1.717560  ... -0.501529 -1.712450      0\n","2             2 -0.102754 -1.133360  ...  2.211170 -0.591685      2\n","3             3 -0.102754  0.292103  ... -0.501529  0.280021      0\n","4             4 -0.102754  1.717560  ...  2.211170  0.591345      2\n","..          ...       ...       ...  ...       ...       ...    ...\n","361         361 -0.102754 -1.133360  ... -0.501529 -0.653950      3\n","362         362  1.401560  0.292103  ... -0.501529  0.030962      3\n","363         363  1.401560  0.292103  ...  2.211170 -0.467156      2\n","364         364 -0.102754 -1.133360  ...  2.211170  0.902668      2\n","365         365  1.401560  0.292103  ... -0.501529 -0.031302      0\n","\n","[366 rows x 36 columns]\n","35\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","echocardiogram.csv\n","\n","     Unnamed: 0        f1        f2  ...       f9       f10  clase\n","0             0  0.725400 -0.471791  ... -0.62609 -0.471791      0\n","1             1  0.793939 -0.471791  ... -0.62609 -0.471791      0\n","2             2 -0.371225 -0.471791  ... -0.62609 -0.471791      0\n","3             3 -0.028530 -0.471791  ... -0.62609 -0.471791      0\n","4             4 -0.234147 -0.471791  ... -0.62609 -0.471791      1\n","..          ...       ...       ...  ...      ...       ...    ...\n","126         126  0.245627 -0.471791  ... -1.92796 -0.471791      1\n","127         127  0.245627 -0.471791  ... -1.92796 -0.471791      0\n","128         128  0.588322 -0.471791  ... -1.92796 -0.471791      0\n","129         129 -0.234147 -0.471791  ... -1.92796 -0.471791      0\n","130         130  0.108549 -0.471791  ... -1.92796 -0.471791      0\n","\n","[131 rows x 12 columns]\n","11\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","energy-y1.csv\n","\n","     Unnamed: 0       f1       f2        f3  ...        f6       f7       f8  clase\n","0             0  2.04045 -1.78471 -0.561586  ... -1.340770 -1.75930 -1.81339      0\n","1             1  2.04045 -1.78471 -0.561586  ... -0.446922 -1.75930 -1.81339      0\n","2             2  2.04045 -1.78471 -0.561586  ...  0.446922 -1.75930 -1.81339      0\n","3             3  2.04045 -1.78471 -0.561586  ...  1.340770 -1.75930 -1.81339      0\n","4             4  1.28414 -1.22844  0.000000  ... -1.340770 -1.75930 -1.81339      1\n","..          ...      ...      ...       ...  ...       ...      ...      ...    ...\n","763         763 -1.17385  1.27479  0.561586  ...  1.340770  1.24324  1.41042      1\n","764         764 -1.36292  1.55293  1.123170  ... -1.340770  1.24324  1.41042      0\n","765         765 -1.36292  1.55293  1.123170  ... -0.446922  1.24324  1.41042      0\n","766         766 -1.36292  1.55293  1.123170  ...  0.446922  1.24324  1.41042      0\n","767         767 -1.36292  1.55293  1.123170  ...  1.340770  1.24324  1.41042      0\n","\n","[768 rows x 10 columns]\n","9\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","energy-y2.csv\n","\n","     Unnamed: 0       f1       f2        f3  ...        f6       f7       f8  clase\n","0             0  2.04045 -1.78471 -0.561586  ... -1.340770 -1.75930 -1.81339      0\n","1             1  2.04045 -1.78471 -0.561586  ... -0.446922 -1.75930 -1.81339      0\n","2             2  2.04045 -1.78471 -0.561586  ...  0.446922 -1.75930 -1.81339      0\n","3             3  2.04045 -1.78471 -0.561586  ...  1.340770 -1.75930 -1.81339      0\n","4             4  1.28414 -1.22844  0.000000  ... -1.340770 -1.75930 -1.81339      1\n","..          ...      ...      ...       ...  ...       ...      ...      ...    ...\n","763         763 -1.17385  1.27479  0.561586  ...  1.340770  1.24324  1.41042      0\n","764         764 -1.36292  1.55293  1.123170  ... -1.340770  1.24324  1.41042      0\n","765         765 -1.36292  1.55293  1.123170  ... -0.446922  1.24324  1.41042      0\n","766         766 -1.36292  1.55293  1.123170  ...  0.446922  1.24324  1.41042      0\n","767         767 -1.36292  1.55293  1.123170  ...  1.340770  1.24324  1.41042      0\n","\n","[768 rows x 10 columns]\n","9\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","fertility.csv\n","\n","    Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0            0 -0.315165  0.173098  ...  0.432779  2.538690      0\n","1            1 -0.315165  2.233790  ...  1.669290 -0.519327      1\n","2            2 -0.315165 -1.393030  ... -0.803732  0.500013      0\n","3            3 -0.315165  0.667664  ... -0.803732 -0.143780      0\n","4            4 -0.315165  0.008243  ... -0.803732  0.500013      1\n","..         ...       ...       ...  ...       ...       ...    ...\n","95          95 -1.156110  0.008243  ... -0.803732  0.500013      0\n","96          96 -1.156110 -0.486323  ...  0.432779  0.500013      0\n","97          97 -1.156110  0.008243  ... -0.803732 -0.519327      0\n","98          98 -1.156110 -0.239040  ...  0.432779 -1.163120      0\n","99          99 -1.156110  0.173098  ... -0.803732 -1.163120      0\n","\n","[100 rows x 11 columns]\n","10\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","glass.csv\n","\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0  0.870826  0.284287  ... -0.352051 -0.585079      0\n","1             1 -0.248750  0.590433  ... -0.352051 -0.585079      0\n","2             2 -0.719631  0.149582  ... -0.352051 -0.585079      0\n","3             3 -0.232286 -0.242285  ... -0.352051 -0.585079      0\n","4             4 -0.311315 -0.168810  ... -0.352051 -0.585079      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","209         209 -0.703166  0.896579  ...  1.779800 -0.585079      5\n","210         210 -0.499008  1.851750  ...  2.845730 -0.585079      5\n","211         211  0.752282  1.165990  ...  2.946290 -0.585079      5\n","212         212 -0.610966  1.190480  ...  2.805510 -0.585079      5\n","213         213 -0.413394  1.006790  ...  3.006630 -0.585079      5\n","\n","[214 rows x 11 columns]\n","10\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","haberman-survival.csv\n","\n","     Unnamed: 0       f1        f2        f3  clase\n","0             0 -2.07874  0.353006 -0.420903      0\n","1             1 -2.07874 -0.262492 -0.142725      0\n","2             2 -2.07874  0.660755 -0.559991      0\n","3             3 -1.98617 -1.185740 -0.281814      0\n","4             4 -1.98617  0.660755 -0.003636      0\n","..          ...      ...       ...       ...    ...\n","301         301  2.08660 -0.262492 -0.420903      0\n","302         302  2.17916  1.276250 -0.559991      0\n","303         303  2.27173  0.660755 -0.142725      0\n","304         304  2.36429  0.660755 -0.420903      1\n","305         305  2.82710 -1.493490 -0.281814      1\n","\n","[306 rows x 5 columns]\n","4\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","heart-cleveland.csv\n","\n","     Unnamed: 0        f1        f2  ...       f12       f13  clase\n","0             0  0.947160  0.685069  ... -0.709957  0.658044      0\n","1             1  1.389700  0.685069  ...  2.500740 -0.863997      2\n","2             2  1.389700  0.685069  ...  1.430510  1.165390      1\n","3             3 -1.929370  0.685069  ... -0.709957 -0.863997      0\n","4             4 -1.486830 -1.454890  ... -0.709957 -0.863997      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","298         298 -1.044290  0.685069  ... -0.709957  1.165390      1\n","299         299  1.500340  0.685069  ...  1.430510  1.165390      2\n","300         300  0.283345  0.685069  ...  0.360277  1.165390      3\n","301         301  0.283345 -1.454890  ...  0.360277 -0.863997      1\n","302         302 -1.818740  0.685069  ... -0.709957 -0.863997      0\n","\n","[303 rows x 15 columns]\n","14\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","heart-hungarian.csv\n","\n","     Unnamed: 0        f1       f2  ...      f11       f12  clase\n","0             0 -2.538020  0.61562  ... -0.72110 -0.310615      0\n","1             1 -2.410010  0.61562  ... -0.72110 -0.310615      0\n","2             2 -2.410010  0.61562  ... -0.72110 -0.310615      0\n","3             3 -2.282000 -1.61885  ... -0.72110  3.157260      0\n","4             4 -2.153990 -1.61885  ... -0.72110 -0.310615      0\n","..          ...       ...      ...  ...      ...       ...    ...\n","289         289  0.534251  0.61562  ... -0.72110 -0.310615      1\n","290         290  0.790274 -1.61885  ...  1.43122 -0.310615      1\n","291         291  1.046300  0.61562  ...  1.43122 -0.310615      1\n","292         292  1.302320 -1.61885  ...  1.43122  3.735240      1\n","293         293  2.198400  0.61562  ...  1.43122 -0.310615      1\n","\n","[294 rows x 14 columns]\n","13\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","heart-switzerland.csv\n","\n","     Unnamed: 0       f1       f2        f3  ...       f10      f11       f12  clase\n","0             0 -2.58158  0.29627 -3.919100  ... -0.649444 -0.19567 -1.058550      1\n","1             1 -2.36014  0.29627  0.436767  ... -0.649444 -0.19567 -1.058550      1\n","2             2 -2.24943  0.29627  0.436767  ... -1.824170 -0.19567  1.158990      3\n","3             3 -2.13871  0.29627  0.436767  ...  0.525285 -0.19567  0.842203      1\n","4             4 -1.91728 -3.34785  0.436767  ... -0.649444 -0.19567 -1.058550      2\n","..          ...      ...      ...       ...  ...       ...      ...       ...    ...\n","118         118  1.62564  0.29627  0.436767  ...  0.525285 -0.19567  1.158990      1\n","119         119  1.62564  0.29627  0.436767  ...  0.525285 -0.19567  1.158990      3\n","120         120  1.84707  0.29627 -1.015190  ...  0.525285  5.82119 -1.058550      0\n","121         121  1.95779 -3.34785 -1.015190  ... -0.649444 -0.19567 -0.108173      1\n","122         122  2.06850  0.29627 -2.467140  ... -0.649444 -0.19567 -1.058550      1\n","\n","[123 rows x 14 columns]\n","13\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","heart-va.csv\n","\n","     Unnamed: 0        f1        f2  ...       f11       f12  clase\n","0             0  0.467248  0.175423  ...  0.818974 -0.440715      2\n","1             1 -1.965000  0.175423  ... -0.896155 -0.440715      0\n","2             2  0.083209  0.175423  ...  1.676540 -0.440715      2\n","3             3 -0.556857  0.175423  ... -0.038590 -0.440715      1\n","4             4  0.851287  0.175423  ...  0.818974 -0.440715      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","195         195 -0.684870 -5.672010  ... -0.896155 -0.440715      1\n","196         196  0.339235  0.175423  ... -0.896155 -0.440715      0\n","197         197 -0.556857  0.175423  ... -0.896155  2.030580      2\n","198         198 -0.172818  0.175423  ... -0.896155 -0.440715      0\n","199         199  0.339235  0.175423  ... -0.896155 -0.440715      1\n","\n","[200 rows x 14 columns]\n","13\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","hepatitis.csv\n","\n","     Unnamed: 0        f1        f2  ...       f18       f19  clase\n","0             0 -0.891303  2.937930  ... -0.996996 -0.904553      1\n","1             1  0.700309 -0.338179  ... -0.996996 -0.904553      1\n","2             2  2.928570 -0.338179  ... -0.996996 -0.904553      1\n","3             3 -0.811722 -0.338179  ...  1.274320 -0.904553      1\n","4             4 -0.572980 -0.338179  ... -0.996996 -0.904553      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","150         150  0.381987 -0.338179  ...  0.422574  1.098390      0\n","151         151  0.222826 -0.338179  ... -0.996996  1.098390      1\n","152         152  1.575700 -0.338179  ... -0.996996  1.098390      1\n","153         153  0.939051  2.937930  ...  0.365791  1.098390      1\n","154         154  0.143245 -0.338179  ...  0.195443  1.098390      0\n","\n","[155 rows x 21 columns]\n","20\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","hayes-roth.csv\n","\n","     Unnamed: 0       f1        f2        f3  clase\n","0             0 -1.00692 -1.006920  0.047948      0\n","1             1 -1.00692  1.102810  0.047948      1\n","2             2 -1.00692  2.157680 -1.006920      2\n","3             3  2.15768  0.047948  0.047948      2\n","4             4 -1.00692  1.102810  2.157680      2\n","..          ...      ...       ...       ...    ...\n","155         155  3.00000  1.000000  2.000000      1\n","156         156  1.00000  1.000000  1.000000      0\n","157         157  2.00000  2.000000  2.000000      1\n","158         158  3.00000  3.000000  3.000000      0\n","159         159  4.00000  4.000000  4.000000      2\n","\n","[160 rows x 5 columns]\n","4\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","hill-valley.csv\n","\n","      Unnamed: 0            f1           f2  ...          f99         f100  clase\n","0              0     -0.441300    -0.443197  ...    -0.441577    -0.444649      0\n","1              1     -0.443363    -0.445144  ...    -0.443563    -0.446745      1\n","2              2      3.339170     3.256770  ...     3.300560     3.752260      1\n","3              3      2.047070     1.748470  ...     1.827630     1.773500      0\n","4              4     -0.443149    -0.444938  ...    -0.443342    -0.446509      0\n","...          ...           ...          ...  ...          ...          ...    ...\n","1207        1207     13.000000    12.870000  ...    13.870000    13.510000      1\n","1208        1208     48.660000    50.110000  ...    47.430000    47.770000      0\n","1209        1209  10160.600000  9048.630000  ...  8997.600000  9305.770000      1\n","1210        1210     34.810000    35.070000  ...    32.830000    34.820000      1\n","1211        1211   8489.430000  7672.980000  ...  8389.310000  8712.800000      0\n","\n","[1212 rows x 102 columns]\n","101\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","horse-colic.csv\n","\n","     Unnamed: 0       f1        f2  ...           f24       f25  clase\n","0             0  1.22289 -0.294392  ... -1.389020e-01  0.700639      1\n","1             1 -0.79286 -0.294392  ... -1.389020e-01  0.700639      1\n","2             2  1.22289 -0.294392  ... -1.389020e-01 -1.422510      1\n","3             3 -0.79286  3.385510  ... -1.389020e-01 -1.422510      0\n","4             4  1.22289 -0.294392  ... -1.389020e-01  0.700639      1\n","..          ...      ...       ...  ...           ...       ...    ...\n","363         363  2.00000  1.000000  ... -1.480000e-18  2.000000      0\n","364         364  2.00000  1.000000  ... -1.480000e-18  2.000000      1\n","365         365  1.00000  1.000000  ... -1.480000e-18  2.000000      0\n","366         366  2.00000  1.000000  ... -1.480000e-18  2.000000      1\n","367         367  2.00000  1.000000  ... -1.480000e-18  2.000000      0\n","\n","[368 rows x 27 columns]\n","26\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","ilpd-indian-liver.csv\n","\n","     Unnamed: 0        f1        f2  ...        f8        f9  clase\n","0             0  1.251020 -0.418518  ...  0.198798 -0.123691      0\n","1             1  1.065720  1.224120  ...  0.073094 -0.611552      0\n","2             2  1.065720  0.644365  ...  0.198798 -0.154182      0\n","3             3  0.818653 -0.370206  ...  0.324502  0.181222      0\n","4             4  1.683390  0.096819  ... -0.932539 -1.648260      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","578         578  0.942188 -0.450727  ... -1.938170 -1.739730      1\n","579         579 -0.293156 -0.434623  ...  0.073094  0.486135      0\n","580         580  0.448050 -0.402414  ...  0.073094  0.181222      0\n","581         581 -0.849060 -0.321893  ...  0.324502  0.181222      0\n","582         582 -0.416690 -0.370206  ...  1.581540  1.705790      1\n","\n","[583 rows x 11 columns]\n","10\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","image-segmentation.csv\n","\n","      Unnamed: 0          f1          f2  ...       f17       f18  clase\n","0              0    0.207173    0.038577  ...  0.538437  0.140168      0\n","1              1    0.854911    0.176177  ...  0.507405  0.266499      0\n","2              2   -0.265136    0.279376  ...  0.481222  0.240125      0\n","3              3   -1.223250    0.244977  ...  0.661596  0.382278      0\n","4              4   -1.155780   -0.202222  ...  0.614466  0.105569      0\n","...          ...         ...         ...  ...       ...       ...    ...\n","2305        2305   32.000000  158.000000  ...  0.520578 -1.982830      3\n","2306        2306    8.000000  162.000000  ...  0.484805 -2.044950      3\n","2307        2307  128.000000  161.000000  ...  0.540918 -1.996310      3\n","2308        2308  150.000000  158.000000  ...  0.503086 -1.943450      3\n","2309        2309  124.000000  162.000000  ...  0.479931 -2.029310      3\n","\n","[2310 rows x 20 columns]\n","19\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","ionosphere.csv\n","\n","     Unnamed: 0        f1        f2  ...       f32       f33  clase\n","0             0  0.347937  0.711357  ... -0.311776 -0.998170      1\n","1             1  0.347937  0.720619  ... -0.931276 -0.083167      0\n","2             2  0.347937  0.720619  ...  0.403867 -0.847381      1\n","3             3  0.347937  0.720619  ... -1.287990  2.104300      0\n","4             4  0.347937  0.720619  ... -0.756593 -1.433690      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","346         346  0.347937  0.389261  ...  1.063970 -0.122882      1\n","347         347  0.347937  0.622429  ...  1.081890  0.069693      1\n","348         348  0.347937  0.614151  ...  1.105120 -0.043238      1\n","349         349  0.347937  0.531914  ...  1.003830 -0.377741      1\n","350         350  0.347937  0.413411  ...  0.972474 -0.162255      1\n","\n","[351 rows x 35 columns]\n","34\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","iris.csv\n","\n","     Unnamed: 0        f1        f2        f3        f4  clase\n","0             0 -0.897674  1.028610 -1.336790 -1.308590      0\n","1             1 -1.139200 -0.124540 -1.336790 -1.308590      0\n","2             2 -1.380730  0.336720 -1.393470 -1.308590      0\n","3             3 -1.501490  0.106090 -1.280120 -1.308590      0\n","4             4 -1.018440  1.259240 -1.336790 -1.308590      0\n","..          ...       ...       ...       ...       ...    ...\n","145         145  1.034540 -0.124540  0.816888  1.443120      2\n","146         146  0.551486 -1.277690  0.703536  0.918985      2\n","147         147  0.793012 -0.124540  0.816888  1.050020      2\n","148         148  0.430722  0.797981  0.930239  1.443120      2\n","149         149  0.068433 -0.124540  0.760212  0.787951      2\n","\n","[150 rows x 6 columns]\n","5\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","led-display.csv\n","\n","     Unnamed: 0       f1        f2  ...        f6        f7  clase\n","0             0  0.55397 -1.206460  ...  0.452343  0.717382      7\n","1             1  0.55397 -1.206460  ... -2.208500 -1.392560      7\n","2             2  0.55397 -1.206460  ... -2.208500 -1.392560      2\n","3             3  0.55397  0.828042  ...  0.452343  0.717382      5\n","4             4  0.55397  0.828042  ...  0.452343  0.717382      0\n","..          ...      ...       ...  ...       ...       ...    ...\n","995         995  0.55397  0.828042  ...  0.452343  0.717382      9\n","996         996 -1.80335 -1.206460  ...  0.452343  0.717382      3\n","997         997  0.55397  0.828042  ... -2.208500 -1.392560      0\n","998         998  0.55397  0.828042  ...  0.452343  0.717382      8\n","999         999  0.55397  0.828042  ...  0.452343  0.717382      8\n","\n","[1000 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","lenses.csv\n","\n","    Unnamed: 0       f1        f2        f3        f4  clase\n","0            0 -1.19896 -0.978945 -0.978945 -0.978945      2\n","1            1 -1.19896 -0.978945 -0.978945  0.978945      1\n","2            2 -1.19896 -0.978945  0.978945 -0.978945      2\n","3            3 -1.19896 -0.978945  0.978945  0.978945      0\n","4            4 -1.19896  0.978945 -0.978945 -0.978945      2\n","5            5 -1.19896  0.978945 -0.978945  0.978945      1\n","6            6 -1.19896  0.978945  0.978945 -0.978945      2\n","7            7 -1.19896  0.978945  0.978945  0.978945      0\n","8            8  0.00000 -0.978945 -0.978945 -0.978945      2\n","9            9  0.00000 -0.978945 -0.978945  0.978945      1\n","10          10  0.00000 -0.978945  0.978945 -0.978945      2\n","11          11  0.00000 -0.978945  0.978945  0.978945      0\n","12          12  0.00000  0.978945 -0.978945 -0.978945      2\n","13          13  0.00000  0.978945 -0.978945  0.978945      1\n","14          14  0.00000  0.978945  0.978945 -0.978945      2\n","15          15  0.00000  0.978945  0.978945  0.978945      2\n","16          16  1.19896 -0.978945 -0.978945 -0.978945      2\n","17          17  1.19896 -0.978945 -0.978945  0.978945      2\n","18          18  1.19896 -0.978945  0.978945 -0.978945      2\n","19          19  1.19896 -0.978945  0.978945  0.978945      0\n","20          20  1.19896  0.978945 -0.978945 -0.978945      2\n","21          21  1.19896  0.978945 -0.978945  0.978945      1\n","22          22  1.19896  0.978945  0.978945 -0.978945      2\n","23          23  1.19896  0.978945  0.978945  0.978945      2\n","5\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","libras.csv\n","\n","     Unnamed: 0        f1        f2  ...       f89       f90  clase\n","0             0  1.157760 -0.928219  ...  0.647092 -0.889723      0\n","1             1  0.564595 -1.508480  ... -1.420030  1.196680      0\n","2             2  0.778505 -1.706040  ...  1.281790 -0.974615      0\n","3             3 -0.009116 -1.236880  ... -0.004772 -1.156560      0\n","4             4  0.525684 -0.915844  ...  0.175311 -0.634995      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","355         355  0.467318  1.257190  ...  0.218237  0.299025     14\n","356         356  0.370091  0.874434  ...  0.123871  0.153504     14\n","357         357  0.224250  1.084320  ... -0.210663  0.274763     14\n","358         358  0.467318  1.257190  ...  0.218237  0.299025     14\n","359         359  0.370091  0.874434  ...  0.123871  0.153504     14\n","\n","[360 rows x 92 columns]\n","91\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","lung-cancer.csv\n","\n","    Unnamed: 0        f1        f2  ...       f55       f56  clase\n","0            0 -0.176777  1.129010  ...  0.472819  0.615692      0\n","1            1 -0.176777  1.129010  ...  0.472819  0.615692      0\n","2            2 -0.176777  1.129010  ... -2.048880  0.615692      0\n","3            3 -0.176777 -0.677408  ...  0.472819  0.615692      0\n","4            4 -0.176777  1.129010  ...  0.472819  0.615692      0\n","5            5 -0.176777  1.129010  ... -2.048880  0.615692      0\n","6            6 -0.176777  1.129010  ... -2.048880  0.615692      0\n","7            7 -0.176777 -0.677408  ...  0.472819  0.615692      0\n","8            8 -0.176777  1.129010  ...  0.472819  0.615692      0\n","9            9 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","10          10 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","11          11 -0.176777 -0.677408  ...  0.472819 -1.573430      1\n","12          12 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","13          13 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","14          14  5.480080  1.129010  ...  0.472819 -1.573430      1\n","15          15 -0.176777  1.129010  ...  0.472819  0.615692      1\n","16          16 -0.176777  1.129010  ...  0.472819  0.615692      1\n","17          17 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","18          18 -0.176777 -0.677408  ... -2.048880  0.615692      1\n","19          19 -0.176777 -2.483830  ...  0.472819 -1.573430      1\n","20          20 -0.176777 -0.677408  ...  0.472819  0.615692      1\n","21          21 -0.176777  1.129010  ... -2.048880  0.615692      1\n","22          22 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","23          23 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","24          24 -0.176777  1.129010  ...  0.472819 -1.573430      2\n","25          25 -0.176777 -0.677408  ... -2.048880  0.615692      2\n","26          26 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","27          27 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","28          28 -0.176777  1.129010  ...  0.472819  0.615692      2\n","29          29 -0.176777 -0.677408  ...  0.472819 -1.573430      2\n","30          30 -0.176777 -0.677408  ...  0.472819  0.615692      2\n","31          31 -0.176777 -0.677408  ...  0.472819  0.615692      2\n","\n","[32 rows x 58 columns]\n","57\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","lymphography.csv\n","\n","     Unnamed: 0        f1        f2  ...       f17       f18  clase\n","0             0  1.537300  0.894114  ...  0.512998 -0.315666      2\n","1             1  0.314072  0.894114  ...  0.512998 -0.315666      1\n","2             2  0.314072  0.894114  ...  0.512998  2.308970      2\n","3             3  0.314072 -1.110870  ...  0.512998  1.784050      2\n","4             4  0.314072 -1.110870  ...  0.512998 -0.840594      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","143         143  0.314072  0.894114  ...  0.512998  0.734190      2\n","144         144 -0.909156 -1.110870  ...  0.512998 -0.840594      1\n","145         145 -0.909156  0.894114  ...  0.512998  0.734190      2\n","146         146 -0.909156 -1.110870  ...  0.512998 -0.840594      1\n","147         147 -0.909156  0.894114  ...  0.512998  1.784050      1\n","\n","[148 rows x 20 columns]\n","19\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","mammographic.csv\n","\n","     Unnamed: 0        f1        f2        f3        f4        f5  clase\n","0             0  0.368698  0.787565  0.278795  1.425410  0.368642      1\n","1             1 -0.189284 -0.814093 -1.243490 -1.007660 -3.093230      1\n","2             2  0.368698  0.186943  1.039940  1.425410  0.368642      1\n","3             3 -0.189284 -1.815130 -1.243490 -1.007660  0.368642      0\n","4             4  0.368698  1.254720 -1.243490  1.425410 -3.093230      1\n","..          ...       ...       ...       ...       ...       ...    ...\n","956         956 -0.189284 -0.547150 -0.482347 -1.007660  0.368642      0\n","957         957 -0.189284  0.053472  1.039940  1.425410  0.368642      1\n","958         958 -0.189284  0.587358  1.039940  1.425410  0.368642      0\n","959         959  0.368698  0.720829  1.039940  1.425410  0.368642      1\n","960         960 -0.189284  0.453886  0.278795  0.208874  0.368642      0\n","\n","[961 rows x 7 columns]\n","6\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","molec-biol-promoter.csv\n","\n","     Unnamed: 0        f1        f2  ...       f56       f57  clase\n","0             0  1.148310 -1.186670  ...  0.403468  1.143730      0\n","1             1  1.148310  0.513155  ... -1.378520 -1.399670      0\n","2             2  0.320277  1.363070  ... -0.487524  0.295929      0\n","3             3 -1.335790 -1.186670  ...  1.294460 -0.551868      0\n","4             4  1.148310 -0.336758  ... -1.378520  0.295929      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","101         101 -0.507757 -0.336758  ... -1.378520  1.143730      1\n","102         102  0.320277  1.363070  ...  1.294460  0.295929      1\n","103         103 -0.507757  0.513155  ... -0.487524 -0.551868      1\n","104         104 -0.507757  1.363070  ... -1.378520 -0.551868      1\n","105         105  1.148310 -1.186670  ... -0.487524  1.143730      1\n","\n","[106 rows x 59 columns]\n","58\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","molec-biol-splice.csv\n","\n","      Unnamed: 0        f1        f2  ...       f59       f60  clase\n","0              0 -0.462236 -0.434755  ...  1.383240  0.436385      0\n","1              1 -1.383240  0.472288  ...  0.476802 -0.491661      0\n","2              2  0.458771 -1.341800  ...  1.383240  0.436385      0\n","3              3  0.458771  0.472288  ... -0.429633 -0.491661      0\n","4              4  0.458771 -0.434755  ... -0.429633  1.364430      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","3185        3185  1.379780 -0.434755  ...  1.383240  1.364430      2\n","3186        3186  0.458771 -1.341800  ...  1.383240  0.436385      2\n","3187        3187  1.379780 -0.434755  ...  1.383240 -0.491661      2\n","3188        3188 -1.383240  1.379330  ... -1.336070 -1.419710      2\n","3189        3189 -1.383240  0.472288  ...  1.383240  1.364430      2\n","\n","[3190 rows x 62 columns]\n","61\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","monks-1.csv\n","\n","     Unnamed: 0       f1        f2  ...        f5        f6  clase\n","0             0  0.45421  0.381467  ...  1.736100  0.740391      1\n","1             1  0.45421  0.381467  ...  1.736100  2.073090      1\n","2             2  0.45421  0.381467  ...  0.970018  0.740391      1\n","3             3  0.45421  0.381467  ...  1.736100  2.073090      1\n","4             4  0.45421  0.381467  ...  0.970018  0.740391      1\n","..          ...      ...       ...  ...       ...       ...    ...\n","551         551  1.22333  1.223330  ... -0.446696  0.998842      1\n","552         552  1.22333  1.223330  ...  0.446696 -0.998842      1\n","553         553  1.22333  1.223330  ...  0.446696  0.998842      1\n","554         554  1.22333  1.223330  ...  1.340090 -0.998842      1\n","555         555  1.22333  1.223330  ...  1.340090  0.998842      1\n","\n","[556 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","monks-2.csv\n","\n","     Unnamed: 0        f1        f2  ...        f5        f6  clase\n","0             0  0.202573  0.209001  ...  0.743270  1.768840      0\n","1             1  0.202573  0.209001  ...  2.183150  0.516154      0\n","2             2  0.202573  0.209001  ...  0.023331  0.516154      0\n","3             3  0.202573  0.209001  ...  0.023331  1.768840      0\n","4             4  0.202573  0.209001  ...  0.743270  0.516154      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","596         596  1.223330  1.223330  ... -0.446696  0.998842      0\n","597         597  1.223330  1.223330  ...  0.446696 -0.998842      0\n","598         598  1.223330  1.223330  ...  0.446696  0.998842      0\n","599         599  1.223330  1.223330  ...  1.340090 -0.998842      0\n","600         600  1.223330  1.223330  ...  1.340090  0.998842      0\n","\n","[601 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","monks-3.csv\n","\n","     Unnamed: 0        f1        f2  ...        f5        f6  clase\n","0             0  0.490585  0.428121  ...  0.237339  2.143340      1\n","1             1  0.490585  0.428121  ...  1.026040  0.779683      1\n","2             2  0.490585  0.428121  ...  1.026040  2.143340      1\n","3             3  0.490585  0.428121  ...  1.814730  0.779683      0\n","4             4  0.490585  0.428121  ...  2.603430  0.779683      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","549         549  1.223330  1.223330  ... -0.446696  0.998842      0\n","550         550  1.223330  1.223330  ...  0.446696 -0.998842      0\n","551         551  1.223330  1.223330  ...  0.446696  0.998842      0\n","552         552  1.223330  1.223330  ...  1.340090 -0.998842      0\n","553         553  1.223330  1.223330  ...  1.340090  0.998842      0\n","\n","[554 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","mushroom.csv\n","\n","      Unnamed: 0        f1        f2  ...       f20       f21  clase\n","0              0 -0.545748  1.065600  ... -0.514358  0.307792      1\n","1              1 -0.545748  1.065600  ... -1.313030 -1.272800      0\n","2              2 -2.764800  1.065600  ... -1.313030 -0.482506      0\n","3              3 -0.545748  0.217879  ... -0.514358  0.307792      1\n","4              4 -0.545748  1.065600  ... -2.910370 -1.272800      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","8119        8119  1.673300  1.065600  ... -2.111700 -0.877655      0\n","8120        8120 -0.545748  1.065600  ...  0.284312 -0.877655      0\n","8121        8121  0.563776  1.065600  ... -2.111700 -0.877655      0\n","8122        8122  1.673300  0.217879  ...  0.284312 -0.877655      1\n","8123        8123 -0.545748  1.065600  ... -2.111700 -0.877655      0\n","\n","[8124 rows x 23 columns]\n","22\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","musk-1.csv\n","\n","     Unnamed: 0        f1        f2  ...      f165      f166  clase\n","0             0  0.180723 -0.881600  ...  0.555801 -0.068543      1\n","1             1  0.180723 -0.802337  ...  0.538563 -0.068543      1\n","2             2  0.180723 -0.802337  ...  0.538563 -0.050089      1\n","3             3  0.180723 -0.881600  ...  0.555801 -0.068543      1\n","4             4  0.180723 -0.881600  ...  0.693711 -0.142359      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","471         471  0.567721 -0.892923  ...  0.193790 -0.806699      0\n","472         472 -0.040419 -0.032352  ...  0.521324  0.743429      0\n","473         473  0.236008  0.205437  ...  0.124835 -1.286500      0\n","474         474  0.014867  0.703662  ...  0.504085  0.743429      0\n","475         475  0.733577 -0.009706  ...  0.659233  1.149410      0\n","\n","[476 rows x 168 columns]\n","167\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","oocytes_merluccius_nucleus_4d.csv\n","\n","      Unnamed: 0       f1       f2       f3  ...      f39      f40      f41  clase\n","0              0 -0.66583  0.87068  0.20516  ...  0.84426  0.82785  0.84868      1\n","1              1 -0.57054  0.43110 -0.03807  ...  0.36387  0.28662  0.26291      1\n","2              2 -0.35195  0.85706  1.09299  ...  0.99675  1.06345  1.09860      1\n","3              3  5.14385 -2.05174 -1.04042  ... -1.60085 -1.56880 -1.55293      1\n","4              4 -0.52017  0.69792  0.26792  ...  0.64029  0.65730  0.69135      1\n","...          ...      ...      ...      ...  ...      ...      ...      ...    ...\n","1017        1017 -0.67901  1.36021  1.58665  ...  1.61590  1.60920  1.59639      1\n","1018        1018  3.85452 -1.74393 -0.90185  ... -1.33751 -1.30136 -1.28101      1\n","1019        1019 -0.71009  1.30292  1.42301  ...  1.44609  1.48844  1.50363      1\n","1020        1020  0.60817 -0.80616 -0.81323  ... -1.25243 -1.23426 -1.22974      1\n","1021        1021  0.16332 -0.88682 -0.88774  ... -0.83327 -0.80755 -0.77084      0\n","\n","[1022 rows x 43 columns]\n","42\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","oocytes_merluccius_states_2f.csv\n","\n","      Unnamed: 0        f1        f2  ...       f24       f25  clase\n","0              0 -1.179380 -2.187880  ... -0.118442  0.762846      2\n","1              1 -1.392120 -1.153970  ... -0.380753  0.419105      2\n","2              2  0.496807 -0.239263  ...  1.874060  0.965877      2\n","3              3 -2.020400 -1.050940  ... -0.589791 -1.725570      1\n","4              4 -0.949725 -1.428900  ...  0.514058  0.740187      2\n","...          ...       ...       ...  ...       ...       ...    ...\n","1017        1017  0.849184  0.046527  ...  1.116800  1.400070      2\n","1018        1018 -1.689340  0.049266  ... -0.371318 -1.583980      1\n","1019        1019  0.764456  0.560675  ...  0.991325  1.416910      2\n","1020        1020 -1.396220 -0.027077  ... -0.393457 -0.412658      1\n","1021        1021 -0.296385  0.284011  ... -0.664495 -0.903268      0\n","\n","[1022 rows x 27 columns]\n","26\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","oocytes_trisopterus_nucleus_2f.csv\n","\n","     Unnamed: 0        f1        f2  ...       f24       f25  clase\n","0             0  1.069570  1.026090  ... -0.238559 -0.100345      1\n","1             1  0.865225  1.007010  ... -0.549728 -0.960983      1\n","2             2  0.470672  0.831544  ... -0.553146 -1.392640      0\n","3             3  0.693030  0.440988  ...  0.880447  0.750328      1\n","4             4 -0.036550 -0.069342  ...  2.072160  1.947350      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","907         907 -2.240880 -2.084740  ... -0.083684  0.984030      1\n","908         908 -2.249550 -2.436180  ... -0.169517  0.888902      1\n","909         909 -2.274820 -2.574890  ... -0.501495 -0.179252      1\n","910         910 -2.228770 -2.109480  ... -0.540793 -0.676919      0\n","911         911 -2.324960 -2.361930  ... -0.302064  0.837900      1\n","\n","[912 rows x 27 columns]\n","26\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","oocytes_trisopterus_states_5b.csv\n","\n","     Unnamed: 0        f1        f2  ...       f31       f32  clase\n","0             0 -0.060327 -0.364650  ... -0.882776 -0.887593      1\n","1             1  0.421689 -0.791496  ... -0.855251 -0.871742      0\n","2             2  0.531289 -1.042850  ... -0.927451 -0.930379      0\n","3             3 -0.636291  0.825897  ...  0.579962  0.607756      2\n","4             4 -0.860368  1.868300  ...  2.439090  2.387320      2\n","..          ...       ...       ...  ...       ...       ...    ...\n","907         907 -0.715138  0.713209  ...  0.430934  0.436670      2\n","908         908 -0.743102  0.839040  ...  0.678978  0.667884      2\n","909         909  0.601100 -0.964491  ... -0.989797 -0.936246      2\n","910         910  1.936950 -1.632370  ... -1.334850 -1.286000      0\n","911         911 -0.636921  0.455490  ... -0.077408 -0.057329      2\n","\n","[912 rows x 34 columns]\n","33\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","ozone.csv\n","\n","      Unnamed: 0        f1        f2  ...       f71       f72  clase\n","0              0 -0.495591  0.305248  ... -1.582260 -0.282034      0\n","1              1  1.034600  1.386190  ... -1.582260 -0.282034      0\n","2              2  1.111110  1.077350  ... -1.149770 -0.282034      0\n","3              3  2.488270  1.849450  ... -1.149770  1.297310      0\n","4              4  0.881577  0.536878  ...  0.003524  0.158360      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","2531        2531 -0.878138 -0.775693  ...  1.877630 -0.282034      0\n","2532        2532 -0.342572 -0.003593  ...  0.436011 -0.282034      0\n","2533        2533 -0.495591 -0.466853  ... -1.005610 -0.282034      0\n","2534        2534 -0.113044 -0.389643  ... -0.861448 -0.244069      0\n","2535        2535  0.039974 -0.080803  ... -0.717286 -0.282034      0\n","\n","[2536 rows x 74 columns]\n","73\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","parkinsons.csv\n","\n","     Unnamed: 0        f1        f2  ...       f21       f22  clase\n","0             0 -0.827171 -0.435045  ... -0.209990  0.866655      1\n","1             1 -0.768992 -0.529611  ...  0.274371  1.798970      1\n","2             2 -0.907141 -0.721312  ... -0.103363  1.399060      1\n","3             3 -0.907286 -0.647425  ...  0.061985  1.802310      1\n","4             4 -0.923281 -0.604689  ... -0.129692  2.261260      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","190         190  0.482226  0.370232  ...  0.720090 -0.815604      0\n","191         191  1.335760  0.611117  ...  1.051430 -0.417853      0\n","192         192  0.494306  0.468897  ...  0.778335 -0.830273      0\n","193         193  1.075990  2.184420  ... -0.635368 -0.923727      0\n","194         194  1.451080  0.690469  ...  0.453635 -0.643399      0\n","\n","[195 rows x 24 columns]\n","23\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","pima.csv\n","\n","     Unnamed: 0        f1        f2  ...        f7        f8  clase\n","0             0  0.639530  0.847771  ...  0.468187  1.425070      1\n","1             1 -0.844335 -1.122660  ... -0.364823 -0.190548      0\n","2             2  1.233080  1.942460  ...  0.604004 -0.105515      1\n","3             3 -0.844335 -0.997558  ... -0.920163 -1.040870      0\n","4             4 -1.141110  0.503727  ...  5.481340 -0.020483      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","763         763  1.826620 -0.622237  ... -0.908090  2.530490      0\n","764         764 -0.547562  0.034576  ... -0.398023 -0.530677      0\n","765         765  0.342757  0.003299  ... -0.684747 -0.275580      0\n","766         766 -0.844335  0.159683  ... -0.370859  1.169970      1\n","767         767 -0.844335 -0.872451  ... -0.473476 -0.870806      0\n","\n","[768 rows x 10 columns]\n","9\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","pittsburg-bridges-MATERIAL.csv\n","\n","     Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0             0  0.503814 -1.627760  ... -0.201322 -1.454630      0\n","1             1 -0.831293 -0.039967  ... -0.201322 -1.454630      0\n","2             2 -0.831293  0.970444  ... -0.912659 -1.454630      0\n","3             3 -0.831293  0.248722  ... -0.201322 -1.454630      0\n","4             4  0.503814 -0.184311  ... -0.201322 -1.454630      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","101         101 -0.831293  0.537411  ...  1.221350  0.574195      2\n","102         102  0.503814 -1.194720  ...  1.221350  0.574195      2\n","103         103 -0.831293 -0.112139  ...  2.644030  0.574195      2\n","104         104  1.838920  1.331310  ...  2.644030  0.574195      2\n","105         105  0.503814 -1.339070  ...  2.644030  0.574195      2\n","\n","[106 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","pittsburg-bridges-REL-L.csv\n","\n","     Unnamed: 0        f1        f2  ...        f6       f7  clase\n","0             0  0.521950 -1.633560  ... -0.137463 -1.42413      0\n","1             1 -0.822072 -0.041248  ... -0.137463 -1.42413      0\n","2             2 -0.822072  0.972039  ... -0.924055 -1.42413      0\n","3             3 -0.822072  0.248262  ... -0.137463 -1.42413      0\n","4             4  0.521950 -0.186004  ... -0.137463 -1.42413      0\n","..          ...       ...       ...  ...       ...      ...    ...\n","98           98  1.865970  1.189170  ... -1.710650  0.58526      2\n","99           99  1.865970  1.551060  ... -0.137463  0.58526      2\n","100         100  0.521950 -1.778310  ...  3.008910  0.58526      2\n","101         101 -0.822072  0.537773  ...  1.435720  0.58526      1\n","102         102  0.521950 -1.199290  ...  1.435720  0.58526      2\n","\n","[103 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","pittsburg-bridges-SPAN.csv\n","\n","    Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0            0  0.566922 -1.646160  ... -0.056886 -1.337370      0\n","1            1 -0.805626 -0.028532  ... -0.056886 -1.337370      0\n","2            2 -0.805626  1.000870  ... -0.929132 -1.337370      0\n","3            3 -0.805626  0.265582  ... -0.056886 -1.337370      0\n","4            4  0.566922 -0.175589  ... -0.056886 -1.337370      0\n","..         ...       ...       ...  ...       ...       ...    ...\n","87          87 -0.805626  1.037630  ...  1.687610  0.615613      1\n","88          88 -0.805626  1.052340  ... -0.056886  0.615613      1\n","89          89 -0.805626  0.964104  ... -0.056886 -1.337370      1\n","90          90  1.939470  1.662630  ... -0.056886  0.615613      2\n","91          91 -2.178170  1.956740  ... -1.801380  0.615613      1\n","\n","[92 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","pittsburg-bridges-T-OR-D_R.csv\n","\n","     Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0             0  0.525186 -1.649010  ... -0.124053 -1.413820      0\n","1             1 -0.814039 -0.053125  ... -0.124053 -1.413820      0\n","2             2 -0.814039  0.962439  ... -0.914891 -1.413820      0\n","3             3 -0.814039  0.237036  ... -0.124053 -1.413820      0\n","4             4  0.525186 -0.198206  ... -0.124053 -1.413820      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","97           97 -0.814039  0.817358  ...  1.457620 -1.413820      1\n","98           98  1.864410  1.180060  ... -1.705730  0.589094      0\n","99           99  1.864410  1.542760  ... -0.124053  0.589094      0\n","100         100  0.525186 -1.794090  ...  3.039300  0.589094      0\n","101         101 -0.814039  0.527197  ...  1.457620  0.589094      1\n","\n","[102 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","pittsburg-bridges-TYPE.csv\n","\n","     Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0             0  0.495178 -1.618130  ... -0.218542 -1.444530      0\n","1             1 -0.837993 -0.030717  ... -0.218542 -1.444530      0\n","2             2 -0.837993  0.979454  ... -0.935635 -1.444530      0\n","3             3 -0.837993  0.257903  ... -0.218542 -1.444530      0\n","4             4  0.495178 -0.175028  ... -0.218542 -1.444530      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","100         100 -0.837993  0.546524  ...  1.215640  0.577813      5\n","101         101  0.495178 -1.185200  ...  1.215640  0.577813      5\n","102         102 -0.837993 -0.102873  ...  2.649830  0.577813      3\n","103         103  1.828350  1.340230  ...  2.649830  0.577813      3\n","104         104  0.495178 -1.329510  ...  2.649830  0.577813      3\n","\n","[105 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","planning.csv\n","\n","     Unnamed: 0        f1        f2  ...       f11       f12  clase\n","0             0 -0.351883 -0.530606  ... -0.002265 -0.987931      0\n","1             1 -0.284001 -0.421044  ... -0.063014  0.212911      0\n","2             2 -0.252349  1.358370  ...  0.243928  1.901720      1\n","3             3  1.364870  1.099500  ...  1.048220  1.723690      0\n","4             4 -0.821941  0.308253  ... -0.381211  0.564927      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","177         177 -1.119760  0.728321  ... -0.005490 -0.288244      1\n","178         178 -1.604360  0.671821  ... -0.072911  1.999710      0\n","179         179  0.638549 -0.459284  ...  0.705566 -1.152280      1\n","180         180 -0.763609 -1.353420  ...  0.009971  1.437280      0\n","181         181  0.805012 -0.112679  ...  0.492909  1.480980      1\n","\n","[182 rows x 14 columns]\n","13\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","plant-margin.csv\n","\n","      Unnamed: 0        f1        f2  ...       f63       f64  clase\n","0              0 -0.689954 -0.635367  ... -0.394050 -0.471823      0\n","1              1 -0.590266 -0.381682  ...  1.091280 -0.471823      0\n","2              2 -0.291153 -0.686098  ... -0.493065 -0.471823      0\n","3              3 -0.191465 -0.432414  ...  0.101078 -0.471823      0\n","4              4 -0.490579 -0.483145  ... -0.592080 -0.471823      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1595        1595  0.905148 -0.026534  ... -1.087210 -0.471823     99\n","1596        1596 -0.091778 -0.483145  ... -1.087210  1.299270     99\n","1597        1597 -0.191465 -0.584635  ... -0.790111  0.635155     99\n","1598        1598 -0.091778 -0.330950  ... -1.087210  0.635155     99\n","1599        1599  0.107597 -0.381682  ... -0.988193  3.070370     99\n","\n","[1600 rows x 66 columns]\n","65\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","plant-shape.csv\n","\n","      Unnamed: 0        f1        f2  ...       f63       f64  clase\n","0              0 -0.585385 -0.402099  ... -0.326183 -0.430958      1\n","1              1 -0.394504 -0.205486  ... -0.117370 -0.232506      1\n","2              2 -0.446232 -0.377145  ... -0.365449 -0.474701      1\n","3              3 -0.459702 -0.550768  ... -0.337773 -0.473350      1\n","4              4 -0.508869 -0.614494  ... -0.351146 -0.504975      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","1595        1595  0.013754  0.010231  ...  0.384563  0.042139     99\n","1596        1596 -0.240470 -0.244899  ... -0.271644 -0.248787     99\n","1597        1597 -0.133489 -0.276309  ... -0.307267 -0.247512     99\n","1598        1598 -0.103172  0.230818  ... -0.068607 -0.099591     99\n","1599        1599  0.419450  0.205410  ...  0.422434  0.253647     99\n","\n","[1600 rows x 66 columns]\n","65\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","plant-texture.csv\n","\n","      Unnamed: 0        f1        f2  ...       f63       f64  clase\n","0              0  0.097574  0.057117  ... -0.664316  0.321163      0\n","1              1 -0.400858  0.391199  ... -0.664316 -0.743886      0\n","2              2 -0.068570  0.112817  ... -0.664316 -0.616110      0\n","3              3  0.334905  0.669581  ... -0.664316  0.108144      0\n","4              4  0.406117  0.168459  ... -0.664316 -0.190073      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1594        1594 -0.377137 -0.555289  ...  1.127100 -0.530911     99\n","1595        1595 -0.495790 -0.555289  ... -0.664316 -0.701308     99\n","1596        1596 -0.210993 -0.388249  ... -0.377707 -0.488290     99\n","1597        1597 -0.495790 -0.555289  ... -0.664316 -0.317892     99\n","1598        1598 -0.258459  0.335500  ... -0.377707 -0.317892     99\n","\n","[1599 rows x 66 columns]\n","65\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","post-operative.csv\n","\n","    Unnamed: 0        f1        f2  ...        f7        f8  clase\n","0            0  0.111882 -1.337670  ... -0.031621  1.471360      0\n","1            1  0.111882  1.598680  ... -0.031621 -0.192238      2\n","2            2  1.790110 -1.337670  ... -1.454570 -0.192238      0\n","3            3  0.111882 -1.337670  ... -1.454570  1.471360      0\n","4            4  0.111882  0.130505  ... -0.031621 -0.192238      0\n","..         ...       ...       ...  ...       ...       ...    ...\n","85          85  0.111882  0.130505  ... -0.031621 -0.192238      0\n","86          86  0.111882  0.130505  ... -0.031621  1.471360      2\n","87          87  0.111882  0.130505  ... -0.031621  1.471360      0\n","88          88  0.111882  0.130505  ... -0.031621 -0.192238      0\n","89          89  0.111882  0.130505  ... -0.031621  1.471360      2\n","\n","[90 rows x 10 columns]\n","9\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","seeds.csv\n","\n","     Unnamed: 0        f1        f2  ...        f6        f7  clase\n","0             0  0.141759  0.214949  ... -0.983801 -0.382663      0\n","1             1  0.011161  0.008204  ... -1.783900 -0.919816      0\n","2             2 -0.191609 -0.359342  ... -0.665888 -1.186360      0\n","3             3 -0.346264 -0.474200  ... -0.958528 -1.227050      0\n","4             4  0.444196  0.329807  ... -1.559770 -0.474223      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","205         205 -0.913333 -1.040830  ... -0.046025 -1.094800      2\n","206         206 -1.243260 -1.285860  ...  0.415547 -0.824186      2\n","207         207 -0.566218 -0.688602  ...  3.069250 -0.716349      2\n","208         208 -1.033620 -1.033180  ... -0.067973 -0.740765      2\n","209         209 -0.875528 -0.933633  ...  1.288140 -0.702106      2\n","\n","[210 rows x 9 columns]\n","8\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","semeion.csv\n","\n","      Unnamed: 0        f1        f2  ...      f255      f256  clase\n","0              0 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","1              1 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","2              2 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","3              3 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","4              4 -0.324678 -0.426189  ... -0.321124 -0.206186      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1588        1588 -0.324678 -0.426189  ...  3.112100 -0.206186      9\n","1589        1589 -0.324678 -0.426189  ... -0.321124 -0.206186      9\n","1590        1590 -0.324678 -0.426189  ... -0.321124 -0.206186      9\n","1591        1591 -0.324678  2.344910  ... -0.321124 -0.206186      9\n","1592        1592 -0.324678 -0.426189  ... -0.321124 -0.206186      9\n","\n","[1593 rows x 258 columns]\n","257\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","soybean.csv\n","\n","     Unnamed: 0            f1            f2  ...           f34           f35  clase\n","0             0  1.441970e+00 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","1             1  2.800680e-01 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","2             2 -3.008840e-01 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","3             3 -3.008840e-01 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","4             4  1.441970e+00 -9.081220e-01  ... -2.341020e-01 -3.650990e-01      0\n","..          ...           ...           ...  ...           ...           ...    ...\n","678         678 -5.470000e-16 -1.610000e-16  ...  4.870000e-16 -3.490000e-17      0\n","679         679 -5.470000e-16  1.000000e+00  ...  4.870000e-16  1.000000e+00     17\n","680         680  2.000000e+00  1.000000e+00  ...  4.870000e-16  1.000000e+00     17\n","681         681 -5.470000e-16  1.000000e+00  ...  4.870000e-16  1.000000e+00     17\n","682         682  2.000000e+00  1.000000e+00  ...  4.870000e-16  1.000000e+00     17\n","\n","[683 rows x 37 columns]\n","36\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","spambase.csv\n","\n","      Unnamed: 0        f1        f2  ...       f56       f57  clase\n","0              0 -0.342396  0.330849  ...  0.045293 -0.008723      1\n","1              1  0.345322  0.051904  ...  0.250536  1.228190      1\n","2              2 -0.145906 -0.165054  ...  2.220860  3.258380      1\n","3              3 -0.342396 -0.165054  ... -0.062459 -0.152205      1\n","4              4 -0.342396 -0.165054  ... -0.062459 -0.152205      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","4596        4596  0.672807 -0.165054  ... -0.252309 -0.322075      0\n","4597        4597 -0.342396 -0.165054  ... -0.247178 -0.444117      0\n","4598        4598  0.640058 -0.165054  ... -0.236916 -0.272598      0\n","4599        4599  2.801460 -0.165054  ... -0.242047 -0.338567      0\n","4600        4600 -0.342396 -0.165054  ... -0.242047 -0.401237      0\n","\n","[4601 rows x 59 columns]\n","58\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","spect.csv\n","\n","     Unnamed: 0            f1            f2  ...           f21           f22  clase\n","0             0  9.811510e-01 -7.362540e-01  ... -5.397650e-01 -5.591580e-01      0\n","1             1  9.811510e-01 -7.362540e-01  ... -5.397650e-01 -5.591580e-01      1\n","2             2  9.811510e-01  1.341030e+00  ... -5.397650e-01 -5.591580e-01      0\n","3             3  9.811510e-01 -7.362540e-01  ...  1.829210e+00  1.765760e+00      1\n","4             4  9.811510e-01 -7.362540e-01  ... -5.397650e-01 -5.591580e-01      0\n","..          ...           ...           ...  ...           ...           ...    ...\n","260         260  2.250000e-17 -3.930000e-17  ... -9.560000e-17 -2.700000e-16      0\n","261         261  2.250000e-17 -3.930000e-17  ... -9.560000e-17 -2.700000e-16      0\n","262         262  2.250000e-17  1.000000e+00  ... -9.560000e-17 -2.700000e-16      0\n","263         263  2.250000e-17  1.000000e+00  ... -9.560000e-17 -2.700000e-16      0\n","264         264  2.250000e-17  1.000000e+00  ... -9.560000e-17 -2.700000e-16      0\n","\n","[265 rows x 24 columns]\n","23\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","spectf.csv\n","\n","     Unnamed: 0        f1        f2  ...       f43       f44  clase\n","0             0  0.865112  0.683281  ...  1.398350  1.527330      1\n","1             1  1.244660  0.979054  ...  1.119050  1.210880      1\n","2             2  1.215470  0.979054  ...  0.944490  0.788953      1\n","3             3  1.157070  1.245250  ...  1.223790  1.386690      1\n","4             4  1.186270  1.097360  ...  0.874666  0.613150      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","262         262  0.989924  0.513293  ...  0.215094  0.557168      0\n","263         263  0.766758 -0.274283  ...  0.364899  0.225774      0\n","264         264  1.101510  0.907082  ...  1.188820  1.485070      0\n","265         265 -0.683817 -0.175836  ...  1.413530  1.418790      0\n","266         266 -0.125903  0.217952  ...  0.439801  0.358331      0\n","\n","[267 rows x 46 columns]\n","45\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","statlog-australian-credit.csv\n","\n","     Unnamed: 0        f1        f2  ...       f13       f14  clase\n","0             0 -0.800471  1.346130  ...  0.037353 -0.894654      1\n","1             1 -0.750696  0.450221  ... -0.195272 -0.894654      0\n","2             2 -0.167735 -0.604384  ... -0.195272 -0.894654      0\n","3             3 -0.835061  1.354170  ... -0.195272  1.116130      0\n","4             4 -0.961608  0.685248  ... -0.164946  1.116130      1\n","..          ...       ...       ...  ...       ...       ...    ...\n","685         685  0.000152  1.153290  ... -0.195272  1.116130      1\n","686         686 -0.919426 -0.872556  ... -0.186827 -0.894654      1\n","687         687 -1.074660  0.960450  ... -0.195272  1.116130      0\n","688         688 -0.349963  1.956800  ... -0.193160  1.116130      0\n","689         689  0.795712 -0.947885  ... -0.195272  1.116130      1\n","\n","[690 rows x 16 columns]\n","15\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","statlog-german-credit.csv\n","\n","     Unnamed: 0        f1        f2  ...      f23       f24  clase\n","0             0 -1.253940 -1.235860  ... -0.49975  0.765973      0\n","1             1 -0.458797  2.247070  ... -0.49975  0.765973      1\n","2             2  1.131490 -0.738298  ...  1.99900 -1.304220      0\n","3             3 -1.253940  1.749510  ... -0.49975  0.765973      0\n","4             4 -1.253940  0.256825  ... -0.49975  0.765973      1\n","..          ...       ...       ...  ...      ...       ...    ...\n","995         995  1.131490 -0.738298  ...  1.99900 -1.304220      0\n","996         996 -1.253940  0.754386  ... -0.49975 -1.304220      0\n","997         997  1.131490 -0.738298  ... -0.49975  0.765973      0\n","998         998 -1.253940  1.998290  ... -0.49975  0.765973      1\n","999         999 -0.458797  1.998290  ... -0.49975  0.765973      0\n","\n","[1000 rows x 26 columns]\n","25\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","statlog-heart_.csv\n","\n","     Unnamed: 0        f1        f2  ...       f12       f13  clase\n","0             0  1.708920  0.688222  ...  2.468100 -0.874083      1\n","1             1  1.379580 -1.447640  ... -0.710216  1.187070      0\n","2             2  0.281771  0.688222  ... -0.710216  1.187070      1\n","3             3  1.050240  0.688222  ...  0.349222  1.187070      0\n","4             4  2.148040 -1.447640  ...  0.349222 -0.874083      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","265         265 -0.267133  0.688222  ... -0.710216  1.187070      0\n","266         266 -1.145380  0.688222  ... -0.710216  1.187070      0\n","267         267  0.171990 -1.447640  ... -0.710216 -0.874083      0\n","268         268  0.281771  0.688222  ... -0.710216  0.671784      0\n","269         269  1.379580  0.688222  ...  2.468100 -0.874083      1\n","\n","[270 rows x 15 columns]\n","14\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","statlog-image.csv\n","\n","      Unnamed: 0        f1        f2  ...       f17       f18  clase\n","0              0  1.275910  0.949531  ... -0.472589 -0.438518      5\n","1              1 -0.163301  0.114514  ...  2.510220 -0.492034      2\n","2              2  1.056600 -1.433750  ... -0.996657 -0.606354      1\n","3              3 -1.273550  0.862550  ... -0.700712 -0.411536      5\n","4              4 -0.876054  1.280060  ... -0.542984 -0.426689      5\n","...          ...       ...       ...  ...       ...       ...    ...\n","2305        2305 -1.300960 -0.372580  ... -0.200752 -0.124374      0\n","2306        2306  0.247903 -1.729480  ... -1.127840 -0.638279      1\n","2307        2307 -0.615625 -0.894465  ... -0.491818 -0.470658      3\n","2308        2308 -0.368903  0.166702  ...  2.510220 -0.492034      2\n","2309        2309 -1.451740  0.410249  ...  1.254150 -0.072959      0\n","\n","[2310 rows x 20 columns]\n","19\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","statlog-vehicle.csv\n","\n","     Unnamed: 0        f1        f2  ...       f17       f18  clase\n","0             0  0.160485  0.508649  ... -0.313537  0.183849      3\n","1             1 -0.325277 -0.625897  ...  0.010931  0.452709      3\n","2             2  1.253450  0.832805  ... -0.151303  0.049418      2\n","3             3 -0.082396 -0.625897  ...  1.633270  1.528150      3\n","4             4 -1.053920 -0.139663  ... -1.449170 -1.698180      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","841         841 -0.082396 -0.950053  ... -0.151303 -0.085012      2\n","842         842 -0.568159  0.184493  ... -0.475770  0.183849      3\n","843         843  1.496330  1.481120  ... -0.313537  0.721570      2\n","844         844 -0.932481 -1.436290  ...  0.173164 -0.085012      2\n","845         845 -1.053920 -1.436290  ... -0.475770 -0.757164      3\n","\n","[846 rows x 20 columns]\n","19\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","steel-plates.csv\n","\n","      Unnamed: 0        f1        f2  ...       f26       f27  clase\n","0              0 -1.016220 -1.141340  ... -1.075470 -0.009487      0\n","1              1  0.141858  0.066386  ... -0.297747 -0.845541      0\n","2              2  0.495235  0.436141  ...  0.057170 -1.091230      0\n","3              3  0.541327  0.486379  ... -0.171375 -0.189189      0\n","4              4  1.378680  1.382630  ... -0.456385  1.221320      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","1936        1936 -0.618671 -0.685180  ...  0.900100  0.412369      6\n","1937        1937 -0.820326 -0.890153  ...  0.491407  0.683100      6\n","1938        1938 -0.818405 -0.892162  ...  0.917577  0.360816      6\n","1939        1939 -0.833770 -0.900201  ...  0.767678  1.197460      6\n","1940        1940  1.324900  1.332390  ...  0.116995 -0.164443      6\n","\n","[1941 rows x 29 columns]\n","28\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","synthetic-control.csv\n","\n","     Unnamed: 0        f1        f2  ...       f59       f60  clase\n","0             0 -0.354718  0.853862  ... -0.291262 -0.277970      0\n","1             1 -1.467260 -1.243980  ...  0.134039 -0.224873      0\n","2             2  0.394101 -0.067707  ... -0.029786 -0.053001      0\n","3             3 -1.215020 -0.093058  ... -0.169434 -0.314574      0\n","4             4 -0.812849 -0.400055  ...  0.070275  0.055547      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","595         595 -0.113208 -1.301130  ... -0.599440 -0.390918      5\n","596         596 -0.745734 -1.326650  ... -1.283800 -1.259920      5\n","597         597  1.681550 -1.020090  ... -0.764354 -0.822167      5\n","598         598 -1.568530 -1.595330  ... -1.090340 -0.823126      5\n","599         599  1.234240  0.005868  ... -1.173640 -1.296730      5\n","\n","[600 rows x 62 columns]\n","61\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","teaching.csv\n","\n","     Unnamed: 0        f1        f2        f3       f4        f5  clase\n","0             0 -2.044270  1.370920 -0.726939 -2.35125 -0.687740      2\n","1             1  0.485933  0.198895 -0.726939 -2.35125 -0.842854      2\n","2             2 -2.044270  1.370920 -0.726939  0.42249  1.638970      2\n","3             3 -2.044270 -1.266140 -0.869310  0.42249  0.398057      2\n","4             4  0.485933 -0.973132  0.412027  0.42249  2.104310      2\n","..          ...       ...       ...       ...      ...       ...    ...\n","146         146  0.485933 -1.559150 -0.869310  0.42249 -0.144841      0\n","147         147  0.485933 -0.533622 -0.726939  0.42249 -1.230640      0\n","148         148 -2.044270  0.638406 -0.157456  0.42249  1.561410      0\n","149         149  0.485933  1.224420 -1.011680  0.42249  1.794080      0\n","150         150  0.485933 -1.705650  0.269656  0.42249 -0.067284      0\n","\n","[151 rows x 7 columns]\n","6\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","tic-tac-toe.csv\n","\n","     Unnamed: 0       f1       f2       f3  ...        f7        f8        f9  clase\n","0             0 -1.03463 -1.10625 -1.03463  ... -1.034630  1.222960  1.230910      1\n","1             1 -1.03463 -1.10625 -1.03463  ...  1.230910 -1.106250  1.230910      1\n","2             2 -1.03463 -1.10625 -1.03463  ...  1.230910  1.222960 -1.034630      1\n","3             3 -1.03463 -1.10625 -1.03463  ...  1.230910  0.058352  0.098142      1\n","4             4 -1.03463 -1.10625 -1.03463  ...  0.098142  1.222960  0.098142      1\n","..          ...      ...      ...      ...  ...       ...       ...       ...    ...\n","953         953  1.23091 -1.10625 -1.03463  ...  1.230910 -1.106250 -1.034630      0\n","954         954  1.23091 -1.10625  1.23091  ... -1.034630  1.222960 -1.034630      0\n","955         955  1.23091 -1.10625  1.23091  ... -1.034630  1.222960 -1.034630      0\n","956         956  1.23091 -1.10625  1.23091  ... -1.034630  1.222960 -1.034630      0\n","957         957  1.23091  1.22296 -1.03463  ...  1.230910 -1.106250 -1.034630      0\n","\n","[958 rows x 11 columns]\n","10\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","titanic.csv\n","\n","      Unnamed: 0        f1       f2        f3  clase\n","0              0 -1.866520 -0.22821  0.520957      1\n","1              1 -1.866520 -0.22821  0.520957      1\n","2              2 -1.866520 -0.22821  0.520957      1\n","3              3 -1.866520 -0.22821  0.520957      1\n","4              4 -1.866520 -0.22821  0.520957      1\n","...          ...       ...      ...       ...    ...\n","2196        2196  0.965424 -0.22821 -1.918670      1\n","2197        2197  0.965424 -0.22821 -1.918670      1\n","2198        2198  0.965424 -0.22821 -1.918670      0\n","2199        2199  0.965424 -0.22821 -1.918670      0\n","2200        2200  0.965424 -0.22821 -1.918670      0\n","\n","[2201 rows x 5 columns]\n","4\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","vertebral-column-2clases.csv\n","\n","     Unnamed: 0        f1        f2  ...        f5        f6  clase\n","0             0  0.146989  0.500302  ... -1.445490 -0.706803      0\n","1             1 -1.243700 -0.747682  ... -0.263602 -0.578738      0\n","2             2  0.483492  0.467329  ... -0.895846 -0.794133      0\n","3             3  0.510760  0.710132  ... -1.205210 -0.401682      0\n","4             4 -0.625807 -0.788648  ... -0.732153 -0.489278      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","305         305 -0.730819 -0.391971  ... -0.035333 -0.813303      1\n","306         306 -0.380392  0.317451  ... -0.266605 -0.711330      1\n","307         307  0.055321  0.514291  ...  0.581894 -0.772300      1\n","308         308 -0.884566 -0.884570  ...  0.047265 -0.694556      1\n","309         309 -1.546550 -1.246280  ...  0.452742 -0.705472      1\n","\n","[310 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","vertebral-column-3clases.csv\n","\n","     Unnamed: 0        f1        f2  ...        f5        f6  clase\n","0             0  0.146989  0.500302  ... -1.445490 -0.706803      0\n","1             1 -1.243700 -0.747682  ... -0.263602 -0.578738      0\n","2             2  0.483492  0.467329  ... -0.895846 -0.794133      0\n","3             3  0.510760  0.710132  ... -1.205210 -0.401682      0\n","4             4 -0.625807 -0.788648  ... -0.732153 -0.489278      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","305         305 -0.730819 -0.391971  ... -0.035333 -0.813303      1\n","306         306 -0.380392  0.317451  ... -0.266605 -0.711330      1\n","307         307  0.055321  0.514291  ...  0.581894 -0.772300      1\n","308         308 -0.884566 -0.884570  ...  0.047265 -0.694556      1\n","309         309 -1.546550 -1.246280  ...  0.452742 -0.705472      1\n","\n","[310 rows x 8 columns]\n","7\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","wall-following.csv\n","\n","      Unnamed: 0        f1       f2  ...       f23       f24  clase\n","0              0 -1.287510 -1.29706  ... -0.863407 -0.999155      1\n","1              1 -1.287510 -1.29706  ... -0.861084 -0.999155      1\n","2              2 -1.287510 -1.29706  ... -0.858761 -0.999155      1\n","3              3 -1.288760 -1.29493  ... -0.860310 -0.999155      1\n","4              4 -1.287510 -1.29706  ... -0.862633 -0.999155      1\n","...          ...       ...      ...  ...       ...       ...    ...\n","5451        5451 -0.699572  1.89552  ...  2.667510 -0.014349      0\n","5452        5452 -0.679642  1.89552  ...  2.667510 -0.428958      2\n","5453        5453 -0.665940  1.89552  ...  2.667510 -0.411574      2\n","5454        5454 -0.655975  1.22325  ...  2.667510 -0.400275      0\n","5455        5455 -0.649747  1.23318  ...  2.667510 -0.356815      2\n","\n","[5456 rows x 26 columns]\n","25\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","waveform.csv\n","\n","      Unnamed: 0        f1        f2  ...       f20       f21  clase\n","0              0 -1.222760 -1.802050  ... -0.108477 -0.540208      2\n","1              1 -0.688173  1.984760  ...  0.224444  2.448570      1\n","2              2 -0.123889 -1.213630  ... -1.061000 -0.098912      0\n","3              3  0.846283 -0.046264  ... -1.421670  1.144740      1\n","4              4  1.143270  0.029662  ... -1.070250 -0.660561      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","4995        4995 -0.648574  0.333367  ...  0.677587 -1.402740      0\n","4996        4996 -0.024892  0.314385  ... -1.301440 -0.159089      1\n","4997        4997  0.004807 -2.210160  ...  0.788561 -0.249354      1\n","4998        4998 -0.401081  0.067625  ...  0.881039  1.395470      0\n","4999        4999  0.618589 -0.387931  ... -0.321177  0.623208      1\n","\n","[5000 rows x 23 columns]\n","22\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","waveform-noise.csv\n","\n","      Unnamed: 0        f1        f2  ...       f39       f40  clase\n","0              0 -0.211150 -1.478890  ... -0.519709  0.263329      2\n","1              1  0.398012  0.051827  ... -0.777011  0.193526      0\n","2              2 -0.670518  0.648710  ... -1.311410  0.971331      1\n","3              3  0.417985  0.340641  ... -1.608290  0.073864      0\n","4              4 -0.790353  1.216710  ...  0.925142  0.373019      1\n","...          ...       ...       ...  ...       ...       ...    ...\n","4995        4995  0.457930  0.225116  ...  1.429850  1.081020      0\n","4996        4996  1.196910 -0.776108  ... -0.094171  0.333132      1\n","4997        4997  0.657655  0.465794  ... -0.687945 -0.873463      2\n","4998        4998  0.198287  1.274480  ... -0.905662  0.602372      0\n","4999        4999  2.065720 -2.229810  ...  0.064169  0.582429      0\n","\n","[5000 rows x 42 columns]\n","41\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","wine.csv\n","\n","     Unnamed: 0        f1        f2  ...       f12       f13  clase\n","0             0  1.514340 -0.560668  ...  1.842720  1.010160      0\n","1             1  0.245597 -0.498009  ...  1.110320  0.962526      0\n","2             2  0.196325  0.021171  ...  0.786369  1.391220      0\n","3             3  1.686790 -0.345835  ...  1.180740  2.328010      0\n","4             4  0.294868  0.227053  ...  0.448336 -0.037768      0\n","..          ...       ...       ...  ...       ...       ...    ...\n","173         173  0.873810  2.966180  ... -1.227740 -0.021890      2\n","174         174  0.491955  1.408640  ... -1.481270  0.009866      2\n","175         175  0.331822  1.739840  ... -1.481270  0.279786      2\n","176         176  0.208643  0.227053  ... -1.396760  0.295664      2\n","177         177  1.391160  1.578710  ... -1.424930 -0.593486      2\n","\n","[178 rows x 15 columns]\n","14\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","wine-quality-red.csv\n","\n","      Unnamed: 0        f1        f2  ...       f10       f11  clase\n","0              0 -0.528194  0.961576  ... -0.579025 -0.959946      2\n","1              1 -0.298454  1.966830  ...  0.128910 -0.584594      2\n","2              2 -0.298454  1.296660  ... -0.048074 -0.584594      2\n","3              3  1.654340 -1.384010  ... -0.461036 -0.584594      3\n","4              4 -0.528194  0.961576  ... -0.579025 -0.959946      2\n","...          ...       ...       ...  ...       ...       ...    ...\n","1594        1594 -1.217420  0.403103  ... -0.461036  0.072271      2\n","1595        1595 -1.389720  0.123866  ...  0.600867  0.729136      3\n","1596        1596 -1.159980 -0.099523  ...  0.541872  0.541460      3\n","1597        1597 -1.389720  0.654416  ...  0.305894 -0.209243      2\n","1598        1598 -1.332290 -1.216470  ...  0.010921  0.541460      3\n","\n","[1599 rows x 13 columns]\n","12\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","wine-quality-white.csv\n","\n","      Unnamed: 0        f1        f2  ...       f10       f11  clase\n","0              0  0.172079 -0.081762  ... -0.349149 -1.393010      3\n","1              1 -0.657434  0.215874  ...  0.001342 -0.824192      3\n","2              2  1.475600  0.017450  ... -0.436771 -0.336633      3\n","3              3  0.409083 -0.478608  ... -0.787262 -0.499152      3\n","4              4  0.409083 -0.478608  ... -0.787262 -0.499152      3\n","...          ...       ...       ...  ...       ...       ...    ...\n","4893        4893 -0.775936 -0.677032  ...  0.088964  0.557225      3\n","4894        4894 -0.301928  0.414297  ... -0.261526 -0.742932      2\n","4895        4895 -0.420430 -0.379397  ... -0.261526 -0.905451      3\n","4896        4896 -1.605450  0.116662  ... -0.962507  1.857380      4\n","4897        4897 -1.012940 -0.677032  ... -1.488240  1.044780      3\n","\n","[4898 rows x 13 columns]\n","12\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","yeast.csv\n","\n","      Unnamed: 0        f1        f2  ...        f7        f8  clase\n","0              0  0.581785  0.888182  ... -0.344059 -0.527741      2\n","1              1 -0.510719  1.372350  ...  0.521044 -0.527741      2\n","2              2  1.018790  0.968876  ...  0.521044 -0.527741      2\n","3              3  0.581785 -0.483623  ...  0.694064 -0.527741      1\n","4              4 -0.583552 -0.483623  ... -0.344059 -0.527741      2\n","...          ...       ...       ...  ...       ...       ...    ...\n","1479        1479  2.256960  0.968876  ...  0.521044 -0.527741      4\n","1480        1480 -0.219384 -0.564317  ... -0.344059  1.819890      1\n","1481        1481  1.237290  0.565405  ...  1.040110 -0.527741      4\n","1482        1482 -0.510719 -0.806400  ...  0.521044  1.068640      1\n","1483        1483  1.091620  0.323321  ...  0.521044 -0.527741      0\n","\n","[1484 rows x 10 columns]\n","9\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","abalon.csv\n","\n","      Unnamed: 0        f1        f2  ...        f7        f8  class\n","0              0 -1.154210 -0.574489  ... -0.726125 -0.638140      2\n","1              1 -1.154210 -1.448810  ... -1.205080 -1.212840      0\n","2              2  0.053792  0.050027  ... -0.356647 -0.207114      1\n","3              3 -1.154210 -0.699393  ... -0.607527 -0.602222      1\n","4              4  1.261790 -1.615350  ... -1.287180 -1.320600      0\n","...          ...       ...       ...  ...       ...       ...    ...\n","4172        4172  0.053792  0.341468  ...  0.532836  0.073053      2\n","4173        4173 -1.154210  0.549640  ...  0.309325  0.155666      1\n","4174        4174 -1.154210  0.632909  ...  0.975296  0.496895      1\n","4175        4175  0.053792  0.841081  ...  0.733540  0.410690      1\n","4176        4176 -1.154210  1.548870  ...  1.787230  1.840260      2\n","\n","[4177 rows x 10 columns]\n","9\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n","\n","ar4.csv\n","\n","     Unnamed: 0  total_loc  ...  formal_parameters  label\n","0             0        103  ...                  0      0\n","1             1         53  ...                  1      0\n","2             2         25  ...                  2      0\n","3             3         73  ...                  0      0\n","4             4         69  ...                  0      0\n","..          ...        ...  ...                ...    ...\n","102         102         71  ...                  0      0\n","103         103         79  ...                  0      0\n","104         104         19  ...                  2      0\n","105         105        119  ...                  0      0\n","106         106          9  ...                  0      0\n","\n","[107 rows x 31 columns]\n","30\n","using bootstrap_samples\n","using build_feature_matrix\n","using modified_diagonal_distribute\n","using build_plus_feature_matrix\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ODBl8BIeE_GH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":108},"executionInfo":{"status":"ok","timestamp":1597611975277,"user_tz":-180,"elapsed":953,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"6fa946a2-5710-408d-874b-5a77fc7d4378"},"source":["arrfor_res = pd.DataFrame(result_list).drop(['AUC', 'Cross Validation','PR-Curve'],axis=1)\n","arrfor_res.mean(0)"],"execution_count":337,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Accuracy          0.740894\n","Precision         0.699383\n","Training Time     0.009698\n","Inference Time    0.005804\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":337}]},{"cell_type":"code","metadata":{"id":"l249UlSrEbla","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597611640701,"user_tz":-180,"elapsed":4878,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"6aeaca61-dc7b-4167-a253-97f5aa5a33d6"},"source":["result_list"],"execution_count":331,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'AUC': 0,\n","  'Accuracy': 0.9905660377358491,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'analcatdata_lawsuit.csv',\n","  'FPR': array([0.125, 0.   ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423137780>,\n","  'Inference Time': 0.004100349714171212,\n","  'PR-Curve': 0,\n","  'Precision': 0.994949494949495,\n","  'TPR': array([1.   , 0.875]),\n","  'Training Time': 0.002649068832397461},\n"," {'AUC': 0,\n","  'Accuracy': 0.9235074626865671,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'baseball.csv',\n","  'FPR': array([0.72340426, 0.00775194, 0.00589391]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423b01ac8>,\n","  'Inference Time': 0.0014540864460503876,\n","  'PR-Curve': 0,\n","  'Precision': 0.6449136276391555,\n","  'TPR': array([0.99591002, 0.3       , 0.07407407]),\n","  'Training Time': 0.008358478546142578},\n"," {'AUC': 0,\n","  'Accuracy': 0.8613861386138614,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'bodyfat.csv',\n","  'FPR': array([0.21568627, 0.06      ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423c60eb8>,\n","  'Inference Time': 0.0039775772850112155,\n","  'PR-Curve': 0,\n","  'Precision': 0.8702886928628708,\n","  'TPR': array([0.94      , 0.78431373]),\n","  'Training Time': 0.002907991409301758},\n"," {'AUC': 0,\n","  'Accuracy': 0.47058823529411764,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'analcatdata_asbestos.csv',\n","  'FPR': array([0.85      , 0.07142857]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142319ee48>,\n","  'Inference Time': 0.009045881383559282,\n","  'PR-Curve': 0,\n","  'Precision': 0.5916666666666667,\n","  'TPR': array([0.92857143, 0.15      ]),\n","  'Training Time': 0.002265453338623047},\n"," {'AUC': 0,\n","  'Accuracy': 0.7894736842105263,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'analcatdata_broadwaymult.csv',\n","  'FPR': array([0.09375   , 0.08823529, 0.01960784, 0.00970874, 0.        ,\n","         0.        , 0.05769231]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14230a4cf8>,\n","  'Inference Time': 0.0031559090865285774,\n","  'PR-Curve': 0,\n","  'Precision': 0.8031602467826957,\n","  'TPR': array([0.86      , 0.58333333, 0.75      , 0.72727273, 0.83333333,\n","         0.69230769, 0.9       ]),\n","  'Training Time': 0.0022699832916259766},\n"," {'AUC': 0,\n","  'Accuracy': 0.56,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'fri_c0_250_5.csv',\n","  'FPR': array([0.71111111, 0.21818182]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14230584a8>,\n","  'Inference Time': 0.0033783912658691406,\n","  'PR-Curve': 0,\n","  'Precision': 0.5466666666666666,\n","  'TPR': array([0.78181818, 0.28888889]),\n","  'Training Time': 0.0024061203002929688},\n"," {'AUC': 0,\n","  'Accuracy': 0.7077922077922078,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'diabetes.csv',\n","  'FPR': array([0.48039216, 0.19902913]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423d51470>,\n","  'Inference Time': 0.0017060861959085835,\n","  'PR-Curve': 0,\n","  'Precision': 0.6674289123086101,\n","  'TPR': array([0.80097087, 0.51960784]),\n","  'Training Time': 0.004140377044677734},\n"," {'AUC': 0,\n","  'Accuracy': 0.6818181818181818,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'cloud.csv',\n","  'FPR': array([0.86666667, 0.03448276]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236690f0>,\n","  'Inference Time': 0.011124394156716086,\n","  'PR-Curve': 0,\n","  'Precision': 0.6747967479674797,\n","  'TPR': array([0.96551724, 0.13333333]),\n","  'Training Time': 0.002363920211791992},\n"," {'AUC': 0,\n","  'Accuracy': 0.868421052631579,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'lowbwt.csv',\n","  'FPR': array([0.24242424, 0.04651163]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423699b70>,\n","  'Inference Time': 0.005044435199938322,\n","  'PR-Curve': 0,\n","  'Precision': 0.8813303099017384,\n","  'TPR': array([0.95348837, 0.75757576]),\n","  'Training Time': 0.003060579299926758},\n"," {'AUC': 0,\n","  'Accuracy': 0.9838709677419355,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'diggle_table_a2.csv',\n","  'FPR': array([0.     , 0.03125]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423b04da0>,\n","  'Inference Time': 0.0035532059208039316,\n","  'PR-Curve': 0,\n","  'Precision': 0.9838709677419355,\n","  'TPR': array([0.96875, 1.     ]),\n","  'Training Time': 0.002973794937133789},\n"," {'AUC': 0,\n","  'Accuracy': 0.7659574468085106,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'chatfield_4.csv',\n","  'FPR': array([0.1754386 , 0.32432432]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422fd0c88>,\n","  'Inference Time': 0.004190079709316822,\n","  'PR-Curve': 0,\n","  'Precision': 0.7554479418886199,\n","  'TPR': array([0.67567568, 0.8245614 ]),\n","  'Training Time': 0.0029180049896240234},\n"," {'AUC': 0,\n","  'Accuracy': 0.54,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'no2.csv',\n","  'FPR': array([0.7184466 , 0.18556701]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14230d0978>,\n","  'Inference Time': 0.0019931793212890625,\n","  'PR-Curve': 0,\n","  'Precision': 0.5666805729383952,\n","  'TPR': array([0.81443299, 0.2815534 ]),\n","  'Training Time': 0.0027399063110351562},\n"," {'AUC': 0,\n","  'Accuracy': 0.5358490566037736,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'disclosure_z.csv',\n","  'FPR': array([0.66666667, 0.23387097]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14230d0358>,\n","  'Inference Time': 0.001448505329635908,\n","  'PR-Curve': 0,\n","  'Precision': 0.5605332776385408,\n","  'TPR': array([0.76612903, 0.33333333]),\n","  'Training Time': 0.003171205520629883},\n"," {'AUC': 0,\n","  'Accuracy': 0.5483870967741935,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'kidney.csv',\n","  'FPR': array([0.5, 0.4]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422ff0e80>,\n","  'Inference Time': 0.011128763998708418,\n","  'PR-Curve': 0,\n","  'Precision': 0.5504201680672269,\n","  'TPR': array([0.6, 0.5]),\n","  'Training Time': 0.0022079944610595703},\n"," {'AUC': 0,\n","  'Accuracy': 0.8,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'lupus.csv',\n","  'FPR': array([0.25      , 0.15789474]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423080cc0>,\n","  'Inference Time': 0.008712496076311384,\n","  'PR-Curve': 0,\n","  'Precision': 0.8,\n","  'TPR': array([0.84210526, 0.75      ]),\n","  'Training Time': 0.0025434494018554688},\n"," {'AUC': 0,\n","  'Accuracy': 0.8695652173913043,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'kc3.csv',\n","  'FPR': array([0.9375    , 0.05357143]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423a21d30>,\n","  'Inference Time': 0.0039429768272068195,\n","  'PR-Curve': 0,\n","  'Precision': 0.506896551724138,\n","  'TPR': array([0.94642857, 0.0625    ]),\n","  'Training Time': 0.00556182861328125},\n"," {'AUC': 0,\n","  'Accuracy': 0.51,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'pm10.csv',\n","  'FPR': array([0.84848485, 0.13861386]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14230d0ac8>,\n","  'Inference Time': 0.0030219554901123047,\n","  'PR-Curve': 0,\n","  'Precision': 0.5130066545674532,\n","  'TPR': array([0.86138614, 0.15151515]),\n","  'Training Time': 0.002832651138305664},\n"," {'AUC': 0,\n","  'Accuracy': 0.910377358490566,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'meta.csv',\n","  'FPR': array([0.01546392, 0.88888889]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423000d30>,\n","  'Inference Time': 0.0028801414201844416,\n","  'PR-Curve': 0,\n","  'Precision': 0.6613526570048309,\n","  'TPR': array([0.11111111, 0.98453608]),\n","  'Training Time': 0.004923343658447266},\n"," {'AUC': 0,\n","  'Accuracy': 0.6964285714285714,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'newton_hema.csv',\n","  'FPR': array([0.53333333, 0.03846154]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422fd0860>,\n","  'Inference Time': 0.005649668829781669,\n","  'PR-Curve': 0,\n","  'Precision': 0.7715447154471544,\n","  'TPR': array([0.96153846, 0.46666667]),\n","  'Training Time': 0.0023169517517089844},\n"," {'AUC': 0,\n","  'Accuracy': 0.77625,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'mfeat-karhunen.csv',\n","  'FPR': array([0.07260274, 0.04661017, 0.00992908, 0.03163686, 0.01788171,\n","         0.01643836, 0.0195258 , 0.0125523 , 0.01248266, 0.00835655]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423b04828>,\n","  'Inference Time': 0.002676844596862793,\n","  'PR-Curve': 0,\n","  'Precision': 0.7931719197725308,\n","  'TPR': array([0.9       , 0.83695652, 0.82105263, 0.67123288, 0.90410959,\n","         0.72857143, 0.69879518, 0.8313253 , 0.62025316, 0.74390244]),\n","  'Training Time': 0.06448602676391602},\n"," {'AUC': 0,\n","  'Accuracy': 0.5909090909090909,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'elusage.csv',\n","  'FPR': array([0.36363636, 0.45454545]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422fdb978>,\n","  'Inference Time': 0.01041455702348189,\n","  'PR-Curve': 0,\n","  'Precision': 0.5916666666666667,\n","  'TPR': array([0.54545455, 0.63636364]),\n","  'Training Time': 0.0020830631256103516},\n"," {'AUC': 0,\n","  'Accuracy': 0.7941176470588235,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'schizo.csv',\n","  'FPR': array([0.17741935, 0.22972973]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422fdb470>,\n","  'Inference Time': 0.0033290947184843175,\n","  'PR-Curve': 0,\n","  'Precision': 0.7941176470588236,\n","  'TPR': array([0.77027027, 0.82258065]),\n","  'Training Time': 0.003061532974243164},\n"," {'AUC': 0,\n","  'Accuracy': 0.5714285714285714,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'squash-unstored.csv',\n","  'FPR': array([0.05 , 0.5  , 0.125]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422ff0898>,\n","  'Inference Time': 0.02418245588030134,\n","  'PR-Curve': 0,\n","  'Precision': 0.5982905982905983,\n","  'TPR': array([1.        , 0.85714286, 0.38461538]),\n","  'Training Time': 0.0029964447021484375},\n"," {'AUC': 0,\n","  'Accuracy': 0.5238095238095238,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'plasma_retinol.csv',\n","  'FPR': array([0.3943662 , 0.58181818]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422ff03c8>,\n","  'Inference Time': 0.003886601281544519,\n","  'PR-Curve': 0,\n","  'Precision': 0.5121568627450981,\n","  'TPR': array([0.41818182, 0.6056338 ]),\n","  'Training Time': 0.003268003463745117},\n"," {'AUC': 0,\n","  'Accuracy': 0.9951219512195122,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'rmftsa_sleepdata.csv',\n","  'FPR': array([0.00507614, 0.00469484]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422ff0ac8>,\n","  'Inference Time': 0.0006943214230421112,\n","  'PR-Curve': 0,\n","  'Precision': 0.9951145110936346,\n","  'TPR': array([0.99530516, 0.99492386]),\n","  'Training Time': 0.001720428466796875},\n"," {'AUC': 0,\n","  'Accuracy': 0.9975,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'mfeat-morphological.csv',\n","  'FPR': array([0.02857143, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f001d0>,\n","  'Inference Time': 0.0005325675010681152,\n","  'PR-Curve': 0,\n","  'Precision': 0.9986338797814207,\n","  'TPR': array([1.        , 0.97142857]),\n","  'Training Time': 0.0023927688598632812},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'prnn_synth.csv',\n","  'FPR': array([0.02040816, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f8e908>,\n","  'Inference Time': 0.002295970916748047,\n","  'PR-Curve': 0,\n","  'Precision': 0.9903846153846154,\n","  'TPR': array([1.        , 0.97959184]),\n","  'Training Time': 0.001585245132446289},\n"," {'AUC': 0,\n","  'Accuracy': 0.9976580796252927,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'solar-flare.csv',\n","  'FPR': array([1., 0.]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423012dd8>,\n","  'Inference Time': 0.002001152663934426,\n","  'PR-Curve': 0,\n","  'Precision': 0.49882903981264637,\n","  'TPR': array([1., 0.]),\n","  'Training Time': 0.0033190250396728516},\n"," {'AUC': 0,\n","  'Accuracy': 0.8120950323974082,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'socmob.csv',\n","  'FPR': array([0.20325203, 0.12765957]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f8e7b8>,\n","  'Inference Time': 0.000885186905994786,\n","  'PR-Curve': 0,\n","  'Precision': 0.7415386536780317,\n","  'TPR': array([0.87234043, 0.79674797]),\n","  'Training Time': 0.003397226333618164},\n"," {'AUC': 0,\n","  'Accuracy': 0.8571428571428571,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'squash-stored.csv',\n","  'FPR': array([0.25      , 0.07692308]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422fad390>,\n","  'Inference Time': 0.026566641671316966,\n","  'PR-Curve': 0,\n","  'Precision': 0.8571428571428571,\n","  'TPR': array([0.92307692, 0.75      ]),\n","  'Training Time': 0.003948688507080078},\n"," {'AUC': 0,\n","  'Accuracy': 0.5084745762711864,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'sleuth_case2002.csv',\n","  'FPR': array([0.48387097, 0.5       ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422fad5c0>,\n","  'Inference Time': 0.005814988734358448,\n","  'PR-Curve': 0,\n","  'Precision': 0.5080459770114942,\n","  'TPR': array([0.5       , 0.51612903]),\n","  'Training Time': 0.002040386199951172},\n"," {'AUC': 0,\n","  'Accuracy': 0.4375,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'schlvote.csv',\n","  'FPR': array([0.53846154, 0.66666667]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f8ea58>,\n","  'Inference Time': 0.020056962966918945,\n","  'PR-Curve': 0,\n","  'Precision': 0.4375,\n","  'TPR': array([0.33333333, 0.46153846]),\n","  'Training Time': 0.0020465850830078125},\n"," {'AUC': 0,\n","  'Accuracy': 0.9016393442622951,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'tae.csv',\n","  'FPR': array([0.3, 0. ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f8ebe0>,\n","  'Inference Time': 0.0050185156650230526,\n","  'PR-Curve': 0,\n","  'Precision': 0.9361702127659575,\n","  'TPR': array([1. , 0.7]),\n","  'Training Time': 0.0020570755004882812},\n"," {'AUC': 0,\n","  'Accuracy': 0.8360655737704918,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'teachingAssistant.csv',\n","  'FPR': array([0.13157895, 0.11627907, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422fdb588>,\n","  'Inference Time': 0.005280385251905097,\n","  'PR-Curve': 0,\n","  'Precision': 0.8525641025641025,\n","  'TPR': array([0.91304348, 0.83333333, 0.75      ]),\n","  'Training Time': 0.00232696533203125},\n"," {'AUC': 0,\n","  'Accuracy': 0.85,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'rabe_131.csv',\n","  'FPR': array([0.33333333, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f00c50>,\n","  'Inference Time': 0.014925003051757812,\n","  'PR-Curve': 0,\n","  'Precision': 0.8928571428571428,\n","  'TPR': array([1.        , 0.66666667]),\n","  'Training Time': 0.002834320068359375},\n"," {'AUC': 0,\n","  'Accuracy': 0.8269230769230769,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'visualizing_livestock.csv',\n","  'FPR': array([0.0952381, 0.5      ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f00978>,\n","  'Inference Time': 0.005020545079157903,\n","  'PR-Curve': 0,\n","  'Precision': 0.7196382428940569,\n","  'TPR': array([0.5      , 0.9047619]),\n","  'Training Time': 0.002085447311401367},\n"," {'AUC': 0,\n","  'Accuracy': 0.6363636363636364,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'veteran.csv',\n","  'FPR': array([0.25641026, 0.625     ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f8e438>,\n","  'Inference Time': 0.005470622669566762,\n","  'PR-Curve': 0,\n","  'Precision': 0.5592948717948718,\n","  'TPR': array([0.375     , 0.74358974]),\n","  'Training Time': 0.0024824142456054688},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'transplant.csv',\n","  'FPR': array([0., 0.]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f8eb00>,\n","  'Inference Time': 0.004233054394991893,\n","  'PR-Curve': 0,\n","  'Precision': 1.0,\n","  'TPR': array([1., 1.]),\n","  'Training Time': 0.0015139579772949219},\n"," {'AUC': 0,\n","  'Accuracy': 0.7733333333333333,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'triazines.csv',\n","  'FPR': array([0.27586207, 0.19565217]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f8e748>,\n","  'Inference Time': 0.026448567708333336,\n","  'PR-Curve': 0,\n","  'Precision': 0.7611111111111111,\n","  'TPR': array([0.80434783, 0.72413793]),\n","  'Training Time': 0.00594329833984375},\n"," {'AUC': 0,\n","  'Accuracy': 0.9137931034482759,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'vote.csv',\n","  'FPR': array([0.22033898, 0.0173913 ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f8e4a8>,\n","  'Inference Time': 0.0031528801753603177,\n","  'PR-Curve': 0,\n","  'Precision': 0.9275793650793651,\n","  'TPR': array([0.9826087 , 0.77966102]),\n","  'Training Time': 0.0037899017333984375},\n"," {'AUC': 0,\n","  'Accuracy': 0.5384615384615384,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'white-clover.csv',\n","  'FPR': array([0.15384615, 0.76923077]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f8eac8>,\n","  'Inference Time': 0.019807081956129808,\n","  'PR-Curve': 0,\n","  'Precision': 0.5619047619047619,\n","  'TPR': array([0.23076923, 0.84615385]),\n","  'Training Time': 0.003559112548828125},\n"," {'AUC': 0,\n","  'Accuracy': 0.625,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': array([0.64      , 0.08695652]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422fad9e8>,\n","  'Inference Time': 0.0071177879969278966,\n","  'PR-Curve': 0,\n","  'Precision': 0.6928746928746929,\n","  'TPR': array([0.91304348, 0.36      ]),\n","  'Training Time': 0.002482175827026367},\n"," {'AUC': 0,\n","  'Accuracy': 0.8958333333333334,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': array([0.26315789, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f009e8>,\n","  'Inference Time': 0.006616115570068359,\n","  'PR-Curve': 0,\n","  'Precision': 0.9264705882352942,\n","  'TPR': array([1.        , 0.73684211]),\n","  'Training Time': 0.002130746841430664},\n"," {'AUC': 0,\n","  'Accuracy': 0.825,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': array([0.        , 0.        , 0.73255814, 0.        , 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f007f0>,\n","  'Inference Time': 0.0022225909762912327,\n","  'PR-Curve': 0,\n","  'Precision': 0.3626112759643917,\n","  'TPR': array([0.  , 0.  , 1.  , 0.92, 0.  ]),\n","  'Training Time': 0.004824161529541016},\n"," {'AUC': 0,\n","  'Accuracy': 0.664,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'balance-scale.csv',\n","  'FPR': array([0.03539823, 0.32191781, 0.2265625 ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422f006a0>,\n","  'Inference Time': 0.0026388168334960938,\n","  'PR-Curve': 0,\n","  'Precision': 0.45967391552902975,\n","  'TPR': array([0.        , 0.78846154, 0.68852459]),\n","  'Training Time': 0.0026743412017822266},\n"," {'AUC': 0,\n","  'Accuracy': 0.882808181315644,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'bank.csv',\n","  'FPR': array([0.93650794, 0.02160494]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423a67d68>,\n","  'Inference Time': 0.0009451075902362105,\n","  'PR-Curve': 0,\n","  'Precision': 0.5774325597121259,\n","  'TPR': array([0.97839506, 0.06349206]),\n","  'Training Time': 0.01682591438293457},\n"," {'AUC': 0,\n","  'Accuracy': 0.71,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'blood.csv',\n","  'FPR': array([0.56962025, 0.19004525]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423a69710>,\n","  'Inference Time': 0.001354217529296875,\n","  'PR-Curve': 0,\n","  'Precision': 0.6232377819548872,\n","  'TPR': array([0.80995475, 0.43037975]),\n","  'Training Time': 0.0025262832641601562},\n"," {'AUC': 0,\n","  'Accuracy': 0.8260869565217391,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'breast-cancer.csv',\n","  'FPR': array([0.44444444, 0.05063291]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423d0a710>,\n","  'Inference Time': 0.003441520359205163,\n","  'PR-Curve': 0,\n","  'Precision': 0.8287545787545787,\n","  'TPR': array([0.94936709, 0.55555556]),\n","  'Training Time': 0.0026345252990722656},\n"," {'AUC': 0,\n","  'Accuracy': 0.9535714285714286,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'breast-cancer-wisc.csv',\n","  'FPR': array([0.07368421, 0.03243243]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423d38780>,\n","  'Inference Time': 0.0017413071223667692,\n","  'PR-Curve': 0,\n","  'Precision': 0.9492679020819035,\n","  'TPR': array([0.96756757, 0.92631579]),\n","  'Training Time': 0.0029935836791992188},\n"," {'AUC': 0,\n","  'Accuracy': 0.9385964912280702,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'breast-cancer-wisc-diag.csv',\n","  'FPR': array([0.1125    , 0.03378378]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423d0a400>,\n","  'Inference Time': 0.002928993158173143,\n","  'PR-Curve': 0,\n","  'Precision': 0.9375,\n","  'TPR': array([0.96621622, 0.8875    ]),\n","  'Training Time': 0.006442546844482422},\n"," {'AUC': 0,\n","  'Accuracy': 0.7375,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'breast-cancer-wisc-prog.csv',\n","  'FPR': array([0.75    , 0.140625]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14aa1c39e8>,\n","  'Inference Time': 0.016811490058898926,\n","  'PR-Curve': 0,\n","  'Precision': 0.5642939150401838,\n","  'TPR': array([0.859375, 0.25    ]),\n","  'Training Time': 0.006400346755981445},\n"," {'AUC': 0,\n","  'Accuracy': 0.7674418604651163,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'breast-tissue.csv',\n","  'FPR': array([0.03030303, 0.        , 0.11428571, 0.05263158, 0.        ,\n","         0.08108108]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423a2b780>,\n","  'Inference Time': 0.009592189345248909,\n","  'PR-Curve': 0,\n","  'Precision': 0.8055555555555555,\n","  'TPR': array([0.9       , 0.57142857, 0.75      , 0.8       , 0.57142857,\n","         1.        ]),\n","  'Training Time': 0.002986907958984375},\n"," {'AUC': 0,\n","  'Accuracy': 0.6213872832369942,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'car.csv',\n","  'FPR': array([0.03157895, 0.53301887, 0.20522388, 0.02714932]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423896550>,\n","  'Inference Time': 0.0008124147536437636,\n","  'PR-Curve': 0,\n","  'Precision': 0.3227535828699406,\n","  'TPR': array([0.03703704, 0.74583333, 0.44230769, 0.06896552]),\n","  'Training Time': 0.0033416748046875},\n"," {'AUC': 0,\n","  'Accuracy': 0.8860164512338425,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'cardiotocography-3clases.csv',\n","  'FPR': array([0.37640449, 0.03556772, 0.00504414]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423b8feb8>,\n","  'Inference Time': 0.0010990788317455107,\n","  'PR-Curve': 0,\n","  'Precision': 0.8394888810586485,\n","  'TPR': array([0.97028232, 0.51666667, 0.67241379]),\n","  'Training Time': 0.009312629699707031},\n"," {'AUC': 0,\n","  'Accuracy': 0.6509988249118684,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'cardiotocography-10clases.csv',\n","  'FPR': array([0.07204611, 0.1936    , 0.00845411, 0.00490798, 0.01094891,\n","         0.07330567, 0.03638814, 0.00122549, 0.00723764, 0.0248366 ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423a3ff98>,\n","  'Inference Time': 0.0013926894908506077,\n","  'PR-Curve': 0,\n","  'Precision': 0.6408210901350027,\n","  'TPR': array([0.61146497, 0.81415929, 0.26086957, 0.36111111, 0.06896552,\n","         0.703125  , 0.65137615, 0.71428571, 0.59090909, 0.62790698]),\n","  'Training Time': 0.010834455490112305},\n"," {'AUC': 0,\n","  'Accuracy': 0.9937451133698202,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'chess-krvkp.csv',\n","  'FPR': array([0.        , 0.01322314]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14232e4828>,\n","  'Inference Time': 0.0010584368194985706,\n","  'PR-Curve': 0,\n","  'Precision': 0.9941348973607038,\n","  'TPR': array([0.98677686, 1.        ]),\n","  'Training Time': 0.007418394088745117},\n"," {'AUC': 0,\n","  'Accuracy': 0.6149425287356322,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'congressional-voting.csv',\n","  'FPR': array([0.54237288, 0.30434783]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423d9b860>,\n","  'Inference Time': 0.002903499822506959,\n","  'PR-Curve': 0,\n","  'Precision': 0.5748847926267281,\n","  'TPR': array([0.69565217, 0.45762712]),\n","  'Training Time': 0.0034055709838867188},\n"," {'AUC': 0,\n","  'Accuracy': 0.8452380952380952,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'conn-bench-sonar-mines-rocks.csv',\n","  'FPR': array([0.15384615, 0.15555556]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1422fbd7f0>,\n","  'Inference Time': 0.009942622411818732,\n","  'PR-Curve': 0,\n","  'Precision': 0.8443181818181817,\n","  'TPR': array([0.84444444, 0.84615385]),\n","  'Training Time': 0.007963180541992188},\n"," {'AUC': 0,\n","  'Accuracy': 0.9745762711864406,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'contrac.csv',\n","  'FPR': array([0.02915452, 0.00222717, 0.01030928]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423b26dd8>,\n","  'Inference Time': 0.0011193550239175052,\n","  'PR-Curve': 0,\n","  'Precision': 0.9778249378109453,\n","  'TPR': array([0.99595142, 0.94326241, 0.97029703]),\n","  'Training Time': 0.0036869049072265625},\n"," {'AUC': 0,\n","  'Accuracy': 0.6717171717171717,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'conn-bench-vowel-deterding.csv',\n","  'FPR': array([0.06267806, 0.07713499, 0.03389831, 0.05509642, 0.04683196,\n","         0.01117318, 0.03611111, 0.01369863, 0.00284091, 0.0027248 ,\n","         0.01923077]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14232d36d8>,\n","  'Inference Time': 0.001664715583878334,\n","  'PR-Curve': 0,\n","  'Precision': 0.7133546371957706,\n","  'TPR': array([0.95555556, 0.75757576, 0.71428571, 0.93939394, 0.84848485,\n","         0.34210526, 0.55555556, 0.70967742, 0.40909091, 0.72413793,\n","         0.46875   ]),\n","  'Training Time': 0.007138252258300781},\n"," {'AUC': 0,\n","  'Accuracy': 0.9130434782608695,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'credit-approval.csv',\n","  'FPR': array([0.06622517, 0.112     ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14aa064400>,\n","  'Inference Time': 0.0021967335023741793,\n","  'PR-Curve': 0,\n","  'Precision': 0.9135163956278326,\n","  'TPR': array([0.888     , 0.93377483]),\n","  'Training Time': 0.004077434539794922},\n"," {'AUC': 0,\n","  'Accuracy': 0.7121951219512195,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'cylinder-bands.csv',\n","  'FPR': array([0.1627907, 0.5      ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423991e10>,\n","  'Inference Time': 0.003686765345131479,\n","  'PR-Curve': 0,\n","  'Precision': 0.6918969120037148,\n","  'TPR': array([0.5      , 0.8372093]),\n","  'Training Time': 0.006186723709106445},\n"," {'AUC': 0,\n","  'Accuracy': 0.9115646258503401,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'dermatology.csv',\n","  'FPR': array([0.01052632, 0.03252033, 0.00833333, 0.02325581, 0.03174603,\n","         0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423b860b8>,\n","  'Inference Time': 0.004241255675854326,\n","  'PR-Curve': 0,\n","  'Precision': 0.9049337141352454,\n","  'TPR': array([1.        , 0.79166667, 0.96296296, 0.83333333, 0.9047619 ,\n","         0.6       ]),\n","  'Training Time': 0.004122734069824219},\n"," {'AUC': 0,\n","  'Accuracy': 0.6792452830188679,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'echocardiogram.csv',\n","  'FPR': array([0.66666667, 0.14285714]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423b01550>,\n","  'Inference Time': 0.007107572735480543,\n","  'PR-Curve': 0,\n","  'Precision': 0.6298701298701299,\n","  'TPR': array([0.85714286, 0.33333333]),\n","  'Training Time': 0.0028553009033203125},\n"," {'AUC': 0,\n","  'Accuracy': 0.9512987012987013,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'energy-y1.csv',\n","  'FPR': array([0.04678363, 0.00784314, 0.02631579]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14239d9978>,\n","  'Inference Time': 0.002631119319370815,\n","  'PR-Curve': 0,\n","  'Precision': 0.9519288299776104,\n","  'TPR': array([0.98540146, 0.75471698, 1.        ]),\n","  'Training Time': 0.0036869049072265625},\n"," {'AUC': 0,\n","  'Accuracy': 0.8831168831168831,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'energy-y2.csv',\n","  'FPR': array([0.04968944, 0.069869  , 0.05309735]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14230f7a20>,\n","  'Inference Time': 0.001580684215991528,\n","  'PR-Curve': 0,\n","  'Precision': 0.8604025365315687,\n","  'TPR': array([1.        , 0.74683544, 0.80487805]),\n","  'Training Time': 0.003100156784057617},\n"," {'AUC': 0,\n","  'Accuracy': 0.85,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'fertility.csv',\n","  'FPR': array([1.        , 0.05555556]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423565f60>,\n","  'Inference Time': 0.00959634780883789,\n","  'PR-Curve': 0,\n","  'Precision': 0.4473684210526316,\n","  'TPR': array([0.94444444, 0.        ]),\n","  'Training Time': 0.0028769969940185547},\n"," {'AUC': 0,\n","  'Accuracy': 0.7093023255813954,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'glass.csv',\n","  'FPR': array([0.20689655, 0.2037037 , 0.01234568, 0.        , 0.01219512,\n","         0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14605de8d0>,\n","  'Inference Time': 0.007263449735419695,\n","  'PR-Curve': 0,\n","  'Precision': 0.7484126984126984,\n","  'TPR': array([0.82142857, 0.6875    , 0.4       , 0.42857143, 0.25      ,\n","         1.        ]),\n","  'Training Time': 0.003740549087524414},\n"," {'AUC': 0,\n","  'Accuracy': 0.6991869918699187,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'haberman-survival.csv',\n","  'FPR': array([0.78787879, 0.12222222]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423565358>,\n","  'Inference Time': 0.00285326949949187,\n","  'PR-Curve': 0,\n","  'Precision': 0.5706349206349206,\n","  'TPR': array([0.87777778, 0.21212121]),\n","  'Training Time': 0.002733469009399414},\n"," {'AUC': 0,\n","  'Accuracy': 0.47540983606557374,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'heart-cleveland.csv',\n","  'FPR': array([0.72413793, 0.12121212, 0.02857143, 0.0462963 , 0.01694915]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142341a470>,\n","  'Inference Time': 0.0036700827176453636,\n","  'PR-Curve': 0,\n","  'Precision': 0.2868202764976958,\n","  'TPR': array([0.796875  , 0.13043478, 0.11764706, 0.14285714, 0.        ]),\n","  'Training Time': 0.0033168792724609375},\n"," {'AUC': 0,\n","  'Accuracy': 0.847457627118644,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'heart-hungarian.csv',\n","  'FPR': array([0.10526316, 0.175     ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142341a630>,\n","  'Inference Time': 0.003453028404106528,\n","  'PR-Curve': 0,\n","  'Precision': 0.825595238095238,\n","  'TPR': array([0.825     , 0.89473684]),\n","  'Training Time': 0.0028753280639648438},\n"," {'AUC': 0,\n","  'Accuracy': 0.34,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'heart-switzerland.csv',\n","  'FPR': array([0.06382979, 0.44827586, 0.20512821, 0.225     , 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142341a160>,\n","  'Inference Time': 0.007991790771484375,\n","  'PR-Curve': 0,\n","  'Precision': 0.1962121212121212,\n","  'TPR': array([0.        , 0.52380952, 0.27272727, 0.3       , 0.        ]),\n","  'Training Time': 0.0030639171600341797},\n"," {'AUC': 0,\n","  'Accuracy': 0.2875,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'heart-va.csv',\n","  'FPR': array([0.33846154, 0.20754717, 0.21538462, 0.14754098, 0.01315789]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14605de588>,\n","  'Inference Time': 0.009426474571228027,\n","  'PR-Curve': 0,\n","  'Precision': 0.2302867383512545,\n","  'TPR': array([0.6       , 0.25925926, 0.26666667, 0.15789474, 0.        ]),\n","  'Training Time': 0.003704547882080078},\n"," {'AUC': 0,\n","  'Accuracy': 0.7741935483870968,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'hepatitis.csv',\n","  'FPR': array([0.04166667, 0.85714286]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14235fcc88>,\n","  'Inference Time': 0.008260050127583166,\n","  'PR-Curve': 0,\n","  'Precision': 0.646551724137931,\n","  'TPR': array([0.14285714, 0.95833333]),\n","  'Training Time': 0.0036220550537109375},\n"," {'AUC': 0,\n","  'Accuracy': 0.421875,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'hayes-roth.csv',\n","  'FPR': array([0.43589744, 0.41025641, 0.08      ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14235fc5c0>,\n","  'Inference Time': 0.006172806024551392,\n","  'PR-Curve': 0,\n","  'Precision': 0.35648795648795645,\n","  'TPR': array([0.64      , 0.4       , 0.07142857]),\n","  'Training Time': 0.0029642581939697266},\n"," {'AUC': 0,\n","  'Accuracy': 0.47216494845360824,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'hill-valley.csv',\n","  'FPR': array([0.63453815, 0.41525424]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14235fc978>,\n","  'Inference Time': 0.004019196500483247,\n","  'PR-Curve': 0,\n","  'Precision': 0.4738488488488488,\n","  'TPR': array([0.58474576, 0.36546185]),\n","  'Training Time': 0.07446861267089844},\n"," {'AUC': 0,\n","  'Accuracy': 0.7905405405405406,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'horse-colic.csv',\n","  'FPR': array([0.28846154, 0.16666667]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14235fc8d0>,\n","  'Inference Time': 0.004492901466988229,\n","  'PR-Curve': 0,\n","  'Precision': 0.7701092353525323,\n","  'TPR': array([0.83333333, 0.71153846]),\n","  'Training Time': 0.004920482635498047},\n"," {'AUC': 0,\n","  'Accuracy': 0.6581196581196581,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'ilpd-indian-liver.csv',\n","  'FPR': array([0.79365079, 0.1754386 ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14235a2dd8>,\n","  'Inference Time': 0.0020775020631969483,\n","  'PR-Curve': 0,\n","  'Precision': 0.5202727383416534,\n","  'TPR': array([0.8245614 , 0.20634921]),\n","  'Training Time': 0.004052162170410156},\n"," {'AUC': 0,\n","  'Accuracy': 0.8982683982683982,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'image-segmentation.csv',\n","  'FPR': array([0.01267427, 0.00123609, 0.02506266, 0.03884712, 0.02292994,\n","         0.01783439, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142353d588>,\n","  'Inference Time': 0.00123853807325487,\n","  'PR-Curve': 0,\n","  'Precision': 0.8984244818143814,\n","  'TPR': array([0.99259259, 1.        , 0.88888889, 0.8015873 , 0.82014388,\n","         0.81294964, 0.97916667]),\n","  'Training Time': 0.013809680938720703},\n"," {'AUC': 0,\n","  'Accuracy': 0.9148936170212766,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'ionosphere.csv',\n","  'FPR': array([0.05681818, 0.13207547]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142353d668>,\n","  'Inference Time': 0.004558698505374556,\n","  'PR-Curve': 0,\n","  'Precision': 0.912091503267974,\n","  'TPR': array([0.86792453, 0.94318182]),\n","  'Training Time': 0.0058345794677734375},\n"," {'AUC': 0,\n","  'Accuracy': 0.9833333333333333,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'iris.csv',\n","  'FPR': array([0.        , 0.02439024, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14235a29b0>,\n","  'Inference Time': 0.009465217590332031,\n","  'PR-Curve': 0,\n","  'Precision': 0.9833333333333334,\n","  'TPR': array([1.        , 1.        , 0.94444444]),\n","  'Training Time': 0.00250244140625},\n"," {'AUC': 0,\n","  'Accuracy': 0.14,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'led-display.csv',\n","  'FPR': array([0.09485095, 0.05722071, 0.10826211, 0.06111111, 0.05382436,\n","         0.10497238, 0.09065934, 0.12290503, 0.10555556, 0.15730337]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142353dc18>,\n","  'Inference Time': 0.001297593116760254,\n","  'PR-Curve': 0,\n","  'Precision': 0.1472827504770618,\n","  'TPR': array([0.12903226, 0.48484848, 0.10204082, 0.025     , 0.21276596,\n","         0.05263158, 0.11111111, 0.14285714, 0.075     , 0.11363636]),\n","  'Training Time': 0.0031714439392089844},\n"," {'AUC': 0,\n","  'Accuracy': 0.1,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'lenses.csv',\n","  'FPR': array([0.44444444, 0.        , 0.83333333]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142354c8d0>,\n","  'Inference Time': 0.033402442932128906,\n","  'PR-Curve': 0,\n","  'Precision': 0.05555555555555555,\n","  'TPR': array([0.  , 0.  , 0.25]),\n","  'Training Time': 0.0027322769165039062},\n"," {'AUC': 0,\n","  'Accuracy': 0.6944444444444444,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'libras.csv',\n","  'FPR': array([0.03787879, 0.05223881, 0.01459854, 0.00763359, 0.02272727,\n","         0.02173913, 0.03007519, 0.02919708, 0.        , 0.03787879,\n","         0.01449275, 0.03703704, 0.01459854, 0.00746269, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142350d0f0>,\n","  'Inference Time': 0.008066495259602865,\n","  'PR-Curve': 0,\n","  'Precision': 0.7042266992266992,\n","  'TPR': array([0.83333333, 0.8       , 1.        , 0.23076923, 0.75      ,\n","         0.66666667, 0.90909091, 0.42857143, 0.63636364, 0.66666667,\n","         0.83333333, 0.55555556, 0.57142857, 0.7       , 0.90909091]),\n","  'Training Time': 0.015180349349975586},\n"," {'AUC': 0,\n","  'Accuracy': 0.5384615384615384,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'lung-cancer.csv',\n","  'FPR': array([0.11111111, 0.625     , 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14235a20b8>,\n","  'Inference Time': 0.051608452430138216,\n","  'PR-Curve': 0,\n","  'Precision': 0.6666666666666666,\n","  'TPR': array([0.25, 1.  , 0.25]),\n","  'Training Time': 0.006273984909057617},\n"," {'AUC': 0,\n","  'Accuracy': 0.6833333333333333,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'lymphography.csv',\n","  'FPR': array([0.        , 0.375     , 0.22580645, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142350d630>,\n","  'Inference Time': 0.008308887481689453,\n","  'PR-Curve': 0,\n","  'Precision': 0.34375,\n","  'TPR': array([0.        , 0.85714286, 0.5862069 , 0.        ]),\n","  'Training Time': 0.0034515857696533203},\n"," {'AUC': 0,\n","  'Accuracy': 0.7298701298701299,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'mammographic.csv',\n","  'FPR': array([0.4171123 , 0.13131313]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142350d278>,\n","  'Inference Time': 0.001154317484273539,\n","  'PR-Curve': 0,\n","  'Precision': 0.7477037037037038,\n","  'TPR': array([0.86868687, 0.5828877 ]),\n","  'Training Time': 0.0030050277709960938},\n"," {'AUC': 0,\n","  'Accuracy': 0.813953488372093,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'molec-biol-promoter.csv',\n","  'FPR': array([0.10526316, 0.25      ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423339630>,\n","  'Inference Time': 0.02648109613462936,\n","  'PR-Curve': 0,\n","  'Precision': 0.8195652173913044,\n","  'TPR': array([0.75      , 0.89473684]),\n","  'Training Time': 0.005997419357299805},\n"," {'AUC': 0,\n","  'Accuracy': 0.8377742946708464,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'molec-biol-splice.csv',\n","  'FPR': array([0.03441084, 0.03014553, 0.22979398]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423314b70>,\n","  'Inference Time': 0.0018378410219772481,\n","  'PR-Curve': 0,\n","  'Precision': 0.8573228798209174,\n","  'TPR': array([0.74132492, 0.74522293, 0.93023256]),\n","  'Training Time': 0.021098613739013672},\n"," {'AUC': 0,\n","  'Accuracy': 0.8071748878923767,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'monks-1.csv',\n","  'FPR': array([0.22123894, 0.16363636]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423321da0>,\n","  'Inference Time': 0.0016464780798941983,\n","  'PR-Curve': 0,\n","  'Precision': 0.8082567327850347,\n","  'TPR': array([0.83636364, 0.77876106]),\n","  'Training Time': 0.0027146339416503906},\n"," {'AUC': 0,\n","  'Accuracy': 0.5435684647302904,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'monks-2.csv',\n","  'FPR': array([0.65822785, 0.35802469]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14233399e8>,\n","  'Inference Time': 0.0018005054521362813,\n","  'PR-Curve': 0,\n","  'Precision': 0.492156862745098,\n","  'TPR': array([0.64197531, 0.34177215]),\n","  'Training Time': 0.0028314590454101562},\n"," {'AUC': 0,\n","  'Accuracy': 0.7072072072072072,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'monks-3.csv',\n","  'FPR': array([0.22115385, 0.3559322 ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423333828>,\n","  'Inference Time': 0.0015851613637563346,\n","  'PR-Curve': 0,\n","  'Precision': 0.7131066765213107,\n","  'TPR': array([0.6440678 , 0.77884615]),\n","  'Training Time': 0.0025854110717773438},\n"," {'AUC': 0,\n","  'Accuracy': 0.9913846153846154,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'mushroom.csv',\n","  'FPR': array([0.0178117, 0.       ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423435a20>,\n","  'Inference Time': 0.0006155600914588341,\n","  'PR-Curve': 0,\n","  'Precision': 0.9917936694021102,\n","  'TPR': array([1.       , 0.9821883]),\n","  'Training Time': 0.01588129997253418},\n"," {'AUC': 0,\n","  'Accuracy': 0.8638743455497382,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'musk-1.csv',\n","  'FPR': array([0.24137931, 0.04807692]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142350d160>,\n","  'Inference Time': 0.0069640693864273144,\n","  'PR-Curve': 0,\n","  'Precision': 0.8772887323943661,\n","  'TPR': array([0.95192308, 0.75862069]),\n","  'Training Time': 0.02227306365966797},\n"," {'AUC': 0,\n","  'Accuracy': 0.6992665036674817,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'oocytes_merluccius_nucleus_4d.csv',\n","  'FPR': array([0.20769231, 0.46308725]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142369f240>,\n","  'Inference Time': 0.002369612528234356,\n","  'PR-Curve': 0,\n","  'Precision': 0.6730529172320217,\n","  'TPR': array([0.53691275, 0.79230769]),\n","  'Training Time': 0.015447378158569336},\n"," {'AUC': 0,\n","  'Accuracy': 0.9193154034229829,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'oocytes_merluccius_states_2f.csv',\n","  'FPR': array([0.0483871 , 0.00769231, 0.12711864]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1575155c50>,\n","  'Inference Time': 0.0019580635872913166,\n","  'PR-Curve': 0,\n","  'Precision': 0.8781237985390234,\n","  'TPR': array([0.87878788, 0.78947368, 0.94158076]),\n","  'Training Time': 0.010676145553588867},\n"," {'AUC': 0,\n","  'Accuracy': 0.6575342465753424,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'oocytes_trisopterus_nucleus_2f.csv',\n","  'FPR': array([0.20792079, 0.50920245]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142369f2e8>,\n","  'Inference Time': 0.002175814484896725,\n","  'PR-Curve': 0,\n","  'Precision': 0.6570869594549011,\n","  'TPR': array([0.49079755, 0.79207921]),\n","  'Training Time': 0.011754751205444336},\n"," {'AUC': 0,\n","  'Accuracy': 0.8547945205479452,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'oocytes_trisopterus_states_5b.csv',\n","  'FPR': array([0.23129252, 0.        , 0.08482143]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236a76a0>,\n","  'Inference Time': 0.002101349504026648,\n","  'PR-Curve': 0,\n","  'Precision': 0.902641135688346,\n","  'TPR': array([0.91284404, 0.33333333, 0.78723404]),\n","  'Training Time': 0.009983062744140625},\n"," {'AUC': 0,\n","  'Accuracy': 0.9753694581280788,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'ozone.csv',\n","  'FPR': array([1., 0.]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14239d2c18>,\n","  'Inference Time': 0.0016137296930322507,\n","  'PR-Curve': 0,\n","  'Precision': 0.4876847290640394,\n","  'TPR': array([1., 0.]),\n","  'Training Time': 0.03437447547912598},\n"," {'AUC': 0,\n","  'Accuracy': 0.8461538461538461,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'parkinsons.csv',\n","  'FPR': array([0.10344828, 0.3       ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423435f60>,\n","  'Inference Time': 0.008919300177158454,\n","  'PR-Curve': 0,\n","  'Precision': 0.7982758620689655,\n","  'TPR': array([0.7       , 0.89655172]),\n","  'Training Time': 0.004137516021728516},\n"," {'AUC': 0,\n","  'Accuracy': 0.7045454545454546,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'pima.csv',\n","  'FPR': array([0.5       , 0.19417476]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236a75f8>,\n","  'Inference Time': 0.0020226874908843596,\n","  'PR-Curve': 0,\n","  'Precision': 0.662708259482453,\n","  'TPR': array([0.80582524, 0.5       ]),\n","  'Training Time': 0.004244804382324219},\n"," {'AUC': 0,\n","  'Accuracy': 0.7906976744186046,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'pittsburg-bridges-MATERIAL.csv',\n","  'FPR': array([0.08571429, 0.07894737, 0.23076923]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14233218d0>,\n","  'Inference Time': 0.007457511369572129,\n","  'PR-Curve': 0,\n","  'Precision': 0.5412748171368861,\n","  'TPR': array([1.        , 0.        , 0.86666667]),\n","  'Training Time': 0.002616405487060547},\n"," {'AUC': 0,\n","  'Accuracy': 0.5952380952380952,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'pittsburg-bridges-REL-L.csv',\n","  'FPR': array([0.14285714, 0.22222222, 0.25      ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423321c88>,\n","  'Inference Time': 0.0077769869849795385,\n","  'PR-Curve': 0,\n","  'Precision': 0.5458333333333333,\n","  'TPR': array([0.85714286, 0.33333333, 0.5       ]),\n","  'Training Time': 0.002199411392211914},\n"," {'AUC': 0,\n","  'Accuracy': 0.5135135135135135,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'pittsburg-bridges-SPAN.csv',\n","  'FPR': array([0.25      , 0.52631579, 0.03703704]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14234350f0>,\n","  'Inference Time': 0.013177459304397171,\n","  'PR-Curve': 0,\n","  'Precision': 0.5506715506715506,\n","  'TPR': array([0.66666667, 0.61111111, 0.2       ]),\n","  'Training Time': 0.0023703575134277344},\n"," {'AUC': 0,\n","  'Accuracy': 0.8048780487804879,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'pittsburg-bridges-T-OR-D_R.csv',\n","  'FPR': array([0.88888889, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236fc390>,\n","  'Inference Time': 0.008100416602157965,\n","  'PR-Curve': 0,\n","  'Precision': 0.9,\n","  'TPR': array([1.        , 0.11111111]),\n","  'Training Time': 0.002071380615234375},\n"," {'AUC': 0,\n","  'Accuracy': 0.47619047619047616,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'pittsburg-bridges-TYPE.csv',\n","  'FPR': array([0.08823529, 0.1025641 , 0.2173913 , 0.10810811, 0.13513514,\n","         0.025     ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236fc128>,\n","  'Inference Time': 0.008514949253627233,\n","  'PR-Curve': 0,\n","  'Precision': 0.39044289044289043,\n","  'TPR': array([1.        , 0.        , 0.42105263, 0.4       , 0.2       ,\n","         0.5       ]),\n","  'Training Time': 0.002839803695678711},\n"," {'AUC': 0,\n","  'Accuracy': 0.684931506849315,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'planning.csv',\n","  'FPR': array([0.86956522, 0.06      ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236fc0f0>,\n","  'Inference Time': 0.0056469277159808436,\n","  'PR-Curve': 0,\n","  'Precision': 0.6007462686567164,\n","  'TPR': array([0.94      , 0.13043478]),\n","  'Training Time': 0.0031375885009765625},\n"," {'AUC': 0,\n","  'Accuracy': 0.6,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'plant-margin.csv',\n","  'FPR': array([0.0188383 , 0.01732283, 0.00471698, 0.00949367, 0.00631912,\n","         0.00471698, 0.00631912, 0.00944882, 0.01105845, 0.00314465,\n","         0.0015873 , 0.01104101, 0.01104101, 0.00315956, 0.00472441,\n","         0.00157729, 0.00473934, 0.00473934, 0.0031746 , 0.00157978,\n","         0.        , 0.00158228, 0.00158983, 0.00950872, 0.01412873,\n","         0.01732283, 0.00317965, 0.        , 0.00946372, 0.00473186,\n","         0.00316957, 0.00941915, 0.00789889, 0.00791139, 0.00157729,\n","         0.00157978, 0.        , 0.00315956, 0.00634921, 0.00631912,\n","         0.00787402, 0.00943396, 0.00157729, 0.        , 0.00158228,\n","         0.00473186, 0.00626959, 0.00474684, 0.        , 0.        ,\n","         0.0015748 , 0.00472441, 0.00158228, 0.00471698, 0.01257862,\n","         0.        , 0.00158228, 0.00157978, 0.00315956, 0.        ,\n","         0.00630915, 0.00158228, 0.00157729, 0.00786164, 0.00471698,\n","         0.00158228, 0.00470958, 0.00158228, 0.00314961, 0.00157978,\n","         0.00157978, 0.00315457, 0.00157729, 0.        , 0.0015748 ,\n","         0.00473934, 0.        , 0.00315457, 0.00157978, 0.0015748 ,\n","         0.00157978, 0.00158228, 0.00474684, 0.00316456, 0.00158228,\n","         0.        , 0.        , 0.00629921, 0.        , 0.00157729,\n","         0.00157233, 0.00157978, 0.00630915, 0.00157729, 0.        ,\n","         0.        , 0.        , 0.00315956, 0.        , 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236fc860>,\n","  'Inference Time': 0.007623061537742615,\n","  'PR-Curve': 0,\n","  'Precision': 0.6587537323787325,\n","  'TPR': array([0.66666667, 1.        , 1.        , 0.625     , 0.71428571,\n","         1.        , 1.        , 1.        , 0.71428571, 0.75      ,\n","         0.8       , 0.83333333, 1.        , 0.57142857, 0.6       ,\n","         0.33333333, 1.        , 0.42857143, 0.8       , 0.71428571,\n","         0.55555556, 0.625     , 0.72727273, 0.33333333, 1.        ,\n","         0.6       , 0.54545455, 0.5       , 0.66666667, 0.83333333,\n","         0.22222222, 1.        , 0.85714286, 0.625     , 0.5       ,\n","         0.85714286, 0.5       , 0.71428571, 0.2       , 0.71428571,\n","         0.4       , 0.5       , 1.        , 0.8       , 0.75      ,\n","         0.66666667, 1.        , 0.375     , 0.83333333, 0.83333333,\n","         0.6       , 0.4       , 0.375     , 0.75      , 0.75      ,\n","         0.6       , 0.125     , 0.28571429, 0.42857143, 1.        ,\n","         0.83333333, 0.125     , 0.5       , 1.        , 0.5       ,\n","         0.375     , 1.        , 0.5       , 0.6       , 0.85714286,\n","         0.28571429, 0.5       , 0.33333333, 0.22222222, 0.6       ,\n","         0.57142857, 0.57142857, 1.        , 0.57142857, 0.6       ,\n","         0.14285714, 0.75      , 0.25      , 0.5       , 0.5       ,\n","         0.83333333, 0.83333333, 0.4       , 0.2       , 0.83333333,\n","         1.        , 0.71428571, 0.5       , 0.5       , 0.5       ,\n","         0.375     , 0.66666667, 0.14285714, 0.2       , 0.85714286]),\n","  'Training Time': 0.05631852149963379},\n"," {'AUC': 0,\n","  'Accuracy': 0.484375,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'plant-shape.csv',\n","  'FPR': array([0.00788644, 0.0188383 , 0.01263823, 0.00634921, 0.01417323,\n","         0.00473934, 0.00314465, 0.0047619 , 0.00473934, 0.0015748 ,\n","         0.00628931, 0.00946372, 0.01107595, 0.01102362, 0.01424051,\n","         0.01104101, 0.00947867, 0.00940439, 0.00474684, 0.01574803,\n","         0.00630915, 0.00789889, 0.00628931, 0.01104101, 0.0031746 ,\n","         0.01259843, 0.00631912, 0.00629921, 0.01265823, 0.        ,\n","         0.01419558, 0.01572327, 0.0015748 , 0.00157729, 0.        ,\n","         0.00473934, 0.00473934, 0.00473186, 0.01107595, 0.00315956,\n","         0.00788644, 0.00314465, 0.00471698, 0.00474684, 0.00784929,\n","         0.00629921, 0.00471698, 0.00158228, 0.00472441, 0.00473934,\n","         0.00315457, 0.00946372, 0.00792393, 0.00473934, 0.00157729,\n","         0.00473934, 0.0015748 , 0.        , 0.        , 0.        ,\n","         0.00157978, 0.00158479, 0.00631912, 0.00316456, 0.00157729,\n","         0.00157978, 0.00158983, 0.00944882, 0.00157978, 0.00316456,\n","         0.        , 0.00158228, 0.        , 0.00627943, 0.00158228,\n","         0.00472441, 0.        , 0.        , 0.0015748 , 0.00626959,\n","         0.00158983, 0.00314961, 0.00630915, 0.00471698, 0.00630915,\n","         0.00473186, 0.        , 0.00157729, 0.00315457, 0.00946372,\n","         0.00158479, 0.00630915, 0.00627943, 0.00632911, 0.        ,\n","         0.        , 0.        , 0.00314961, 0.00316456, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236ad978>,\n","  'Inference Time': 0.007632002234458923,\n","  'PR-Curve': 0,\n","  'Precision': 0.5307230824730825,\n","  'TPR': array([0.5       , 0.33333333, 0.57142857, 0.9       , 0.6       ,\n","         1.        , 0.75      , 0.3       , 0.85714286, 1.        ,\n","         0.75      , 0.5       , 0.5       , 0.6       , 0.5       ,\n","         0.33333333, 1.        , 1.        , 0.875     , 0.6       ,\n","         1.        , 0.71428571, 1.        , 0.33333333, 0.5       ,\n","         0.2       , 0.85714286, 0.2       , 0.75      , 0.75      ,\n","         0.33333333, 0.5       , 0.4       , 1.        , 0.5       ,\n","         0.71428571, 0.71428571, 0.5       , 0.5       , 0.71428571,\n","         0.33333333, 0.25      , 0.5       , 0.375     , 0.33333333,\n","         0.8       , 0.75      , 0.25      , 0.8       , 0.14285714,\n","         0.5       , 0.16666667, 0.55555556, 0.14285714, 0.5       ,\n","         0.14285714, 0.4       , 0.14285714, 0.3       , 0.42857143,\n","         0.71428571, 0.11111111, 0.28571429, 0.375     , 0.        ,\n","         0.28571429, 0.27272727, 0.6       , 0.        , 0.125     ,\n","         0.11111111, 0.5       , 0.75      , 1.        , 0.25      ,\n","         0.2       , 0.66666667, 0.16666667, 0.4       , 0.5       ,\n","         0.36363636, 0.4       , 0.16666667, 0.5       , 0.66666667,\n","         0.83333333, 0.14285714, 0.16666667, 0.66666667, 0.66666667,\n","         0.77777778, 0.83333333, 0.66666667, 0.375     , 0.22222222,\n","         0.42857143, 0.        , 0.6       , 0.625     , 0.28571429]),\n","  'Training Time': 0.1345047950744629},\n"," {'AUC': 0,\n","  'Accuracy': 0.640625,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'plant-texture.csv',\n","  'FPR': array([0.02194357, 0.00787402, 0.01102362, 0.00789889, 0.01424051,\n","         0.00471698, 0.00788644, 0.00157729, 0.00473934, 0.00786164,\n","         0.00158479, 0.0300158 , 0.01104101, 0.00315956, 0.00786164,\n","         0.00473934, 0.00157729, 0.00789889, 0.0015873 , 0.00632911,\n","         0.00158479, 0.00631912, 0.        , 0.00158479, 0.00628931,\n","         0.00157233, 0.        , 0.00314961, 0.        , 0.00787402,\n","         0.00158479, 0.00314465, 0.00630915, 0.00316456, 0.00157978,\n","         0.00157729, 0.        , 0.00473934, 0.        , 0.00315956,\n","         0.0015748 , 0.0015748 , 0.00315457, 0.0015748 , 0.        ,\n","         0.00157729, 0.00470958, 0.00157978, 0.00630915, 0.00157978,\n","         0.        , 0.00630915, 0.00314961, 0.00157233, 0.00784929,\n","         0.00627943, 0.0015873 , 0.00629921, 0.00157978, 0.00471698,\n","         0.00314961, 0.        , 0.00156986, 0.        , 0.00157978,\n","         0.        , 0.00315457, 0.00472441, 0.00473186, 0.        ,\n","         0.0015748 , 0.00314465, 0.        , 0.        , 0.00629921,\n","         0.0031746 , 0.        , 0.00315956, 0.        , 0.00473934,\n","         0.00158228, 0.00316456, 0.        , 0.00157729, 0.00158228,\n","         0.        , 0.00315457, 0.00788644, 0.        , 0.00157729,\n","         0.        , 0.00157729, 0.00314961, 0.00473186, 0.00631912,\n","         0.        , 0.        , 0.        , 0.00314465, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14233215f8>,\n","  'Inference Time': 0.007181987166404724,\n","  'PR-Curve': 0,\n","  'Precision': 0.6661564935064935,\n","  'TPR': array([1.        , 0.8       , 1.        , 0.85714286, 0.625     ,\n","         1.        , 0.5       , 1.        , 1.        , 0.75      ,\n","         0.88888889, 0.85714286, 0.83333333, 0.57142857, 0.5       ,\n","         0.71428571, 0.83333333, 0.85714286, 0.3       , 0.75      ,\n","         0.55555556, 0.85714286, 0.        , 0.77777778, 1.        ,\n","         0.25      , 0.75      , 0.2       , 0.28571429, 0.        ,\n","         0.55555556, 0.5       , 0.33333333, 0.875     , 0.85714286,\n","         0.66666667, 0.8       , 0.14285714, 0.72727273, 0.28571429,\n","         0.6       , 0.8       , 0.33333333, 0.8       , 0.66666667,\n","         0.83333333, 0.33333333, 0.42857143, 0.83333333, 0.14285714,\n","         0.375     , 0.5       , 0.6       , 1.        , 0.        ,\n","         1.        , 0.4       , 0.6       , 0.85714286, 1.        ,\n","         0.8       , 1.        , 0.66666667, 0.5       , 0.71428571,\n","         0.42857143, 0.83333333, 1.        , 1.        , 0.88888889,\n","         0.4       , 0.75      , 0.4       , 1.        , 0.6       ,\n","         0.5       , 0.625     , 0.42857143, 0.83333333, 0.85714286,\n","         0.625     , 0.375     , 0.33333333, 0.5       , 0.375     ,\n","         1.        , 0.33333333, 1.        , 0.83333333, 0.5       ,\n","         0.5       , 0.83333333, 1.        , 0.83333333, 0.57142857,\n","         0.75      , 0.625     , 0.71428571, 0.75      , 0.        ]),\n","  'Training Time': 0.06335282325744629},\n"," {'AUC': 0,\n","  'Accuracy': 0.6388888888888888,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'post-operative.csv',\n","  'FPR': array([0.5       , 0.33333333]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14238ba2e8>,\n","  'Inference Time': 0.0109606319003635,\n","  'PR-Curve': 0,\n","  'Precision': 0.5501672240802675,\n","  'TPR': array([0.66666667, 0.5       ]),\n","  'Training Time': 0.0029251575469970703},\n"," {'AUC': 0,\n","  'Accuracy': 0.8452380952380952,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'seeds.csv',\n","  'FPR': array([0.21428571, 0.01818182, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14238ba128>,\n","  'Inference Time': 0.0036557515462239585,\n","  'PR-Curve': 0,\n","  'Precision': 0.8841025641025642,\n","  'TPR': array([0.96428571, 0.82758621, 0.74074074]),\n","  'Training Time': 0.002568960189819336},\n"," {'AUC': 0,\n","  'Accuracy': 0.8134796238244514,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'semeion.csv',\n","  'FPR': array([0.0173913 , 0.03658537, 0.02595156, 0.01048951, 0.01405975,\n","         0.01546392, 0.02763385, 0.02439024, 0.00880282, 0.0262697 ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14238ba470>,\n","  'Inference Time': 0.005812854228722264,\n","  'PR-Curve': 0,\n","  'Precision': 0.8148706905592004,\n","  'TPR': array([1.        , 0.734375  , 0.78333333, 0.78787879, 0.7826087 ,\n","         0.83928571, 0.83050847, 0.859375  , 0.82857143, 0.70149254]),\n","  'Training Time': 0.03711581230163574},\n"," {'AUC': 0,\n","  'Accuracy': 0.9343065693430657,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'soybean.csv',\n","  'FPR': array([0.        , 0.        , 0.        , 0.01276596, 0.00393701,\n","         0.        , 0.        , 0.01234568, 0.        , 0.        ,\n","         0.        , 0.0078125 , 0.0037594 , 0.02521008, 0.0041841 ,\n","         0.        , 0.0037037 , 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14233336a0>,\n","  'Inference Time': 0.003420523483387745,\n","  'PR-Curve': 0,\n","  'Precision': 0.9474978601114421,\n","  'TPR': array([0.9375    , 0.88888889, 1.        , 1.        , 1.        ,\n","         0.83333333, 1.        , 1.        , 0.875     , 0.77777778,\n","         1.        , 0.88888889, 0.375     , 0.97222222, 0.91428571,\n","         1.        , 1.        , 0.66666667]),\n","  'Training Time': 0.006072282791137695},\n"," {'AUC': 0,\n","  'Accuracy': 0.9239543726235742,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'spambase.csv',\n","  'FPR': array([0.17021277, 0.01101928]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14238ba5f8>,\n","  'Inference Time': 0.0012998409986107458,\n","  'PR-Curve': 0,\n","  'Precision': 0.9374540045408284,\n","  'TPR': array([0.98898072, 0.82978723]),\n","  'Training Time': 0.02933502197265625},\n"," {'AUC': 0,\n","  'Accuracy': 0.6698113207547169,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'spect.csv',\n","  'FPR': array([0.42857143, 0.265625  ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236b3208>,\n","  'Inference Time': 0.0047616238863963005,\n","  'PR-Curve': 0,\n","  'Precision': 0.6542213883677298,\n","  'TPR': array([0.734375  , 0.57142857]),\n","  'Training Time': 0.0035088062286376953},\n"," {'AUC': 0,\n","  'Accuracy': 0.8691588785046729,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'spectf.csv',\n","  'FPR': array([0.08045977, 0.35      ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423333d68>,\n","  'Inference Time': 0.006120895670953198,\n","  'PR-Curve': 0,\n","  'Precision': 0.7847701149425288,\n","  'TPR': array([0.65      , 0.91954023]),\n","  'Training Time': 0.005079507827758789},\n"," {'AUC': 0,\n","  'Accuracy': 0.6159420289855072,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'statlog-australian-credit.csv',\n","  'FPR': array([0.19371728, 0.81176471]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423333278>,\n","  'Inference Time': 0.0047580055568529215,\n","  'PR-Curve': 0,\n","  'Precision': 0.49623487604704286,\n","  'TPR': array([0.18823529, 0.80628272]),\n","  'Training Time': 0.004197359085083008},\n"," {'AUC': 0,\n","  'Accuracy': 0.715,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'statlog-german-credit.csv',\n","  'FPR': array([0.84745763, 0.04964539]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f142368e5f8>,\n","  'Inference Time': 0.0024718046188354492,\n","  'PR-Curve': 0,\n","  'Precision': 0.6453804347826086,\n","  'TPR': array([0.95035461, 0.15254237]),\n","  'Training Time': 0.007550954818725586},\n"," {'AUC': 0,\n","  'Accuracy': 0.6388888888888888,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'statlog-heart_.csv',\n","  'FPR': array([0.42222222, 0.31746032]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236f47b8>,\n","  'Inference Time': 0.004006756676567925,\n","  'PR-Curve': 0,\n","  'Precision': 0.6293828892005611,\n","  'TPR': array([0.68253968, 0.57777778]),\n","  'Training Time': 0.0032346248626708984},\n"," {'AUC': 0,\n","  'Accuracy': 0.8495670995670995,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'statlog-image.csv',\n","  'FPR': array([0.05      , 0.01867995, 0.03069054, 0.03037975, 0.01918159,\n","         0.02386935, 0.00252845]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236f4048>,\n","  'Inference Time': 0.0012720818127388562,\n","  'PR-Curve': 0,\n","  'Precision': 0.8530090150555857,\n","  'TPR': array([0.97580645, 0.97520661, 0.83802817, 0.70149254, 0.73943662,\n","         0.8046875 , 0.93984962]),\n","  'Training Time': 0.01457834243774414},\n"," {'AUC': 0,\n","  'Accuracy': 0.6076696165191741,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'statlog-vehicle.csv',\n","  'FPR': array([0.09016393, 0.24535316, 0.16115702, 0.02290076]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14233b9c88>,\n","  'Inference Time': 0.001974865398575774,\n","  'PR-Curve': 0,\n","  'Precision': 0.6173410529967907,\n","  'TPR': array([0.90526316, 0.55714286, 0.26804124, 0.71428571]),\n","  'Training Time': 0.006207704544067383},\n"," {'AUC': 0,\n","  'Accuracy': 0.7966537966537967,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'steel-plates.csv',\n","  'FPR': array([0.03878116, 0.03174603, 0.00489396, 0.00267023, 0.00396301,\n","         0.07232704, 0.1097561 ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14236f4fd0>,\n","  'Inference Time': 0.001555090551977759,\n","  'PR-Curve': 0,\n","  'Precision': 0.7885906824318756,\n","  'TPR': array([0.81818182, 0.71428571, 0.94512195, 0.96428571, 0.5       ,\n","         0.71631206, 0.7754386 ]),\n","  'Training Time': 0.016406536102294922},\n"," {'AUC': 0,\n","  'Accuracy': 0.8708333333333333,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'synthetic-control.csv',\n","  'FPR': array([0.04615385, 0.        , 0.04040404, 0.01456311, 0.04      ,\n","         0.01507538]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14233b9940>,\n","  'Inference Time': 0.004088878631591797,\n","  'PR-Curve': 0,\n","  'Precision': 0.8743812240615311,\n","  'TPR': array([0.95555556, 1.        , 0.9047619 , 0.94117647, 0.65      ,\n","         0.7804878 ]),\n","  'Training Time': 0.013398408889770508},\n"," {'AUC': 0,\n","  'Accuracy': 0.8032786885245902,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'teaching.csv',\n","  'FPR': array([0.13157895, 0.1627907 , 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14233b9f28>,\n","  'Inference Time': 0.005518803831006659,\n","  'PR-Curve': 0,\n","  'Precision': 0.8244949494949495,\n","  'TPR': array([0.82608696, 0.83333333, 0.75      ]),\n","  'Training Time': 0.0025386810302734375},\n"," {'AUC': 0,\n","  'Accuracy': 0.9739583333333334,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'tic-tac-toe.csv',\n","  'FPR': array([0.        , 0.08264463]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14238ccf60>,\n","  'Inference Time': 0.0013882915178934732,\n","  'PR-Curve': 0,\n","  'Precision': 0.9816849816849818,\n","  'TPR': array([0.91735537, 1.        ]),\n","  'Training Time': 0.0030035972595214844},\n"," {'AUC': 0,\n","  'Accuracy': 0.9795686719636776,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'titanic.csv',\n","  'FPR': array([0.01993355, 0.02068966]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14238cc128>,\n","  'Inference Time': 0.0005393509967643747,\n","  'PR-Curve': 0,\n","  'Precision': 0.9752295452223949,\n","  'TPR': array([0.97931034, 0.98006645]),\n","  'Training Time': 0.0027251243591308594},\n"," {'AUC': 0,\n","  'Accuracy': 0.8709677419354839,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'vertebral-column-2clases.csv',\n","  'FPR': array([0.48484848, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14233b95f8>,\n","  'Inference Time': 0.00446458016672442,\n","  'PR-Curve': 0,\n","  'Precision': 0.9252336448598131,\n","  'TPR': array([1.        , 0.51515152]),\n","  'Training Time': 0.0018994808197021484},\n"," {'AUC': 0,\n","  'Accuracy': 0.782258064516129,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'vertebral-column-3clases.csv',\n","  'FPR': array([0.09090909, 0.1978022 , 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14239357b8>,\n","  'Inference Time': 0.002918704863517515,\n","  'PR-Curve': 0,\n","  'Precision': 0.7784313725490196,\n","  'TPR': array([1.        , 0.81818182, 0.68181818]),\n","  'Training Time': 0.0033020973205566406},\n"," {'AUC': 0,\n","  'Accuracy': 0.9289967934035731,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'wall-following.csv',\n","  'FPR': array([0.05837174, 0.01784749, 0.02682563, 0.00486381]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14239243c8>,\n","  'Inference Time': 0.001184120125798965,\n","  'PR-Curve': 0,\n","  'Precision': 0.9232814929228599,\n","  'TPR': array([0.95119183, 0.91017964, 0.91914388, 0.88976378]),\n","  'Training Time': 0.05327272415161133},\n"," {'AUC': 0,\n","  'Accuracy': 0.635,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'waveform.csv',\n","  'FPR': array([0.26518519, 0.15665399, 0.12434457]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423924da0>,\n","  'Inference Time': 0.001012563705444336,\n","  'PR-Curve': 0,\n","  'Precision': 0.6444961471743539,\n","  'TPR': array([0.69076923, 0.5810219 , 0.63609023]),\n","  'Training Time': 0.045815229415893555},\n"," {'AUC': 0,\n","  'Accuracy': 0.6345,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'waveform-noise.csv',\n","  'FPR': array([0.28324568, 0.14392245, 0.12123494]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423cee400>,\n","  'Inference Time': 0.0015314817428588867,\n","  'PR-Curve': 0,\n","  'Precision': 0.6472587050767676,\n","  'TPR': array([0.69207773, 0.60698027, 0.60416667]),\n","  'Training Time': 0.0934295654296875},\n"," {'AUC': 0,\n","  'Accuracy': 0.8888888888888888,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'wine.csv',\n","  'FPR': array([0.08695652, 0.06666667, 0.01886792]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14600a7320>,\n","  'Inference Time': 0.005804830127292209,\n","  'PR-Curve': 0,\n","  'Precision': 0.8954008954008955,\n","  'TPR': array([0.92307692, 0.85185185, 0.89473684]),\n","  'Training Time': 0.0032873153686523438},\n"," {'AUC': 0,\n","  'Accuracy': 0.53125,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'wine-quality-red.csv',\n","  'FPR': array([0.01253918, 0.03727715, 0.39779006, 0.25765306, 0.04293381,\n","         0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14605da630>,\n","  'Inference Time': 0.0017840415239334106,\n","  'PR-Curve': 0,\n","  'Precision': 0.4599159144847646,\n","  'TPR': array([0.        , 0.13043478, 0.65827338, 0.50806452, 0.33333333,\n","         0.125     ]),\n","  'Training Time': 0.010909318923950195},\n"," {'AUC': 0,\n","  'Accuracy': 0.503061224489796,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'wine-quality-white.csv',\n","  'FPR': array([0.0102459 , 0.05663346, 0.27930535, 0.31593663, 0.06779661,\n","         0.00686741]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423a3f358>,\n","  'Inference Time': 0.0009598780651481785,\n","  'PR-Curve': 0,\n","  'Precision': 0.3841834052828423,\n","  'TPR': array([0.125     , 0.24528302, 0.56747405, 0.57271702, 0.32425068,\n","         0.25373134]),\n","  'Training Time': 0.0221555233001709},\n"," {'AUC': 0,\n","  'Accuracy': 0.43434343434343436,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'yeast.csv',\n","  'FPR': array([0.3649635 , 0.26229508, 0.0755102 , 0.04789272, 0.01206897,\n","         0.00522648, 0.        , 0.00172117, 0.00170358, 0.        ]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f14230f7048>,\n","  'Inference Time': 0.0013554537737811053,\n","  'PR-Curve': 0,\n","  'Precision': 0.3637025107665287,\n","  'TPR': array([0.61202186, 0.48502994, 0.33653846, 0.29166667, 0.14285714,\n","         0.25      , 0.15384615, 0.        , 0.        , 0.        ]),\n","  'Training Time': 0.005968332290649414},\n"," {'AUC': 0,\n","  'Accuracy': 0.5990424895272292,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'abalon.csv',\n","  'FPR': array([0.20604396, 0.20564872, 0.18979409]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1460093e80>,\n","  'Inference Time': 0.00083154008318606,\n","  'PR-Curve': 0,\n","  'Precision': 0.585911575779389,\n","  'TPR': array([0.77374784, 0.39033457, 0.61913357]),\n","  'Training Time': 0.01641535758972168},\n"," {'AUC': 0,\n","  'Accuracy': 0.7906976744186046,\n","  'Algorithm Name': 'Arranged Forest',\n","  'Cross Validation': 0,\n","  'Dataset Name': 'ar4.csv',\n","  'FPR': array([0.88888889, 0.02941176]),\n","  'Hyper-Parameters Values': <__main__.ControlledForestClassifier at 0x7f1423213c88>,\n","  'Inference Time': 0.012830246326535247,\n","  'PR-Curve': 0,\n","  'Precision': 0.6524390243902439,\n","  'TPR': array([0.97058824, 0.11111111]),\n","  'Training Time': 0.0040662288665771484}]"]},"metadata":{"tags":[]},"execution_count":331}]},{"cell_type":"markdown","metadata":{"id":"ObgtZK7jqxdM","colab_type":"text"},"source":["####with kfold"]},{"cell_type":"code","metadata":{"id":"EslLRtgFqztX","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597606851753,"user_tz":-180,"elapsed":23,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["\n","# def arranged_forest(df_name):\n","#   df = data_dic[df_name]\n","#   target = pd.DataFrame(df[df.columns[-1]])\n","#   train = df.drop([df.columns[-1]], axis=1)\n","#   # print()\n","#   # print(df_name)\n","#   # print()\n","#   # print(df)\n","#   data = np.array(df)\n","#   total_num_of_features = len(df.columns)-1\n","#   # print(total_num_of_features)\n","#   feature_per_tree = int(math.sqrt(total_num_of_features))\n","#   num_feature = feature_per_tree * feature_per_tree\n","\n","#   # print(data)\n","#   # print(feature_per_tree)\n","  \n","#   # xtrain, xtest, ytrain, ytest = train_test_split(train, target, test_size=test_size, random_state=random_state)\n","\n","#   # train_x = np.array(xtrain.values.tolist())\n","#   # train_y = np.array(ytrain.values.tolist())\n","#   # test_x = np.array(xtest.values.tolist())\n","#   # test_y = np.array(ytest.values.tolist())\n","\n","\n","#   # if df_name=='audiology-std.csv':\n","#   # print('xtrain')\n","#   # print(train_x.shape)\n","#   # print('ytrain')\n","#   # print(train_y.shape)\n","#   # print('xtest')\n","#   # print(test_x.shape)\n","#   # print('ytest')\n","#   # print(test_y.shape)\n","#   # train_x = data[:, 0:-1]\n","#   # train_y = data[:, -1]\n","  \n","#   # print('train_x')\n","#   # print(train_x.shape)\n","\n","#   # print('train_y')\n","#   # print(train_y.shape)\n","  \n","#   # print('test_x')\n","#   # print(test_x.shape)\n","#   # print('test_y')\n","#   # print(test_y.shape) \n","\n","\n","  \n","\n","#   # test_x = test[:, 0:-1]\n","#   # test_y = test[:, -1]\n","\n","\n","#   train_arr = np.array(train).tolist()\n","#   target_arr = np.array(target).tolist()\n","#   classes = np.unique(target_arr)\n","#   i=0\n","#   start_time = time()\n","#   # print('train_arr')\n","#   # print(train_arr)\n","#   # print('target_arr')\n","#   # print(target_arr)\n","#   # print(data)\n","#   # print(feature_per_tree)\n","  \n","#   kf = KFold(n_splits=10, random_state=random_state, shuffle=True).split(train_arr,target_arr)\n","  \n","#   for train_idx, test_idx in kf:\n","#     i+=1\n","#     # print('train_idx')\n","#     # print(train_idx)\n","#     # print('test_idx')\n","#     # print(test_idx)\n","#     train_x=np.array([train_arr[ii] for ii in train_idx])\n","#     test_x=np.array([train_arr[ii] for ii in test_idx])\n","#     train_y=np.array([target_arr[ii] for ii in train_idx])\n","#     test_y=np.array([target_arr[ii] for ii in test_idx])\n","  \n","#     # print('i = {}'.format(i))\n","#     # print('train_x')\n","#     # print(train_x.shape)\n","\n","#     # print('train_y')\n","#     # print(train_y.shape)\n","    \n","#     # print('test_x')\n","#     # print(test_x.shape)\n","#     # print('test_y')\n","#     # print(test_y.shape) \n","\n","#     boot_xtrain, boot_ytrain = bootstrap_samples(feature_per_tree, train_x, train_y, seed=seed)\n","\n","#     feature_matrix = build_feature_matrix(num_feature=num_feature, feature_per_tree=feature_per_tree)\n","\n","#     k_family_F = modified_diagonal_distribute(feature_per_tree=feature_per_tree, feature_matrix=feature_matrix)\n","\n","#     # print(k_family_F)\n","\n","#     arranged_clf = ControlledForestClassifier(n_estimators=feature_per_tree)\n","\n","#     arranged_clf.fit(k_family_F, boot_xtrain, boot_ytrain, train_y)\n","\n","#     end_time = time()\n","#     inference_start_time = time()\n","\n","#     pred_y = arranged_clf.predict(test_x)\n","\n","#     inference_end_time = time()\n","\n","#     inference_time = (1000/len(pred_y))*(inference_end_time-inference_start_time)\n","    \n","\n","\n","#     acc, tpr, fpr, precision, auc, prc = get_metrics(test_y, pred_y, classes)\n","\n","    \n","\n","#     train_time = end_time - start_time\n","#     params= {'features_per_tree':feature_per_tree, 'num_of_trees':num_feature}\n","#     add_result(df_name,'Arranged Forest', i, params, acc, tpr, fpr, precision, auc, prc, train_time, inference_time)\n","\n","#     # arranged_report = classification_report(test_y, predict_y, output_dict=False)\n","\n","#     # print(arranged_report)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eA6sW5nFNPSB","colab_type":"text"},"source":["##KiGB\n"]},{"cell_type":"markdown","metadata":{"id":"IOKWJjLNRdy_","colab_type":"text"},"source":["###Utils"]},{"cell_type":"code","metadata":{"id":"-_CxVyfJRf5c","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590665991,"user_tz":-180,"elapsed":1476,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["import numpy as np\n","# import pydotplus\n","import matplotlib.pyplot as plt\n","from collections import defaultdict\n","\n","import pydotplus\n","import collections\n","from sklearn import tree\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import mean_absolute_error\n","import logging\n","\n","\"\"\" KiGB update of Scikit Gradient boosting Regressor\"\"\"\n","advice = None\n","epsilon = 0.0\n","lamda = 0.0\n","\n","\n","# Update terminal region with KiGB Penalty\n","def kigb_penalty_update(stage, gbr, fields):\n","    global trees_modified\n","    global node_violations\n","    y_pred = fields['y_pred']\n","    regressor = gbr.estimators_[stage][0]\n","    children_left = regressor.tree_.children_left\n","    children_right = regressor.tree_.children_right\n","    feature = regressor.tree_.feature\n","    samples = regressor.tree_.n_node_samples\n","    values = regressor.tree_.__getstate__()['values']\n","    delta_values = defaultdict(float)\n","    for feature_index in np.where(advice != 0)[0]:\n","        if feature_index in feature:\n","            node_idx_list = np.where(feature == feature_index)[0]\n","            for node_idx in node_idx_list:\n","                stack = [children_left[node_idx]]\n","                # Calculate Expected Value of left child\n","                lvalue = 0.0\n","                lsamples = 0.0\n","                while len(stack) > 0:\n","                    node_id = stack.pop()\n","                    # node is not leaf node\n","                    if children_left[node_id] != children_right[node_id]:\n","                        stack.append(children_left[node_id])\n","                        stack.append(children_right[node_id])\n","                    else:\n","                        lvalue += (values[node_id][0][0] * samples[node_id])\n","                        lsamples += (samples[node_id])\n","                lexpected = lvalue / lsamples\n","                # Calculate Expected Value of right child\n","                rvalue = 0.0\n","                rsamples = 0.0\n","                stack = [children_right[node_idx]]\n","                while len(stack) > 0:\n","                    node_id = stack.pop()\n","                    # node is not leaf node\n","                    if children_left[node_id] != children_right[node_id]:\n","                        stack.append(children_left[node_id])\n","                        stack.append(children_right[node_id])\n","                    else:\n","                        rvalue += (values[node_id][0][0] * samples[node_id])\n","                        rsamples += (samples[node_id])\n","                rexpected = rvalue / rsamples\n","                if advice[feature_index] > 0:\n","                    error = 'isotonic constraint not satisfied for tree ' + str(stage) + \" node \" + str(node_idx)\n","                    if lexpected > (rexpected + epsilon):\n","                        # Isotonic constraint violated, calculate bepsilon penalty\n","                        violation = lexpected - rexpected - epsilon\n","                        logging.debug(error)\n","                        node_violations = node_violations + 1\n","                        # left leaves penalty\n","                        l_samples = samples[children_left[node_idx]]\n","                        logging.debug(\n","                            'left penalty: ' + str(-(lamda * violation) / (2.0 * l_samples)) + ' sample: ' + str(\n","                                l_samples) + ' violation: ' + str(lexpected - rexpected))\n","                        stack = [children_left[node_idx]]\n","                        while len(stack) > 0:\n","                            node_id = stack.pop()\n","                            # node is not leaf node\n","                            if children_left[node_id] != children_right[node_id]:\n","                                stack.append(children_left[node_id])\n","                                stack.append(children_right[node_id])\n","                            else:\n","                                delta_values[node_id] = delta_values[node_id] - (lamda * violation) / (2.0 * l_samples)\n","                        # right leaves penalty\n","                        r_samples = samples[children_right[node_idx]]\n","                        logging.debug(\n","                            'right penalty: ' + str((lamda * violation) / (2.0 * r_samples)) + ' sample: ' + str(\n","                                r_samples) + ' violation: ' + str(lexpected - rexpected))\n","                        stack = [children_right[node_idx]]\n","                        while len(stack) > 0:\n","                            node_id = stack.pop()\n","                            # node is not leaf node\n","                            if children_left[node_id] != children_right[node_id]:\n","                                stack.append(children_left[node_id])\n","                                stack.append(children_right[node_id])\n","                            else:\n","                                delta_values[node_id] = delta_values[node_id] + (lamda * violation) / (2.0 * r_samples)\n","                else:\n","                    error = 'antitonic constraint not satisfied for tree ' + str(stage) + \" node \" + str(node_idx)\n","                    if (lexpected + epsilon) < rexpected:\n","                        # Antitonic constraint violated, calculate beta penalty\n","                        violation = rexpected - lexpected - epsilon\n","                        logging.debug(error)\n","                        node_violations = node_violations + 1\n","                        # left leaves penalty\n","                        l_samples = samples[children_left[node_idx]]\n","                        logging.debug(\n","                            'left penalty: ' + str((lamda * violation) / (2.0 * l_samples)) + ' sample: ' + str(\n","                                l_samples) + ' violation: ' + str(rexpected - lexpected))\n","                        stack = [children_left[node_idx]]\n","                        while len(stack) > 0:\n","                            node_id = stack.pop()\n","                            # node is not leaf node\n","                            if children_left[node_id] != children_right[node_id]:\n","                                stack.append(children_left[node_id])\n","                                stack.append(children_right[node_id])\n","                            else:\n","                                delta_values[node_id] = delta_values[node_id] + (lamda * violation) / (2.0 * l_samples)\n","                        # right leaves penalty\n","                        stack = [children_right[node_idx]]\n","                        r_samples = samples[children_right[node_idx]]\n","                        logging.debug(\n","                            'right penalty: ' + str(-(lamda * violation) / (2.0 * r_samples)) + ' sample: ' + str(\n","                                r_samples) + ' violation: ' + str(rexpected - lexpected))\n","                        while len(stack) > 0:\n","                            node_id = stack.pop()\n","                            # node is not leaf node\n","                            if children_left[node_id] != children_right[node_id]:\n","                                stack.append(children_left[node_id])\n","                                stack.append(children_right[node_id])\n","                            else:\n","                                delta_values[node_id] = delta_values[node_id] - (lamda * violation) / (2.0 * r_samples)\n","    if len(delta_values.keys()) > 0:\n","        trees_modified = trees_modified + 1\n","        X_train = fields['X']\n","        # export_tree(gbr.estimators_.flatten()[stage], features_list, 'temp/before_tree_'+str(stage)+'.png')\n","        for idx in delta_values.keys():\n","            logging.debug(\"Updating node \" + str(idx) + \" prev: \" + str(values[idx][0][0]) + \" new: \" + str(\n","                values[idx][0][0] + delta_values[idx]))\n","            values[idx][0][0] = values[idx][0][0] + delta_values[idx]\n","        decision = regressor.apply(X_train)\n","        y_updated_pred = map(lambda x: [x[1] - delta_values[decision[x[0]]]], enumerate(y_pred))\n","        # export_tree(gbr.estimators_.flatten()[stage], features_list, 'temp/after_tree_'+str(stage)+'.png')\n","        return np.reshape(list(y_updated_pred), (-1, 1))\n","    return y_pred\n","\n","def mse_score(clf, X_test, y_test):\n","    \"\"\"compute stepwise scores on ``X_test`` and ``y_test``. \"\"\"\n","    score = np.zeros((clf.n_estimators,), dtype=np.float64)\n","    for i, y_pred in enumerate(clf._staged_decision_function(X_test)):\n","        score[i] = mean_squared_error(y_test, np.reshape(y_pred, (1, -1))[0])\n","    return score"],"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kNyblSdcRZX9","colab_type":"text"},"source":["###Gradient Boosting"]},{"cell_type":"code","metadata":{"id":"GFPrhNVp3Oti","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590678055,"user_tz":-180,"elapsed":9916,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["\"\"\"Gradient Boosted Regression Trees\n","This module contains methods for fitting gradient boosted regression trees for\n","both classification and regression.\n","The module structure is the following:\n","- The ``BaseGradientBoosting`` base class implements a common ``fit`` method\n","  for all the estimators in the module. Regression and classification\n","  only differ in the concrete ``LossFunction`` used.\n","- ``GradientBoostingClassifier`` implements gradient boosting for\n","  classification problems.\n","- ``GradientBoostingRegressor`` implements gradient boosting for\n","  regression problems.\n","\"\"\"\n","\n","# Authors: Peter Prettenhofer, Scott White, Gilles Louppe, Emanuele Olivetti,\n","#          Arnaud Joly, Jacob Schreiber\n","# License: BSD 3 clause\n","\n","from __future__ import print_function\n","from __future__ import division\n","\n","from abc import ABCMeta\n","from abc import abstractmethod\n","\n","from sklearn.ensemble.base import BaseEnsemble\n","from sklearn.base import ClassifierMixin\n","from sklearn.base import RegressorMixin\n","from sklearn.externals import six\n","\n","from sklearn.ensemble._gradient_boosting import predict_stages\n","from sklearn.ensemble._gradient_boosting import predict_stage\n","from sklearn.ensemble._gradient_boosting import _random_sample_mask\n","\n","import numbers\n","import numpy as np\n","\n","from scipy import stats\n","from scipy.sparse import csc_matrix\n","from scipy.sparse import csr_matrix\n","from scipy.sparse import issparse\n","from scipy.special import expit\n","\n","from time import time\n","from sklearn.tree.tree import DecisionTreeRegressor\n","from sklearn.tree._tree import DTYPE\n","from sklearn.tree._tree import TREE_LEAF\n","\n","from sklearn.utils import check_random_state\n","from sklearn.utils import check_array\n","from sklearn.utils import check_X_y\n","from sklearn.utils import column_or_1d\n","from sklearn.utils import check_consistent_length\n","from sklearn.utils import deprecated\n","from sklearn.utils.fixes import logsumexp\n","from sklearn.utils.stats import _weighted_percentile\n","from sklearn.utils.validation import check_is_fitted\n","from sklearn.utils.multiclass import check_classification_targets\n","from sklearn.exceptions import NotFittedError\n","\n","\n","class QuantileEstimator(object):\n","    \"\"\"An estimator predicting the alpha-quantile of the training targets.\"\"\"\n","\n","    def __init__(self, alpha=0.9):\n","        if not 0 < alpha < 1.0:\n","            raise ValueError(\"`alpha` must be in (0, 1.0) but was %r\" % alpha)\n","        self.alpha = alpha\n","\n","    def fit(self, X, y, sample_weight=None):\n","        if sample_weight is None:\n","            self.quantile = stats.scoreatpercentile(y, self.alpha * 100.0)\n","        else:\n","            self.quantile = _weighted_percentile(y, sample_weight,\n","                                                 self.alpha * 100.0)\n","\n","    def predict(self, X):\n","        check_is_fitted(self, 'quantile')\n","\n","        y = np.empty((X.shape[0], 1), dtype=np.float64)\n","        y.fill(self.quantile)\n","        return y\n","\n","\n","class MeanEstimator(object):\n","    \"\"\"An estimator predicting the mean of the training targets.\"\"\"\n","\n","    def fit(self, X, y, sample_weight=None):\n","        if sample_weight is None:\n","            self.mean = np.mean(y)\n","        else:\n","            self.mean = np.average(y, weights=sample_weight)\n","\n","    def predict(self, X):\n","        check_is_fitted(self, 'mean')\n","\n","        y = np.empty((X.shape[0], 1), dtype=np.float64)\n","        y.fill(self.mean)\n","        return y\n","\n","\n","class LogOddsEstimator(object):\n","    \"\"\"An estimator predicting the log odds ratio.\"\"\"\n","    scale = 1.0\n","\n","    def fit(self, X, y, sample_weight=None):\n","        # pre-cond: pos, neg are encoded as 1, 0\n","        if sample_weight is None:\n","            pos = np.sum(y)\n","            neg = y.shape[0] - pos\n","        else:\n","            pos = np.sum(sample_weight * y)\n","            neg = np.sum(sample_weight * (1 - y))\n","\n","        if neg == 0 or pos == 0:\n","            raise ValueError('y contains non binary labels.')\n","        self.prior = self.scale * np.log(pos / neg)\n","\n","    def predict(self, X):\n","        check_is_fitted(self, 'prior')\n","\n","        y = np.empty((X.shape[0], 1), dtype=np.float64)\n","        y.fill(self.prior)\n","        return y\n","\n","\n","class ScaledLogOddsEstimator(LogOddsEstimator):\n","    \"\"\"Log odds ratio scaled by 0.5 -- for exponential loss. \"\"\"\n","    scale = 0.5\n","\n","\n","class PriorProbabilityEstimator(object):\n","    \"\"\"An estimator predicting the probability of each\n","    class in the training data.\n","    \"\"\"\n","\n","    def fit(self, X, y, sample_weight=None):\n","        if sample_weight is None:\n","            sample_weight = np.ones_like(y, dtype=np.float64)\n","        class_counts = np.bincount(y, weights=sample_weight)\n","        self.priors = class_counts / class_counts.sum()\n","\n","    def predict(self, X):\n","        check_is_fitted(self, 'priors')\n","\n","        y = np.empty((X.shape[0], self.priors.shape[0]), dtype=np.float64)\n","        y[:] = self.priors\n","        return y\n","\n","\n","class ZeroEstimator(object):\n","    \"\"\"An estimator that simply predicts zero. \"\"\"\n","\n","    def fit(self, X, y, sample_weight=None):\n","        if np.issubdtype(y.dtype, np.signedinteger):\n","            # classification\n","            self.n_classes = np.unique(y).shape[0]\n","            if self.n_classes == 2:\n","                self.n_classes = 1\n","        else:\n","            # regression\n","            self.n_classes = 1\n","\n","    def predict(self, X):\n","        check_is_fitted(self, 'n_classes')\n","\n","        y = np.empty((X.shape[0], self.n_classes), dtype=np.float64)\n","        y.fill(0.0)\n","        return y\n","\n","\n","class LossFunction(six.with_metaclass(ABCMeta, object)):\n","    \"\"\"Abstract base class for various loss functions.\n","    Attributes\n","    ----------\n","    K : int\n","        The number of regression trees to be induced;\n","        1 for regression and binary classification;\n","        ``n_classes`` for multi-class classification.\n","    \"\"\"\n","\n","    is_multi_class = False\n","\n","    def __init__(self, n_classes):\n","        self.K = n_classes\n","\n","    def init_estimator(self):\n","        \"\"\"Default ``init`` estimator for loss function. \"\"\"\n","        raise NotImplementedError()\n","\n","    @abstractmethod\n","    def __call__(self, y, pred, sample_weight=None):\n","        \"\"\"Compute the loss of prediction ``pred`` and ``y``. \"\"\"\n","\n","    @abstractmethod\n","    def negative_gradient(self, y, y_pred, **kargs):\n","        \"\"\"Compute the negative gradient.\n","        Parameters\n","        ---------\n","        y : np.ndarray, shape=(n,)\n","            The target labels.\n","        y_pred : np.ndarray, shape=(n,):\n","            The predictions.\n","        \"\"\"\n","\n","    def update_terminal_regions(self, tree, X, y, residual, y_pred,\n","                                sample_weight, sample_mask,\n","                                learning_rate=1.0, k=0):\n","        \"\"\"Update the terminal regions (=leaves) of the given tree and\n","        updates the current predictions of the model. Traverses tree\n","        and invokes template method `_update_terminal_region`.\n","        Parameters\n","        ----------\n","        tree : tree.Tree\n","            The tree object.\n","        X : ndarray, shape=(n, m)\n","            The data array.\n","        y : ndarray, shape=(n,)\n","            The target labels.\n","        residual : ndarray, shape=(n,)\n","            The residuals (usually the negative gradient).\n","        y_pred : ndarray, shape=(n,)\n","            The predictions.\n","        sample_weight : ndarray, shape=(n,)\n","            The weight of each sample.\n","        sample_mask : ndarray, shape=(n,)\n","            The sample mask to be used.\n","        learning_rate : float, default=0.1\n","            learning rate shrinks the contribution of each tree by\n","             ``learning_rate``.\n","        k : int, default 0\n","            The index of the estimator being updated.\n","        \"\"\"\n","        # compute leaf for each sample in ``X``.\n","        terminal_regions = tree.apply(X)\n","\n","        # mask all which are not in sample mask.\n","        masked_terminal_regions = terminal_regions.copy()\n","        masked_terminal_regions[~sample_mask] = -1\n","\n","        # update each leaf (= perform line search)\n","        for leaf in np.where(tree.children_left == TREE_LEAF)[0]:\n","            self._update_terminal_region(tree, masked_terminal_regions,\n","                                         leaf, X, y, residual,\n","                                         y_pred[:, k], sample_weight)\n","\n","        # update predictions (both in-bag and out-of-bag)\n","        y_pred[:, k] += (learning_rate\n","                         * tree.value[:, 0, 0].take(terminal_regions, axis=0))\n","\n","    @abstractmethod\n","    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n","                                residual, pred, sample_weight):\n","        \"\"\"Template method for updating terminal regions (=leaves). \"\"\"\n","\n","\n","class RegressionLossFunction(six.with_metaclass(ABCMeta, LossFunction)):\n","    \"\"\"Base class for regression loss functions. \"\"\"\n","\n","    def __init__(self, n_classes):\n","        if n_classes != 1:\n","            raise ValueError(\"``n_classes`` must be 1 for regression but \"\n","                             \"was %r\" % n_classes)\n","        super(RegressionLossFunction, self).__init__(n_classes)\n","\n","\n","class LeastSquaresError(RegressionLossFunction):\n","    \"\"\"Loss function for least squares (LS) estimation.\n","    Terminal regions need not to be updated for least squares. \"\"\"\n","\n","    def init_estimator(self):\n","        return MeanEstimator()\n","\n","    def __call__(self, y, pred, sample_weight=None):\n","        if sample_weight is None:\n","            return np.mean((y - pred.ravel()) ** 2.0)\n","        else:\n","            return (1.0 / sample_weight.sum() *\n","                    np.sum(sample_weight * ((y - pred.ravel()) ** 2.0)))\n","\n","    def negative_gradient(self, y, pred, **kargs):\n","        return y - pred.ravel()\n","\n","    def update_terminal_regions(self, tree, X, y, residual, y_pred,\n","                                sample_weight, sample_mask,\n","                                learning_rate=1.0, k=0):\n","        \"\"\"Least squares does not need to update terminal regions.\n","        But it has to update the predictions.\n","        \"\"\"\n","        # update predictions\n","        y_pred[:, k] += learning_rate * tree.predict(X).ravel()\n","\n","    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n","                                residual, pred, sample_weight):\n","        pass\n","\n","\n","class LeastAbsoluteError(RegressionLossFunction):\n","    \"\"\"Loss function for least absolute deviation (LAD) regression. \"\"\"\n","\n","    def init_estimator(self):\n","        return QuantileEstimator(alpha=0.5)\n","\n","    def __call__(self, y, pred, sample_weight=None):\n","        if sample_weight is None:\n","            return np.abs(y - pred.ravel()).mean()\n","        else:\n","            return (1.0 / sample_weight.sum() *\n","                    np.sum(sample_weight * np.abs(y - pred.ravel())))\n","\n","    def negative_gradient(self, y, pred, **kargs):\n","        \"\"\"1.0 if y - pred > 0.0 else -1.0\"\"\"\n","        pred = pred.ravel()\n","        return 2.0 * (y - pred > 0.0) - 1.0\n","\n","    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n","                                residual, pred, sample_weight):\n","        \"\"\"LAD updates terminal regions to median estimates. \"\"\"\n","        terminal_region = np.where(terminal_regions == leaf)[0]\n","        sample_weight = sample_weight.take(terminal_region, axis=0)\n","        diff = y.take(terminal_region, axis=0) - pred.take(terminal_region, axis=0)\n","        tree.value[leaf, 0, 0] = _weighted_percentile(diff, sample_weight, percentile=50)\n","\n","\n","class LeastAbsolutePercentageError(RegressionLossFunction):\n","    \"\"\"Loss function for least absolute percentage deviation (LAPD) regression. \"\"\"\n","\n","    def init_estimator(self):\n","        return QuantileEstimator(alpha=0.5)\n","\n","    def __call__(self, y, pred, sample_weight=None):\n","        if sample_weight is None:\n","            return np.abs(y - pred.ravel()).mean()\n","        else:\n","            return (1.0 / sample_weight.sum() *\n","                    np.sum(sample_weight * np.abs(y - pred.ravel())))\n","\n","    def negative_gradient(self, y, pred, **kargs):\n","        \"\"\"1.0 if y - pred > 0.0 else -1.0\"\"\"\n","        pred = pred.ravel()\n","        return 2.0 * (y - pred > 0.0) - 1.0\n","\n","    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n","                                residual, pred, sample_weight):\n","        \"\"\"LAD updates terminal regions to median estimates. \"\"\"\n","        terminal_region = np.where(terminal_regions == leaf)[0]\n","        sample_weight = sample_weight.take(terminal_region, axis=0)\n","        diff = y.take(terminal_region, axis=0) - pred.take(terminal_region, axis=0)\n","        tree.value[leaf, 0, 0] = _weighted_percentile(diff, sample_weight, percentile=50)\n","\n","\n","class HuberLossFunction(RegressionLossFunction):\n","    \"\"\"Huber loss function for robust regression.\n","    M-Regression proposed in Friedman 2001.\n","    References\n","    ----------\n","    J. Friedman, Greedy Function Approximation: A Gradient Boosting\n","    Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n","    \"\"\"\n","\n","    def __init__(self, n_classes, alpha=0.9):\n","        super(HuberLossFunction, self).__init__(n_classes)\n","        self.alpha = alpha\n","        self.gamma = None\n","\n","    def init_estimator(self):\n","        return QuantileEstimator(alpha=0.5)\n","\n","    def __call__(self, y, pred, sample_weight=None):\n","        pred = pred.ravel()\n","        diff = y - pred\n","        gamma = self.gamma\n","        if gamma is None:\n","            if sample_weight is None:\n","                gamma = stats.scoreatpercentile(np.abs(diff), self.alpha * 100)\n","            else:\n","                gamma = _weighted_percentile(np.abs(diff), sample_weight, self.alpha * 100)\n","\n","        gamma_mask = np.abs(diff) <= gamma\n","        if sample_weight is None:\n","            sq_loss = np.sum(0.5 * diff[gamma_mask] ** 2.0)\n","            lin_loss = np.sum(gamma * (np.abs(diff[~gamma_mask]) - gamma / 2.0))\n","            loss = (sq_loss + lin_loss) / y.shape[0]\n","        else:\n","            sq_loss = np.sum(0.5 * sample_weight[gamma_mask] * diff[gamma_mask] ** 2.0)\n","            lin_loss = np.sum(gamma * sample_weight[~gamma_mask] *\n","                              (np.abs(diff[~gamma_mask]) - gamma / 2.0))\n","            loss = (sq_loss + lin_loss) / sample_weight.sum()\n","        return loss\n","\n","    def negative_gradient(self, y, pred, sample_weight=None, **kargs):\n","        pred = pred.ravel()\n","        diff = y - pred\n","        if sample_weight is None:\n","            gamma = stats.scoreatpercentile(np.abs(diff), self.alpha * 100)\n","        else:\n","            gamma = _weighted_percentile(np.abs(diff), sample_weight, self.alpha * 100)\n","        gamma_mask = np.abs(diff) <= gamma\n","        residual = np.zeros((y.shape[0],), dtype=np.float64)\n","        residual[gamma_mask] = diff[gamma_mask]\n","        residual[~gamma_mask] = gamma * np.sign(diff[~gamma_mask])\n","        self.gamma = gamma\n","        return residual\n","\n","    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n","                                residual, pred, sample_weight):\n","        terminal_region = np.where(terminal_regions == leaf)[0]\n","        sample_weight = sample_weight.take(terminal_region, axis=0)\n","        gamma = self.gamma\n","        diff = (y.take(terminal_region, axis=0)\n","                - pred.take(terminal_region, axis=0))\n","        median = _weighted_percentile(diff, sample_weight, percentile=50)\n","        diff_minus_median = diff - median\n","        tree.value[leaf, 0] = median + np.mean(\n","            np.sign(diff_minus_median) *\n","            np.minimum(np.abs(diff_minus_median), gamma))\n","\n","\n","class QuantileLossFunction(RegressionLossFunction):\n","    \"\"\"Loss function for quantile regression.\n","    Quantile regression allows to estimate the percentiles\n","    of the conditional distribution of the target.\n","    \"\"\"\n","\n","    def __init__(self, n_classes, alpha=0.9):\n","        super(QuantileLossFunction, self).__init__(n_classes)\n","        assert 0 < alpha < 1.0\n","        self.alpha = alpha\n","        self.percentile = alpha * 100.0\n","\n","    def init_estimator(self):\n","        return QuantileEstimator(self.alpha)\n","\n","    def __call__(self, y, pred, sample_weight=None):\n","        pred = pred.ravel()\n","        diff = y - pred\n","        alpha = self.alpha\n","\n","        mask = y > pred\n","        if sample_weight is None:\n","            loss = (alpha * diff[mask].sum() -\n","                    (1.0 - alpha) * diff[~mask].sum()) / y.shape[0]\n","        else:\n","            loss = ((alpha * np.sum(sample_weight[mask] * diff[mask]) -\n","                     (1.0 - alpha) * np.sum(sample_weight[~mask] * diff[~mask])) /\n","                    sample_weight.sum())\n","        return loss\n","\n","    def negative_gradient(self, y, pred, **kargs):\n","        alpha = self.alpha\n","        pred = pred.ravel()\n","        mask = y > pred\n","        return (alpha * mask) - ((1.0 - alpha) * ~mask)\n","\n","    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n","                                residual, pred, sample_weight):\n","        terminal_region = np.where(terminal_regions == leaf)[0]\n","        diff = (y.take(terminal_region, axis=0)\n","                - pred.take(terminal_region, axis=0))\n","        sample_weight = sample_weight.take(terminal_region, axis=0)\n","\n","        val = _weighted_percentile(diff, sample_weight, self.percentile)\n","        tree.value[leaf, 0] = val\n","\n","\n","class ClassificationLossFunction(six.with_metaclass(ABCMeta, LossFunction)):\n","    \"\"\"Base class for classification loss functions. \"\"\"\n","\n","    def _score_to_proba(self, score):\n","        \"\"\"Template method to convert scores to probabilities.\n","         the does not support probabilities raises AttributeError.\n","        \"\"\"\n","        raise TypeError('%s does not support predict_proba' % type(self).__name__)\n","\n","    @abstractmethod\n","    def _score_to_decision(self, score):\n","        \"\"\"Template method to convert scores to decisions.\n","        Returns int arrays.\n","        \"\"\"\n","\n","\n","class BinomialDeviance(ClassificationLossFunction):\n","    \"\"\"Binomial deviance loss function for binary classification.\n","    Binary classification is a special case; here, we only need to\n","    fit one tree instead of ``n_classes`` trees.\n","    \"\"\"\n","\n","    def __init__(self, n_classes):\n","        if n_classes != 2:\n","            raise ValueError(\"{0:s} requires 2 classes.\".format(\n","                self.__class__.__name__))\n","        # we only need to fit one tree for binary clf.\n","        super(BinomialDeviance, self).__init__(1)\n","\n","    def init_estimator(self):\n","        return LogOddsEstimator()\n","\n","    def __call__(self, y, pred, sample_weight=None):\n","        \"\"\"Compute the deviance (= 2 * negative log-likelihood). \"\"\"\n","        # logaddexp(0, v) == log(1.0 + exp(v))\n","        pred = pred.ravel()\n","        if sample_weight is None:\n","            return -2.0 * np.mean((y * pred) - np.logaddexp(0.0, pred))\n","        else:\n","            return (-2.0 / sample_weight.sum() *\n","                    np.sum(sample_weight * ((y * pred) - np.logaddexp(0.0, pred))))\n","\n","    def negative_gradient(self, y, pred, **kargs):\n","        \"\"\"Compute the residual (= negative gradient). \"\"\"\n","        return y - expit(pred.ravel())\n","\n","    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n","                                residual, pred, sample_weight):\n","        \"\"\"Make a single Newton-Raphson step.\n","        our node estimate is given by:\n","            sum(w * (y - prob)) / sum(w * prob * (1 - prob))\n","        we take advantage that: y - prob = residual\n","        \"\"\"\n","        terminal_region = np.where(terminal_regions == leaf)[0]\n","        residual = residual.take(terminal_region, axis=0)\n","        y = y.take(terminal_region, axis=0)\n","        sample_weight = sample_weight.take(terminal_region, axis=0)\n","\n","        numerator = np.sum(sample_weight * residual)\n","        denominator = np.sum(sample_weight * (y - residual) * (1 - y + residual))\n","\n","        # prevents overflow and division by zero\n","        if abs(denominator) < 1e-150:\n","            tree.value[leaf, 0, 0] = 0.0\n","        else:\n","            tree.value[leaf, 0, 0] = numerator / denominator\n","\n","    def _score_to_proba(self, score):\n","        proba = np.ones((score.shape[0], 2), dtype=np.float64)\n","        proba[:, 1] = expit(score.ravel())\n","        proba[:, 0] -= proba[:, 1]\n","        return proba\n","\n","    def _score_to_decision(self, score):\n","        proba = self._score_to_proba(score)\n","        return np.argmax(proba, axis=1)\n","\n","\n","class MultinomialDeviance(ClassificationLossFunction):\n","    \"\"\"Multinomial deviance loss function for multi-class classification.\n","    For multi-class classification we need to fit ``n_classes`` trees at\n","    each stage.\n","    \"\"\"\n","\n","    is_multi_class = True\n","\n","    def __init__(self, n_classes):\n","        if n_classes < 3:\n","            raise ValueError(\"{0:s} requires more than 2 classes.\".format(\n","                self.__class__.__name__))\n","        super(MultinomialDeviance, self).__init__(n_classes)\n","\n","    def init_estimator(self):\n","        return PriorProbabilityEstimator()\n","\n","    def __call__(self, y, pred, sample_weight=None):\n","        # create one-hot label encoding\n","        Y = np.zeros((y.shape[0], self.K), dtype=np.float64)\n","        for k in range(self.K):\n","            Y[:, k] = y == k\n","\n","        if sample_weight is None:\n","            return np.sum(-1 * (Y * pred).sum(axis=1) +\n","                          logsumexp(pred, axis=1))\n","        else:\n","            return np.sum(-1 * sample_weight * (Y * pred).sum(axis=1) +\n","                          logsumexp(pred, axis=1))\n","\n","    def negative_gradient(self, y, pred, k=0, **kwargs):\n","        \"\"\"Compute negative gradient for the ``k``-th class. \"\"\"\n","        return y - np.nan_to_num(np.exp(pred[:, k] -\n","                                        logsumexp(pred, axis=1)))\n","\n","    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n","                                residual, pred, sample_weight):\n","        \"\"\"Make a single Newton-Raphson step. \"\"\"\n","        terminal_region = np.where(terminal_regions == leaf)[0]\n","        residual = residual.take(terminal_region, axis=0)\n","        y = y.take(terminal_region, axis=0)\n","        sample_weight = sample_weight.take(terminal_region, axis=0)\n","\n","        numerator = np.sum(sample_weight * residual)\n","        numerator *= (self.K - 1) / self.K\n","\n","        denominator = np.sum(sample_weight * (y - residual) *\n","                             (1.0 - y + residual))\n","\n","        # prevents overflow and division by zero\n","        if abs(denominator) < 1e-150:\n","            tree.value[leaf, 0, 0] = 0.0\n","        else:\n","            tree.value[leaf, 0, 0] = numerator / denominator\n","\n","    def _score_to_proba(self, score):\n","        return np.nan_to_num(\n","            np.exp(score - (logsumexp(score, axis=1)[:, np.newaxis])))\n","\n","    def _score_to_decision(self, score):\n","        proba = self._score_to_proba(score)\n","        return np.argmax(proba, axis=1)\n","\n","\n","class ExponentialLoss(ClassificationLossFunction):\n","    \"\"\"Exponential loss function for binary classification.\n","    Same loss as AdaBoost.\n","    References\n","    ----------\n","    Greg Ridgeway, Generalized Boosted Models: A guide to the gbm package, 2007\n","    \"\"\"\n","\n","    def __init__(self, n_classes):\n","        if n_classes != 2:\n","            raise ValueError(\"{0:s} requires 2 classes.\".format(\n","                self.__class__.__name__))\n","        # we only need to fit one tree for binary clf.\n","        super(ExponentialLoss, self).__init__(1)\n","\n","    def init_estimator(self):\n","        return ScaledLogOddsEstimator()\n","\n","    def __call__(self, y, pred, sample_weight=None):\n","        pred = pred.ravel()\n","        if sample_weight is None:\n","            return np.mean(np.exp(-(2. * y - 1.) * pred))\n","        else:\n","            return (1.0 / sample_weight.sum() *\n","                    np.sum(sample_weight * np.exp(-(2 * y - 1) * pred)))\n","\n","    def negative_gradient(self, y, pred, **kargs):\n","        y_ = -(2. * y - 1.)\n","        return y_ * np.exp(y_ * pred.ravel())\n","\n","    def _update_terminal_region(self, tree, terminal_regions, leaf, X, y,\n","                                residual, pred, sample_weight):\n","        terminal_region = np.where(terminal_regions == leaf)[0]\n","        pred = pred.take(terminal_region, axis=0)\n","        y = y.take(terminal_region, axis=0)\n","        sample_weight = sample_weight.take(terminal_region, axis=0)\n","\n","        y_ = 2. * y - 1.\n","\n","        numerator = np.sum(y_ * sample_weight * np.exp(-y_ * pred))\n","        denominator = np.sum(sample_weight * np.exp(-y_ * pred))\n","\n","        # prevents overflow and division by zero\n","        if abs(denominator) < 1e-150:\n","            tree.value[leaf, 0, 0] = 0.0\n","        else:\n","            tree.value[leaf, 0, 0] = numerator / denominator\n","\n","    def _score_to_proba(self, score):\n","        proba = np.ones((score.shape[0], 2), dtype=np.float64)\n","        proba[:, 1] = expit(2.0 * score.ravel())\n","        proba[:, 0] -= proba[:, 1]\n","        return proba\n","\n","    def _score_to_decision(self, score):\n","        return (score.ravel() >= 0.0).astype(np.int)\n","\n","\n","LOSS_FUNCTIONS = {'ls': LeastSquaresError,\n","                  'lad': LeastAbsoluteError,\n","                  'huber': HuberLossFunction,\n","                  'quantile': QuantileLossFunction,\n","                  'qc': LeastSquaresError,\n","                  'deviance': None,  # for both, multinomial and binomial\n","                  'exponential': ExponentialLoss,\n","                  }\n","\n","INIT_ESTIMATORS = {'zero': ZeroEstimator}\n","\n","\n","class VerboseReporter(object):\n","    \"\"\"Reports verbose output to stdout.\n","    If ``verbose==1`` output is printed once in a while (when iteration mod\n","    verbose_mod is zero).; if larger than 1 then output is printed for\n","    each update.\n","    \"\"\"\n","\n","    def __init__(self, verbose):\n","        self.verbose = verbose\n","\n","    def init(self, est, begin_at_stage=0):\n","        # header fields and line format str\n","        header_fields = ['Iter', 'Train Loss']\n","        verbose_fmt = ['{iter:>10d}', '{train_score:>16.4f}']\n","        # do oob?\n","        if est.subsample < 1:\n","            header_fields.append('OOB Improve')\n","            verbose_fmt.append('{oob_impr:>16.4f}')\n","        header_fields.append('Remaining Time')\n","        verbose_fmt.append('{remaining_time:>16s}')\n","\n","        # print the header line\n","        print(('%10s ' + '%16s ' *\n","               (len(header_fields) - 1)) % tuple(header_fields))\n","\n","        self.verbose_fmt = ' '.join(verbose_fmt)\n","        # plot verbose info each time i % verbose_mod == 0\n","        self.verbose_mod = 1\n","        self.start_time = time()\n","        self.begin_at_stage = begin_at_stage\n","\n","    def update(self, j, est):\n","        \"\"\"Update reporter with new iteration. \"\"\"\n","        do_oob = est.subsample < 1\n","        # we need to take into account if we fit additional estimators.\n","        i = j - self.begin_at_stage  # iteration relative to the start iter\n","        if (i + 1) % self.verbose_mod == 0:\n","            oob_impr = est.oob_improvement_[j] if do_oob else 0\n","            remaining_time = ((est.n_estimators - (j + 1)) *\n","                              (time() - self.start_time) / float(i + 1))\n","            if remaining_time > 60:\n","                remaining_time = '{0:.2f}m'.format(remaining_time / 60.0)\n","            else:\n","                remaining_time = '{0:.2f}s'.format(remaining_time)\n","            print(self.verbose_fmt.format(iter=j + 1,\n","                                          train_score=est.train_score_[j],\n","                                          oob_impr=oob_impr,\n","                                          remaining_time=remaining_time))\n","            if self.verbose == 1 and ((i + 1) // (self.verbose_mod * 10) > 0):\n","                # adjust verbose frequency (powers of 10)\n","                self.verbose_mod *= 10\n","\n","\n","class BaseGradientBoosting(six.with_metaclass(ABCMeta, BaseEnsemble)):\n","    \"\"\"Abstract base class for Gradient Boosting. \"\"\"\n","\n","    @abstractmethod\n","    def __init__(self, loss, learning_rate, n_estimators, criterion,\n","                 min_samples_split, min_samples_leaf, min_weight_fraction_leaf,\n","                 max_depth, min_impurity_decrease, min_impurity_split,\n","                 init, subsample, max_features,\n","                 random_state, alpha=0.9, verbose=0, max_leaf_nodes=None,\n","                 warm_start=False, presort='auto'):\n","\n","        self.n_estimators = n_estimators\n","        self.learning_rate = learning_rate\n","        self.loss = loss\n","        self.criterion = criterion\n","        self.min_samples_split = min_samples_split\n","        self.min_samples_leaf = min_samples_leaf\n","        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n","        self.subsample = subsample\n","        self.max_features = max_features\n","        self.max_depth = max_depth\n","        self.min_impurity_decrease = min_impurity_decrease\n","        self.min_impurity_split = min_impurity_split\n","        self.init = init\n","        self.random_state = random_state\n","        self.alpha = alpha\n","        self.verbose = verbose\n","        self.max_leaf_nodes = max_leaf_nodes\n","        self.warm_start = warm_start\n","        self.presort = presort\n","\n","    def _fit_stage(self, i, X, y, y_pred, sample_weight, sample_mask,\n","                   random_state, X_idx_sorted, X_csc=None, X_csr=None):\n","        \"\"\"Fit another stage of ``n_classes_`` trees to the boosting model. \"\"\"\n","\n","        assert sample_mask.dtype == np.bool\n","        loss = self.loss_\n","        original_y = y\n","\n","        for k in range(loss.K):\n","            if loss.is_multi_class:\n","                y = np.array(original_y == k, dtype=np.float64)\n","\n","            residual = loss.negative_gradient(y, y_pred, k=k,\n","                                              sample_weight=sample_weight)\n","\n","            # induce regression tree on residuals\n","            tree = DecisionTreeRegressor(\n","                criterion=self.criterion,\n","                splitter='best',\n","                max_depth=self.max_depth,\n","                min_samples_split=self.min_samples_split,\n","                min_samples_leaf=self.min_samples_leaf,\n","                min_weight_fraction_leaf=self.min_weight_fraction_leaf,\n","                min_impurity_decrease=self.min_impurity_decrease,\n","                min_impurity_split=self.min_impurity_split,\n","                max_features=self.max_features,\n","                max_leaf_nodes=self.max_leaf_nodes,\n","                random_state=random_state,\n","                presort=self.presort)\n","\n","            if self.subsample < 1.0:\n","                # no inplace multiplication!\n","                sample_weight = sample_weight * sample_mask.astype(np.float64)\n","\n","            if X_csc is not None:\n","                tree.fit(X_csc, residual, sample_weight=sample_weight,\n","                         check_input=False, X_idx_sorted=X_idx_sorted)\n","            else:\n","                tree.fit(X, residual, sample_weight=sample_weight,\n","                         check_input=False, X_idx_sorted=X_idx_sorted)\n","\n","            # update tree leaves\n","            if X_csr is not None:\n","                loss.update_terminal_regions(tree.tree_, X_csr, y, residual, y_pred,\n","                                             sample_weight, sample_mask,\n","                                             self.learning_rate, k=k)\n","            else:\n","                loss.update_terminal_regions(tree.tree_, X, y, residual, y_pred,\n","                                             sample_weight, sample_mask,\n","                                             self.learning_rate, k=k)\n","\n","            # add tree to ensemble\n","            self.estimators_[i, k] = tree\n","\n","        return y_pred\n","\n","    def _check_params(self):\n","        \"\"\"Check validity of parameters and raise ValueError if not valid. \"\"\"\n","        if self.n_estimators <= 0:\n","            raise ValueError(\"n_estimators must be greater than 0 but \"\n","                             \"was %r\" % self.n_estimators)\n","\n","        if self.learning_rate <= 0.0:\n","            raise ValueError(\"learning_rate must be greater than 0 but \"\n","                             \"was %r\" % self.learning_rate)\n","\n","        if (self.loss not in self._SUPPORTED_LOSS\n","                or self.loss not in LOSS_FUNCTIONS):\n","            raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n","\n","        if self.loss == 'deviance':\n","            loss_class = (MultinomialDeviance\n","                          if len(self.classes_) > 2\n","                          else BinomialDeviance)\n","        else:\n","            loss_class = LOSS_FUNCTIONS[self.loss]\n","\n","        if self.loss in ('huber', 'quantile'):\n","            self.loss_ = loss_class(self.n_classes_, self.alpha)\n","        else:\n","            self.loss_ = loss_class(self.n_classes_)\n","\n","        if not (0.0 < self.subsample <= 1.0):\n","            raise ValueError(\"subsample must be in (0,1] but \"\n","                             \"was %r\" % self.subsample)\n","\n","        if self.init is not None:\n","            if isinstance(self.init, six.string_types):\n","                if self.init not in INIT_ESTIMATORS:\n","                    raise ValueError('init=\"%s\" is not supported' % self.init)\n","            else:\n","                if (not hasattr(self.init, 'fit')\n","                        or not hasattr(self.init, 'predict')):\n","                    raise ValueError(\"init=%r must be valid BaseEstimator \"\n","                                     \"and support both fit and \"\n","                                     \"predict\" % self.init)\n","\n","        if not (0.0 < self.alpha < 1.0):\n","            raise ValueError(\"alpha must be in (0.0, 1.0) but \"\n","                             \"was %r\" % self.alpha)\n","\n","        if isinstance(self.max_features, six.string_types):\n","            if self.max_features == \"auto\":\n","                # if is_classification\n","                if self.n_classes_ > 1:\n","                    max_features = max(1, int(np.sqrt(self.n_features_)))\n","                else:\n","                    # is regression\n","                    max_features = self.n_features_\n","            elif self.max_features == \"sqrt\":\n","                max_features = max(1, int(np.sqrt(self.n_features_)))\n","            elif self.max_features == \"log2\":\n","                max_features = max(1, int(np.log2(self.n_features_)))\n","            else:\n","                raise ValueError(\"Invalid value for max_features: %r. \"\n","                                 \"Allowed string values are 'auto', 'sqrt' \"\n","                                 \"or 'log2'.\" % self.max_features)\n","        elif self.max_features is None:\n","            max_features = self.n_features_\n","        elif isinstance(self.max_features, (numbers.Integral, np.integer)):\n","            max_features = self.max_features\n","        else:  # float\n","            if 0. < self.max_features <= 1.:\n","                max_features = max(int(self.max_features *\n","                                       self.n_features_), 1)\n","            else:\n","                raise ValueError(\"max_features must be in (0, n_features]\")\n","\n","        self.max_features_ = max_features\n","\n","    def _init_state(self):\n","        \"\"\"Initialize model state and allocate model state data structures. \"\"\"\n","\n","        if self.init is None:\n","            self.init_ = self.loss_.init_estimator()\n","        elif isinstance(self.init, six.string_types):\n","            self.init_ = INIT_ESTIMATORS[self.init]()\n","        else:\n","            self.init_ = self.init\n","\n","        self.estimators_ = np.empty((self.n_estimators, self.loss_.K),\n","                                    dtype=np.object)\n","        self.train_score_ = np.zeros((self.n_estimators,), dtype=np.float64)\n","        # do oob?\n","        if self.subsample < 1.0:\n","            self.oob_improvement_ = np.zeros((self.n_estimators),\n","                                             dtype=np.float64)\n","\n","    def _clear_state(self):\n","        \"\"\"Clear the state of the gradient boosting model. \"\"\"\n","        if hasattr(self, 'estimators_'):\n","            self.estimators_ = np.empty((0, 0), dtype=np.object)\n","        if hasattr(self, 'train_score_'):\n","            del self.train_score_\n","        if hasattr(self, 'oob_improvement_'):\n","            del self.oob_improvement_\n","        if hasattr(self, 'init_'):\n","            del self.init_\n","\n","    def _resize_state(self):\n","        \"\"\"Add additional ``n_estimators`` entries to all attributes. \"\"\"\n","        # self.n_estimators is the number of additional est to fit\n","        total_n_estimators = self.n_estimators\n","        if total_n_estimators < self.estimators_.shape[0]:\n","            raise ValueError('resize with smaller n_estimators %d < %d' %\n","                             (total_n_estimators, self.estimators_[0]))\n","        self.estimators_ = self.estimators_.copy()\n","        self.estimators_.resize((total_n_estimators, self.loss_.K))\n","        self.train_score_ = self.train_score_.copy()\n","        self.train_score_.resize(total_n_estimators)\n","        if (self.subsample < 1 or hasattr(self, 'oob_improvement_')):\n","            # if do oob resize arrays or create new if not available\n","            if hasattr(self, 'oob_improvement_'):\n","                self.oob_improvement_.resize(total_n_estimators)\n","            else:\n","                self.oob_improvement_ = np.zeros((total_n_estimators,),\n","                                                 dtype=np.float64)\n","\n","    def _is_initialized(self):\n","        return len(getattr(self, 'estimators_', [])) > 0\n","\n","    def _check_initialized(self):\n","        \"\"\"Check that the estimator is initialized, raising an error if not.\"\"\"\n","        check_is_fitted(self, 'estimators_')\n","\n","    @property\n","    @deprecated(\"Attribute n_features was deprecated in version 0.19 and \"\n","                \"will be removed in 0.21.\")\n","    def n_features(self):\n","        return self.n_features_\n","\n","    def fit(self, X, y, sample_weight=None, monitor=None):\n","        \"\"\"Fit the gradient boosting model.\n","        Parameters\n","        ----------\n","        X : array-like, shape = [n_samples, n_features]\n","            Training vectors, where n_samples is the number of samples\n","            and n_features is the number of features.\n","        y : array-like, shape = [n_samples]\n","            Target values (integers in classification, real numbers in\n","            regression)\n","            For classification, labels must correspond to classes.\n","        sample_weight : array-like, shape = [n_samples] or None\n","            Sample weights. If None, then samples are equally weighted. Splits\n","            that would create child nodes with net zero or negative weight are\n","            ignored while searching for a split in each node. In the case of\n","            classification, splits are also ignored if they would result in any\n","            single class carrying a negative weight in either child node.\n","        monitor : callable, optional\n","            The monitor is called after each iteration with the current\n","            iteration, a reference to the estimator and the local variables of\n","            ``_fit_stages`` as keyword arguments ``callable(i, self,\n","            locals())``. If the callable returns ``True`` the fitting procedure\n","            is stopped. The monitor can be used for various things such as\n","            computing held-out estimates, early stopping, model introspect, and\n","            snapshoting.\n","        Returns\n","        -------\n","        self : object\n","            Returns self.\n","        \"\"\"\n","        # if not warmstart - clear the estimator state\n","        if not self.warm_start:\n","            self._clear_state()\n","\n","        # Check input\n","        X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'], dtype=DTYPE)\n","        n_samples, self.n_features_ = X.shape\n","        if sample_weight is None:\n","            sample_weight = np.ones(n_samples, dtype=np.float32)\n","        else:\n","            sample_weight = column_or_1d(sample_weight, warn=True)\n","\n","        check_consistent_length(X, y, sample_weight)\n","\n","        y = self._validate_y(y)\n","\n","        random_state = check_random_state(self.random_state)\n","        self._check_params()\n","\n","        if not self._is_initialized():\n","            # init state\n","            self._init_state()\n","\n","            # fit initial model - FIXME make sample_weight optional\n","            self.init_.fit(X, y, sample_weight)\n","\n","            # init predictions\n","            y_pred = self.init_.predict(X)\n","            begin_at_stage = 0\n","        else:\n","            # add more estimators to fitted model\n","            # invariant: warm_start = True\n","            if self.n_estimators < self.estimators_.shape[0]:\n","                raise ValueError('n_estimators=%d must be larger or equal to '\n","                                 'estimators_.shape[0]=%d when '\n","                                 'warm_start==True'\n","                                 % (self.n_estimators,\n","                                    self.estimators_.shape[0]))\n","            begin_at_stage = self.estimators_.shape[0]\n","            y_pred = self._decision_function(X)\n","            self._resize_state()\n","\n","        X_idx_sorted = None\n","        presort = self.presort\n","        # Allow presort to be 'auto', which means True if the dataset is dense,\n","        # otherwise it will be False.\n","        if presort == 'auto' and issparse(X):\n","            presort = False\n","        elif presort == 'auto':\n","            presort = True\n","\n","        if presort == True:\n","            if issparse(X):\n","                raise ValueError(\"Presorting is not supported for sparse matrices.\")\n","            else:\n","                X_idx_sorted = np.asfortranarray(np.argsort(X, axis=0),\n","                                                 dtype=np.int32)\n","\n","        # fit the boosting stages\n","        n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n","                                    begin_at_stage, monitor, X_idx_sorted)\n","        # change shape of arrays after fit (early-stopping or additional ests)\n","        if n_stages != self.estimators_.shape[0]:\n","            self.estimators_ = self.estimators_[:n_stages]\n","            self.train_score_ = self.train_score_[:n_stages]\n","            if hasattr(self, 'oob_improvement_'):\n","                self.oob_improvement_ = self.oob_improvement_[:n_stages]\n","\n","        return self\n","\n","    def _fit_stages(self, X, y, y_pred, sample_weight, random_state,\n","                    begin_at_stage=0, monitor=None, X_idx_sorted=None):\n","        \"\"\"Iteratively fits the stages.\n","        For each stage it computes the progress (OOB, train score)\n","        and delegates to ``_fit_stage``.\n","        Returns the number of stages fit; might differ from ``n_estimators``\n","        due to early stopping.\n","        \"\"\"\n","        n_samples = X.shape[0]\n","        do_oob = self.subsample < 1.0\n","        sample_mask = np.ones((n_samples,), dtype=np.bool)\n","        n_inbag = max(1, int(self.subsample * n_samples))\n","        loss_ = self.loss_\n","\n","        # Set min_weight_leaf from min_weight_fraction_leaf\n","        if self.min_weight_fraction_leaf != 0. and sample_weight is not None:\n","            min_weight_leaf = (self.min_weight_fraction_leaf *\n","                               np.sum(sample_weight))\n","        else:\n","            min_weight_leaf = 0.\n","\n","        if self.verbose:\n","            verbose_reporter = VerboseReporter(self.verbose)\n","            verbose_reporter.init(self, begin_at_stage)\n","\n","        X_csc = csc_matrix(X) if issparse(X) else None\n","        X_csr = csr_matrix(X) if issparse(X) else None\n","\n","        # perform boosting iterations\n","        i = begin_at_stage\n","        for i in range(begin_at_stage, self.n_estimators):\n","\n","            # subsampling\n","            if do_oob:\n","                sample_mask = _random_sample_mask(n_samples, n_inbag,\n","                                                  random_state)\n","                # OOB score before adding this stage\n","                old_oob_score = loss_(y[~sample_mask],\n","                                      y_pred[~sample_mask],\n","                                      sample_weight[~sample_mask])\n","\n","            # fit next stage of trees\n","            # if i == 51 :\n","            #     print (\"---51st tree before learing ............ \")\n","            #     print(y_pred)\n","            #     print (\"............ \")\n","            # if i == 50 :\n","            #     print (\"---50th tree before learing ............ \")\n","            #     print(y_pred)\n","            #     print (\"............ \")\n","            y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n","                                     sample_mask, random_state, X_idx_sorted,\n","                                     X_csc, X_csr)\n","            # if i == 51 :\n","            #     print (\"---51st tree after learing ............ \")\n","            #     print(y_pred)\n","            #     print (\"............ \")\n","            # if i == 50 :\n","            #     print (\"---50th tree after learing ............ \")\n","            #     print(y_pred)\n","            #     print (\"............ \")\n","            # track deviance (= loss)\n","            if do_oob:\n","                self.train_score_[i] = loss_(y[sample_mask],\n","                                             y_pred[sample_mask],\n","                                             sample_weight[sample_mask])\n","                self.oob_improvement_[i] = (\n","                        old_oob_score - loss_(y[~sample_mask],\n","                                              y_pred[~sample_mask],\n","                                              sample_weight[~sample_mask]))\n","            else:\n","                # no need to fancy index w/ no subsampling\n","                self.train_score_[i] = loss_(y, y_pred, sample_weight)\n","\n","            if self.verbose > 0:\n","                verbose_reporter.update(i, self)\n","            if monitor is not None:\n","                y_pred = monitor(i, self, locals())\n","                # if early_stopping:\n","                #     break\n","        return i + 1\n","\n","    def _make_estimator(self, append=True):\n","        # we don't need _make_estimator\n","        raise NotImplementedError()\n","\n","    def _init_decision_function(self, X):\n","        \"\"\"Check input and compute prediction of ``init``. \"\"\"\n","        self._check_initialized()\n","        X = self.estimators_[0, 0]._validate_X_predict(X, check_input=True)\n","        if X.shape[1] != self.n_features_:\n","            raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n","                self.n_features_, X.shape[1]))\n","        score = self.init_.predict(X).astype(np.float64)\n","        return score\n","\n","    def _decision_function(self, X):\n","        # for use in inner loop, not raveling the output in single-class case,\n","        # not doing input validation.\n","        score = self._init_decision_function(X)\n","        predict_stages(self.estimators_, X, self.learning_rate, score)\n","        return score\n","\n","    def _staged_decision_function(self, X):\n","        \"\"\"Compute decision function of ``X`` for each iteration.\n","        This method allows monitoring (i.e. determine error on testing set)\n","        after each stage.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        score : generator of array, shape = [n_samples, k]\n","            The decision function of the input samples. The order of the\n","            classes corresponds to that in the attribute `classes_`.\n","            Regression and binary classification are special cases with\n","            ``k == 1``, otherwise ``k==n_classes``.\n","        \"\"\"\n","        X = check_array(X, dtype=DTYPE, order=\"C\", accept_sparse='csr')\n","        score = self._init_decision_function(X)\n","        for i in range(self.estimators_.shape[0]):\n","            predict_stage(self.estimators_, i, X, self.learning_rate, score)\n","            yield score.copy()\n","\n","    @property\n","    def feature_importances_(self):\n","        \"\"\"Return the feature importances (the higher, the more important the\n","           feature).\n","        Returns\n","        -------\n","        feature_importances_ : array, shape = [n_features]\n","        \"\"\"\n","        self._check_initialized()\n","\n","        total_sum = np.zeros((self.n_features_,), dtype=np.float64)\n","        for stage in self.estimators_:\n","            stage_sum = sum(tree.feature_importances_\n","                            for tree in stage) / len(stage)\n","            total_sum += stage_sum\n","\n","        importances = total_sum / len(self.estimators_)\n","        return importances\n","\n","    def _validate_y(self, y):\n","        self.n_classes_ = 1\n","        if y.dtype.kind == 'O':\n","            y = y.astype(np.float64)\n","        # Default implementation\n","        return y\n","\n","    def apply(self, X):\n","        \"\"\"Apply trees in the ensemble to X, return leaf indices.\n","        .. versionadded:: 0.17\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, its dtype will be converted to\n","            ``dtype=np.float32``. If a sparse matrix is provided, it will\n","            be converted to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        X_leaves : array_like, shape = [n_samples, n_estimators, n_classes]\n","            For each datapoint x in X and for each tree in the ensemble,\n","            return the index of the leaf x ends up in each estimator.\n","            In the case of binary classification n_classes is 1.\n","        \"\"\"\n","\n","        self._check_initialized()\n","        X = self.estimators_[0, 0]._validate_X_predict(X, check_input=True)\n","\n","        # n_classes will be equal to 1 in the binary classification or the\n","        # regression case.\n","        n_estimators, n_classes = self.estimators_.shape\n","        leaves = np.zeros((X.shape[0], n_estimators, n_classes))\n","\n","        for i in range(n_estimators):\n","            for j in range(n_classes):\n","                estimator = self.estimators_[i, j]\n","                leaves[:, i, j] = estimator.apply(X, check_input=False)\n","\n","        return leaves\n","\n","\n","class GradientBoostingClassifier(BaseGradientBoosting, ClassifierMixin):\n","    \"\"\"Gradient Boosting for classification.\n","    GB builds an additive model in a\n","    forward stage-wise fashion; it allows for the optimization of\n","    arbitrary differentiable loss functions. In each stage ``n_classes_``\n","    regression trees are fit on the negative gradient of the\n","    binomial or multinomial deviance loss function. Binary classification\n","    is a special case where only a single regression tree is induced.\n","    Read more in the :ref:`User Guide <gradient_boosting>`.\n","    Parameters\n","    ----------\n","    loss : {'deviance', 'exponential'}, optional (default='deviance')\n","        loss function to be optimized. 'deviance' refers to\n","        deviance (= logistic regression) for classification\n","        with probabilistic outputs. For loss 'exponential' gradient\n","        boosting recovers the AdaBoost algorithm.\n","    learning_rate : float, optional (default=0.1)\n","        learning rate shrinks the contribution of each tree by `learning_rate`.\n","        There is a trade-off between learning_rate and n_estimators.\n","    n_estimators : int (default=100)\n","        The number of boosting stages to perform. Gradient boosting\n","        is fairly robust to over-fitting so a large number usually\n","        results in better performance.\n","    max_depth : integer, optional (default=3)\n","        maximum depth of the individual regression estimators. The maximum\n","        depth limits the number of nodes in the tree. Tune this parameter\n","        for best performance; the best value depends on the interaction\n","        of the input variables.\n","    criterion : string, optional (default=\"friedman_mse\")\n","        The function to measure the quality of a split. Supported criteria\n","        are \"friedman_mse\" for the mean squared error with improvement\n","        score by Friedman, \"mse\" for mean squared error, and \"mae\" for\n","        the mean absolute error. The default value of \"friedman_mse\" is\n","        generally the best as it can provide a better approximation in\n","        some cases.\n","        .. versionadded:: 0.18\n","    min_samples_split : int, float, optional (default=2)\n","        The minimum number of samples required to split an internal node:\n","        - If int, then consider `min_samples_split` as the minimum number.\n","        - If float, then `min_samples_split` is a percentage and\n","          `ceil(min_samples_split * n_samples)` are the minimum\n","          number of samples for each split.\n","        .. versionchanged:: 0.18\n","           Added float values for percentages.\n","    min_samples_leaf : int, float, optional (default=1)\n","        The minimum number of samples required to be at a leaf node:\n","        - If int, then consider `min_samples_leaf` as the minimum number.\n","        - If float, then `min_samples_leaf` is a percentage and\n","          `ceil(min_samples_leaf * n_samples)` are the minimum\n","          number of samples for each node.\n","        .. versionchanged:: 0.18\n","           Added float values for percentages.\n","    min_weight_fraction_leaf : float, optional (default=0.)\n","        The minimum weighted fraction of the sum total of weights (of all\n","        the input samples) required to be at a leaf node. Samples have\n","        equal weight when sample_weight is not provided.\n","    subsample : float, optional (default=1.0)\n","        The fraction of samples to be used for fitting the individual base\n","        learners. If smaller than 1.0 this results in Stochastic Gradient\n","        Boosting. `subsample` interacts with the parameter `n_estimators`.\n","        Choosing `subsample < 1.0` leads to a reduction of variance\n","        and an increase in bias.\n","    max_features : int, float, string or None, optional (default=None)\n","        The number of features to consider when looking for the best split:\n","        - If int, then consider `max_features` features at each split.\n","        - If float, then `max_features` is a percentage and\n","          `int(max_features * n_features)` features are considered at each\n","          split.\n","        - If \"auto\", then `max_features=sqrt(n_features)`.\n","        - If \"sqrt\", then `max_features=sqrt(n_features)`.\n","        - If \"log2\", then `max_features=log2(n_features)`.\n","        - If None, then `max_features=n_features`.\n","        Choosing `max_features < n_features` leads to a reduction of variance\n","        and an increase in bias.\n","        Note: the search for a split does not stop until at least one\n","        valid partition of the node samples is found, even if it requires to\n","        effectively inspect more than ``max_features`` features.\n","    max_leaf_nodes : int or None, optional (default=None)\n","        Grow trees with ``max_leaf_nodes`` in best-first fashion.\n","        Best nodes are defined as relative reduction in impurity.\n","        If None then unlimited number of leaf nodes.\n","    min_impurity_split : float,\n","        Threshold for early stopping in tree growth. A node will split\n","        if its impurity is above the threshold, otherwise it is a leaf.\n","        .. deprecated:: 0.19\n","           ``min_impurity_split`` has been deprecated in favor of\n","           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.\n","           Use ``min_impurity_decrease`` instead.\n","    min_impurity_decrease : float, optional (default=0.)\n","        A node will be split if this split induces a decrease of the impurity\n","        greater than or equal to this value.\n","        The weighted impurity decrease equation is the following::\n","            N_t / N * (impurity - N_t_R / N_t * right_impurity\n","                                - N_t_L / N_t * left_impurity)\n","        where ``N`` is the total number of samples, ``N_t`` is the number of\n","        samples at the current node, ``N_t_L`` is the number of samples in the\n","        left child, and ``N_t_R`` is the number of samples in the right child.\n","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n","        if ``sample_weight`` is passed.\n","        .. versionadded:: 0.19\n","    init : BaseEstimator, None, optional (default=None)\n","        An estimator object that is used to compute the initial\n","        predictions. ``init`` has to provide ``fit`` and ``predict``.\n","        If None it uses ``loss.init_estimator``.\n","    verbose : int, default: 0\n","        Enable verbose output. If 1 then it prints progress and performance\n","        once in a while (the more trees the lower the frequency). If greater\n","        than 1 then it prints progress and performance for every tree.\n","    warm_start : bool, default: False\n","        When set to ``True``, reuse the solution of the previous call to fit\n","        and add more estimators to the ensemble, otherwise, just erase the\n","        previous solution.\n","    random_state : int, RandomState instance or None, optional (default=None)\n","        If int, random_state is the seed used by the random number generator;\n","        If RandomState instance, random_state is the random number generator;\n","        If None, the random number generator is the RandomState instance used\n","        by `np.random`.\n","    presort : bool or 'auto', optional (default='auto')\n","        Whether to presort the data to speed up the finding of best splits in\n","        fitting. Auto mode by default will use presorting on dense data and\n","        default to normal sorting on sparse data. Setting presort to true on\n","        sparse data will raise an error.\n","        .. versionadded:: 0.17\n","           *presort* parameter.\n","    Attributes\n","    ----------\n","    feature_importances_ : array, shape = [n_features]\n","        The feature importances (the higher, the more important the feature).\n","    oob_improvement_ : array, shape = [n_estimators]\n","        The improvement in loss (= deviance) on the out-of-bag samples\n","        relative to the previous iteration.\n","        ``oob_improvement_[0]`` is the improvement in\n","        loss of the first stage over the ``init`` estimator.\n","    train_score_ : array, shape = [n_estimators]\n","        The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n","        model at iteration ``i`` on the in-bag sample.\n","        If ``subsample == 1`` this is the deviance on the training data.\n","    loss_ : LossFunction\n","        The concrete ``LossFunction`` object.\n","    init : BaseEstimator\n","        The estimator that provides the initial predictions.\n","        Set via the ``init`` argument or ``loss.init_estimator``.\n","    estimators_ : ndarray of DecisionTreeRegressor, shape = [n_estimators, ``loss_.K``]\n","        The collection of fitted sub-estimators. ``loss_.K`` is 1 for binary\n","        classification, otherwise n_classes.\n","    Notes\n","    -----\n","    The features are always randomly permuted at each split. Therefore,\n","    the best found split may vary, even with the same training data and\n","    ``max_features=n_features``, if the improvement of the criterion is\n","    identical for several splits enumerated during the search of the best\n","    split. To obtain a deterministic behaviour during fitting,\n","    ``random_state`` has to be fixed.\n","    See also\n","    --------\n","    sklearn.tree.DecisionTreeClassifier, RandomForestClassifier\n","    AdaBoostClassifier\n","    References\n","    ----------\n","    J. Friedman, Greedy Function Approximation: A Gradient Boosting\n","    Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n","    J. Friedman, Stochastic Gradient Boosting, 1999\n","    T. Hastie, R. Tibshirani and J. Friedman.\n","    Elements of Statistical Learning Ed. 2, Springer, 2009.\n","    \"\"\"\n","\n","    _SUPPORTED_LOSS = ('deviance', 'exponential')\n","\n","    def __init__(self, loss='deviance', learning_rate=0.1, n_estimators=100,\n","                 subsample=1.0, criterion='friedman_mse', min_samples_split=2,\n","                 min_samples_leaf=1, min_weight_fraction_leaf=0.,\n","                 max_depth=3, min_impurity_decrease=0.,\n","                 min_impurity_split=None, init=None,\n","                 random_state=None, max_features=None, verbose=0,\n","                 max_leaf_nodes=None, warm_start=False,\n","                 presort='auto'):\n","\n","        super(GradientBoostingClassifier, self).__init__(\n","            loss=loss, learning_rate=learning_rate, n_estimators=n_estimators,\n","            criterion=criterion, min_samples_split=min_samples_split,\n","            min_samples_leaf=min_samples_leaf,\n","            min_weight_fraction_leaf=min_weight_fraction_leaf,\n","            max_depth=max_depth, init=init, subsample=subsample,\n","            max_features=max_features,\n","            random_state=random_state, verbose=verbose,\n","            max_leaf_nodes=max_leaf_nodes,\n","            min_impurity_decrease=min_impurity_decrease,\n","            min_impurity_split=min_impurity_split,\n","            warm_start=warm_start,\n","            presort=presort)\n","\n","    def _validate_y(self, y):\n","        check_classification_targets(y)\n","        self.classes_, y = np.unique(y, return_inverse=True)\n","        self.n_classes_ = len(self.classes_)\n","        return y\n","\n","    def decision_function(self, X):\n","        \"\"\"Compute the decision function of ``X``.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        score : array, shape = [n_samples, n_classes] or [n_samples]\n","            The decision function of the input samples. The order of the\n","            classes corresponds to that in the attribute `classes_`.\n","            Regression and binary classification produce an array of shape\n","            [n_samples].\n","        \"\"\"\n","        X = check_array(X, dtype=DTYPE, order=\"C\", accept_sparse='csr')\n","        score = self._decision_function(X)\n","        if score.shape[1] == 1:\n","            return score.ravel()\n","        return score\n","\n","    def staged_decision_function(self, X):\n","        \"\"\"Compute decision function of ``X`` for each iteration.\n","        This method allows monitoring (i.e. determine error on testing set)\n","        after each stage.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        score : generator of array, shape = [n_samples, k]\n","            The decision function of the input samples. The order of the\n","            classes corresponds to that in the attribute `classes_`.\n","            Regression and binary classification are special cases with\n","            ``k == 1``, otherwise ``k==n_classes``.\n","        \"\"\"\n","        for dec in self._staged_decision_function(X):\n","            # no yield from in Python2.X\n","            yield dec\n","\n","    def predict(self, X):\n","        \"\"\"Predict class for X.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        y : array of shape = [n_samples]\n","            The predicted values.\n","        \"\"\"\n","        score = self.decision_function(X)\n","        decisions = self.loss_._score_to_decision(score)\n","        return self.classes_.take(decisions, axis=0)\n","\n","    def staged_predict(self, X):\n","        \"\"\"Predict class at each stage for X.\n","        This method allows monitoring (i.e. determine error on testing set)\n","        after each stage.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        y : generator of array of shape = [n_samples]\n","            The predicted value of the input samples.\n","        \"\"\"\n","        for score in self._staged_decision_function(X):\n","            decisions = self.loss_._score_to_decision(score)\n","            yield self.classes_.take(decisions, axis=0)\n","\n","    def predict_proba(self, X):\n","        \"\"\"Predict class probabilities for X.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Raises\n","        ------\n","        AttributeError\n","            If the ``loss`` does not support probabilities.\n","        Returns\n","        -------\n","        p : array of shape = [n_samples]\n","            The class probabilities of the input samples. The order of the\n","            classes corresponds to that in the attribute `classes_`.\n","        \"\"\"\n","        score = self.decision_function(X)\n","        try:\n","            return self.loss_._score_to_proba(score)\n","        except NotFittedError:\n","            raise\n","        except AttributeError:\n","            raise AttributeError('loss=%r does not support predict_proba' %\n","                                 self.loss)\n","\n","    def predict_log_proba(self, X):\n","        \"\"\"Predict class log-probabilities for X.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Raises\n","        ------\n","        AttributeError\n","            If the ``loss`` does not support probabilities.\n","        Returns\n","        -------\n","        p : array of shape = [n_samples]\n","            The class log-probabilities of the input samples. The order of the\n","            classes corresponds to that in the attribute `classes_`.\n","        \"\"\"\n","        proba = self.predict_proba(X)\n","        return np.log(proba)\n","\n","    def staged_predict_proba(self, X):\n","        \"\"\"Predict class probabilities at each stage for X.\n","        This method allows monitoring (i.e. determine error on testing set)\n","        after each stage.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        y : generator of array of shape = [n_samples]\n","            The predicted value of the input samples.\n","        \"\"\"\n","        try:\n","            for score in self._staged_decision_function(X):\n","                yield self.loss_._score_to_proba(score)\n","        except NotFittedError:\n","            raise\n","        except AttributeError:\n","            raise AttributeError('loss=%r does not support predict_proba' %\n","                                 self.loss)\n","\n","\n","class GradientBoostingRegressor(BaseGradientBoosting, RegressorMixin):\n","    \"\"\"Gradient Boosting for regression.\n","    GB builds an additive model in a forward stage-wise fashion;\n","    it allows for the optimization of arbitrary differentiable loss functions.\n","    In each stage a regression tree is fit on the negative gradient of the\n","    given loss function.\n","    Read more in the :ref:`User Guide <gradient_boosting>`.\n","    Parameters\n","    ----------\n","    loss : {'ls', 'lad', 'huber', 'quantile'}, optional (default='ls')\n","        loss function to be optimized. 'ls' refers to least squares\n","        regression. 'lad' (least absolute deviation) is a highly robust\n","        loss function solely based on order information of the input\n","        variables. 'huber' is a combination of the two. 'quantile'\n","        allows quantile regression (use `alpha` to specify the quantile).\n","    learning_rate : float, optional (default=0.1)\n","        learning rate shrinks the contribution of each tree by `learning_rate`.\n","        There is a trade-off between learning_rate and n_estimators.\n","    n_estimators : int (default=100)\n","        The number of boosting stages to perform. Gradient boosting\n","        is fairly robust to over-fitting so a large number usually\n","        results in better performance.\n","    max_depth : integer, optional (default=3)\n","        maximum depth of the individual regression estimators. The maximum\n","        depth limits the number of nodes in the tree. Tune this parameter\n","        for best performance; the best value depends on the interaction\n","        of the input variables.\n","    criterion : string, optional (default=\"friedman_mse\")\n","        The function to measure the quality of a split. Supported criteria\n","        are \"friedman_mse\" for the mean squared error with improvement\n","        score by Friedman, \"mse\" for mean squared error, and \"mae\" for\n","        the mean absolute error. The default value of \"friedman_mse\" is\n","        generally the best as it can provide a better approximation in\n","        some cases.\n","        .. versionadded:: 0.18\n","    min_samples_split : int, float, optional (default=2)\n","        The minimum number of samples required to split an internal node:\n","        - If int, then consider `min_samples_split` as the minimum number.\n","        - If float, then `min_samples_split` is a percentage and\n","          `ceil(min_samples_split * n_samples)` are the minimum\n","          number of samples for each split.\n","        .. versionchanged:: 0.18\n","           Added float values for percentages.\n","    min_samples_leaf : int, float, optional (default=1)\n","        The minimum number of samples required to be at a leaf node:\n","        - If int, then consider `min_samples_leaf` as the minimum number.\n","        - If float, then `min_samples_leaf` is a percentage and\n","          `ceil(min_samples_leaf * n_samples)` are the minimum\n","          number of samples for each node.\n","        .. versionchanged:: 0.18\n","           Added float values for percentages.\n","    min_weight_fraction_leaf : float, optional (default=0.)\n","        The minimum weighted fraction of the sum total of weights (of all\n","        the input samples) required to be at a leaf node. Samples have\n","        equal weight when sample_weight is not provided.\n","    subsample : float, optional (default=1.0)\n","        The fraction of samples to be used for fitting the individual base\n","        learners. If smaller than 1.0 this results in Stochastic Gradient\n","        Boosting. `subsample` interacts with the parameter `n_estimators`.\n","        Choosing `subsample < 1.0` leads to a reduction of variance\n","        and an increase in bias.\n","    max_features : int, float, string or None, optional (default=None)\n","        The number of features to consider when looking for the best split:\n","        - If int, then consider `max_features` features at each split.\n","        - If float, then `max_features` is a percentage and\n","          `int(max_features * n_features)` features are considered at each\n","          split.\n","        - If \"auto\", then `max_features=n_features`.\n","        - If \"sqrt\", then `max_features=sqrt(n_features)`.\n","        - If \"log2\", then `max_features=log2(n_features)`.\n","        - If None, then `max_features=n_features`.\n","        Choosing `max_features < n_features` leads to a reduction of variance\n","        and an increase in bias.\n","        Note: the search for a split does not stop until at least one\n","        valid partition of the node samples is found, even if it requires to\n","        effectively inspect more than ``max_features`` features.\n","    max_leaf_nodes : int or None, optional (default=None)\n","        Grow trees with ``max_leaf_nodes`` in best-first fashion.\n","        Best nodes are defined as relative reduction in impurity.\n","        If None then unlimited number of leaf nodes.\n","    min_impurity_split : float,\n","        Threshold for early stopping in tree growth. A node will split\n","        if its impurity is above the threshold, otherwise it is a leaf.\n","        .. deprecated:: 0.19\n","           ``min_impurity_split`` has been deprecated in favor of\n","           ``min_impurity_decrease`` in 0.19 and will be removed in 0.21.\n","           Use ``min_impurity_decrease`` instead.\n","    min_impurity_decrease : float, optional (default=0.)\n","        A node will be split if this split induces a decrease of the impurity\n","        greater than or equal to this value.\n","        The weighted impurity decrease equation is the following::\n","            N_t / N * (impurity - N_t_R / N_t * right_impurity\n","                                - N_t_L / N_t * left_impurity)\n","        where ``N`` is the total number of samples, ``N_t`` is the number of\n","        samples at the current node, ``N_t_L`` is the number of samples in the\n","        left child, and ``N_t_R`` is the number of samples in the right child.\n","        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n","        if ``sample_weight`` is passed.\n","        .. versionadded:: 0.19\n","    alpha : float (default=0.9)\n","        The alpha-quantile of the huber loss function and the quantile\n","        loss function. Only if ``loss='huber'`` or ``loss='quantile'``.\n","    init : BaseEstimator, None, optional (default=None)\n","        An estimator object that is used to compute the initial\n","        predictions. ``init`` has to provide ``fit`` and ``predict``.\n","        If None it uses ``loss.init_estimator``.\n","    verbose : int, default: 0\n","        Enable verbose output. If 1 then it prints progress and performance\n","        once in a while (the more trees the lower the frequency). If greater\n","        than 1 then it prints progress and performance for every tree.\n","    warm_start : bool, default: False\n","        When set to ``True``, reuse the solution of the previous call to fit\n","        and add more estimators to the ensemble, otherwise, just erase the\n","        previous solution.\n","    random_state : int, RandomState instance or None, optional (default=None)\n","        If int, random_state is the seed used by the random number generator;\n","        If RandomState instance, random_state is the random number generator;\n","        If None, the random number generator is the RandomState instance used\n","        by `np.random`.\n","    presort : bool or 'auto', optional (default='auto')\n","        Whether to presort the data to speed up the finding of best splits in\n","        fitting. Auto mode by default will use presorting on dense data and\n","        default to normal sorting on sparse data. Setting presort to true on\n","        sparse data will raise an error.\n","        .. versionadded:: 0.17\n","           optional parameter *presort*.\n","    Attributes\n","    ----------\n","    feature_importances_ : array, shape = [n_features]\n","        The feature importances (the higher, the more important the feature).\n","    oob_improvement_ : array, shape = [n_estimators]\n","        The improvement in loss (= deviance) on the out-of-bag samples\n","        relative to the previous iteration.\n","        ``oob_improvement_[0]`` is the improvement in\n","        loss of the first stage over the ``init`` estimator.\n","    train_score_ : array, shape = [n_estimators]\n","        The i-th score ``train_score_[i]`` is the deviance (= loss) of the\n","        model at iteration ``i`` on the in-bag sample.\n","        If ``subsample == 1`` this is the deviance on the training data.\n","    loss_ : LossFunction\n","        The concrete ``LossFunction`` object.\n","    init : BaseEstimator\n","        The estimator that provides the initial predictions.\n","        Set via the ``init`` argument or ``loss.init_estimator``.\n","    estimators_ : ndarray of DecisionTreeRegressor, shape = [n_estimators, 1]\n","        The collection of fitted sub-estimators.\n","    Notes\n","    -----\n","    The features are always randomly permuted at each split. Therefore,\n","    the best found split may vary, even with the same training data and\n","    ``max_features=n_features``, if the improvement of the criterion is\n","    identical for several splits enumerated during the search of the best\n","    split. To obtain a deterministic behaviour during fitting,\n","    ``random_state`` has to be fixed.\n","    See also\n","    --------\n","    DecisionTreeRegressor, RandomForestRegressor\n","    References\n","    ----------\n","    J. Friedman, Greedy Function Approximation: A Gradient Boosting\n","    Machine, The Annals of Statistics, Vol. 29, No. 5, 2001.\n","    J. Friedman, Stochastic Gradient Boosting, 1999\n","    T. Hastie, R. Tibshirani and J. Friedman.\n","    Elements of Statistical Learning Ed. 2, Springer, 2009.\n","    \"\"\"\n","\n","    _SUPPORTED_LOSS = ('ls', 'lad', 'huber', 'quantile', 'qc')\n","\n","    def __init__(self, loss='ls', learning_rate=0.1, n_estimators=100,\n","                 subsample=1.0, criterion='friedman_mse', min_samples_split=2,\n","                 min_samples_leaf=1, min_weight_fraction_leaf=0.,\n","                 max_depth=3, min_impurity_decrease=0.,\n","                 min_impurity_split=None, init=None, random_state=None,\n","                 max_features=None, alpha=0.9, verbose=0, max_leaf_nodes=None,\n","                 warm_start=False, presort='auto'):\n","        super(GradientBoostingRegressor, self).__init__(\n","            loss=loss, learning_rate=learning_rate, n_estimators=n_estimators,\n","            criterion=criterion, min_samples_split=min_samples_split,\n","            min_samples_leaf=min_samples_leaf,\n","            min_weight_fraction_leaf=min_weight_fraction_leaf,\n","            max_depth=max_depth, init=init, subsample=subsample,\n","            max_features=max_features,\n","            min_impurity_decrease=min_impurity_decrease,\n","            min_impurity_split=min_impurity_split,\n","            random_state=random_state, alpha=alpha, verbose=verbose,\n","            max_leaf_nodes=max_leaf_nodes, warm_start=warm_start,\n","            presort=presort)\n","\n","    def predict(self, X):\n","        \"\"\"Predict regression target for X.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        y : array of shape = [n_samples]\n","            The predicted values.\n","        \"\"\"\n","        X = check_array(X, dtype=DTYPE, order=\"C\", accept_sparse='csr')\n","        return self._decision_function(X).ravel()\n","\n","    def staged_predict(self, X):\n","        \"\"\"Predict regression target at each stage for X.\n","        This method allows monitoring (i.e. determine error on testing set)\n","        after each stage.\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, it will be converted to\n","            ``dtype=np.float32`` and if a sparse matrix is provided\n","            to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        y : generator of array of shape = [n_samples]\n","            The predicted value of the input samples.\n","        \"\"\"\n","        for y in self._staged_decision_function(X):\n","            yield y.ravel()\n","\n","    def apply(self, X):\n","        \"\"\"Apply trees in the ensemble to X, return leaf indices.\n","        .. versionadded:: 0.17\n","        Parameters\n","        ----------\n","        X : array-like or sparse matrix, shape = [n_samples, n_features]\n","            The input samples. Internally, its dtype will be converted to\n","            ``dtype=np.float32``. If a sparse matrix is provided, it will\n","            be converted to a sparse ``csr_matrix``.\n","        Returns\n","        -------\n","        X_leaves : array_like, shape = [n_samples, n_estimators]\n","            For each datapoint x in X and for each tree in the ensemble,\n","            return the index of the leaf x ends up in each estimator.\n","        \"\"\"\n","\n","        leaves = super(GradientBoostingRegressor, self).apply(X)\n","        leaves = leaves.reshape(X.shape[0], self.estimators_.shape[0])\n","        return leaves"],"execution_count":60,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5zorYyt1RoCQ","colab_type":"text"},"source":["###KiGB"]},{"cell_type":"code","metadata":{"id":"Z-X-lY7DRsCF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590687804,"user_tz":-180,"elapsed":1105,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["from sklearn.base import RegressorMixin\n","import logging\n","\n","\n","class SKiGB(GradientBoostingRegressor, RegressorMixin):\n","\n","    def _make_estimator(self, append=True):\n","        pass\n","\n","    def __init__(self, criterion='mse',\n","                 n_estimators=35,\n","                 max_depth=10,\n","                 learning_rate=0.1,\n","                 loss='ls',\n","                 random_state=random_state,\n","                 advice=None,\n","                 lamda=1,\n","                 epsilon=0,\n","                 init=None, **kwargs):\n","        self.criterion = criterion\n","        self.n_estimators = n_estimators\n","        self.max_depth = max_depth\n","        self.learning_rate = learning_rate\n","        self.loss = loss\n","        self.random_state = random_state\n","        self.advice = advice\n","        self.epsilon = epsilon\n","        self.lamda = lamda\n","        self.init = init\n","        self.kigb = None\n","\n","    def fit(self, X, y, sample_weight=None, monitor=None):\n","        logging.debug(\"Starting KiGB fit\")\n","        utils.advice = self.advice\n","        utils.epsilon = self.epsilon\n","        utils.lamda = self.lamda\n","        utils.trees_modified = 0\n","        utils.node_violations = 0\n","        if self.loss == 'deviance':\n","            clf = GradientBoostingClassifier(criterion=self.criterion, n_estimators=self.n_estimators,\n","                                             max_depth=self.max_depth,\n","                                             warm_start=True,\n","                                             learning_rate=self.learning_rate,\n","                                             loss=self.loss,\n","                                             random_state=self.random_state, init=self.init)\n","        else:\n","            clf = GradientBoostingRegressor(criterion=self.criterion, n_estimators=self.n_estimators,\n","                                            max_depth=self.max_depth,\n","                                            warm_start=True,\n","                                            learning_rate=self.learning_rate,\n","                                            loss=self.loss,\n","                                            random_state=self.random_state, init=self.init)\n","        clf.fit(X, y, monitor=utils.kigb_penalty_update)\n","        self.kigb = clf\n","        if utils.trees_modified ==0:\n","            logging.info(\"No Trees Updated\")\n","        logging.debug(\"Trees Modified: \" + str(utils.trees_modified))\n","        logging.debug(\"Nodes Violation: \" + str(utils.node_violations))\n","        logging.debug(\"finished KiGB fit\")\n","        return self\n","\n","    def predict(self, X, y=None):\n","        return self.kigb.predict(X)"],"execution_count":61,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FTA1Pm9eR-W4","colab_type":"text"},"source":["###Example"]},{"cell_type":"code","metadata":{"id":"oDE8xT51SCNr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590689840,"user_tz":-180,"elapsed":1307,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def kigb(df_name):\n","  df = data_dic[df_name]\n","  target = pd.DataFrame(df[df.columns[-1]])\n","  train = df.drop([df.columns[-1]], axis=1)\n","  print(df)\n","  data = np.array(df)\n","  total_num_of_features = len(data[0])-1\n","  feature_per_tree = int(math.sqrt(total_num_of_features))\n","  num_feature = feature_per_tree * feature_per_tree\n","\n","  train_arr = np.array(train).tolist()\n","  target_arr = np.array(target).tolist()\n","  classes = np.unique(target_arr)\n","  i=0\n","  start_time = time()\n","  \n","  kf = KFold(n_splits=10, random_state=random_state, shuffle=True).split(train_arr,target_arr)\n","  \n","\n","  for train_idx, test_idx in kf:\n","    i+=1\n","    train_x=[train_arr[ii] for ii in train_idx]\n","    test_x=[train_arr[ii] for ii in test_idx]\n","    train_y=[target_arr[ii] for ii in train_idx]\n","    test_y=[target_arr[ii] for ii in test_idx]  \n"," \n","\n","    gb = GradientBoostingClassifier(verbose=verbose)\n","    gb.fit(train_x, train_y)\n","    end_time = time()\n","    inference_start_time = time()\n","\n","    pred_y = gb.predict(test_x)\n","\n","    inference_end_time = time()\n","\n","    inference_time = (1000/len(pred_y))*(inference_end_time-inference_start_time)\n","    \n","\n","\n","    acc, tpr, fpr, precision, auc, prc = get_metrics(test_y, pred_y, classes)\n","\n","    \n","\n","    train_time = end_time - start_time\n","\n","    add_result(df_name,'Gradient Boosting', i, gb.get_params(), acc, tpr, fpr, precision, auc, prc, train_time, inference_time)\n"],"execution_count":62,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_kH8iCHUKnQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597598290064,"user_tz":-180,"elapsed":30411,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"b7d96224-26cd-4c03-f6f7-201ebf8e5f56"},"source":["j=0\n","for dn in data_dic:\n","  j+=1  \n","  kigb(dn)\n","  if j==10:\n","    break"],"execution_count":222,"outputs":[{"output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","         6           0.9511            0.09s\n","         7           0.8983            0.09s\n","         8           0.8542            0.10s\n","         9           0.8206            0.10s\n","        10           0.7855            0.10s\n","        11           0.7490            0.10s\n","        12           0.7201            0.10s\n","        13           0.6921            0.10s\n","        14           0.6622            0.10s\n","        15           0.6394            0.09s\n","        16           0.6138            0.09s\n","        17           0.5912            0.09s\n","        18           0.5664            0.09s\n","        19           0.5472            0.09s\n","        20           0.5314            0.09s\n","        21           0.5127            0.09s\n","        22           0.4949            0.08s\n","        23           0.4809            0.08s\n","        24           0.4642            0.08s\n","        25           0.4488            0.08s\n","        26           0.4347            0.08s\n","        27           0.4218            0.08s\n","        28           0.4097            0.08s\n","        29           0.3994            0.07s\n","        30           0.3893            0.07s\n","        31           0.3796            0.07s\n","        32           0.3670            0.07s\n","        33           0.3549            0.07s\n","        34           0.3460            0.07s\n","        35           0.3359            0.07s\n","        36           0.3268            0.07s\n","        37           0.3182            0.07s\n","        38           0.3085            0.06s\n","        39           0.3018            0.06s\n","        40           0.2939            0.06s\n","        41           0.2844            0.06s\n","        42           0.2792            0.06s\n","        43           0.2710            0.06s\n","        44           0.2641            0.06s\n","        45           0.2572            0.06s\n","        46           0.2496            0.06s\n","        47           0.2436            0.05s\n","        48           0.2385            0.05s\n","        49           0.2324            0.05s\n","        50           0.2258            0.05s\n","        51           0.2211            0.05s\n","        52           0.2163            0.05s\n","        53           0.2105            0.05s\n","        54           0.2072            0.05s\n","        55           0.2027            0.05s\n","        56           0.1978            0.04s\n","        57           0.1938            0.04s\n","        58           0.1891            0.04s\n","        59           0.1844            0.04s\n","        60           0.1795            0.04s\n","        61           0.1759            0.04s\n","        62           0.1714            0.04s\n","        63           0.1688            0.04s\n","        64           0.1645            0.04s\n","        65           0.1605            0.04s\n","        66           0.1571            0.03s\n","        67           0.1534            0.03s\n","        68           0.1505            0.03s\n","        69           0.1462            0.03s\n","        70           0.1427            0.03s\n","        71           0.1403            0.03s\n","        72           0.1367            0.03s\n","        73           0.1341            0.03s\n","        74           0.1317            0.03s\n","        75           0.1284            0.02s\n","        76           0.1259            0.02s\n","        77           0.1238            0.02s\n","        78           0.1209            0.02s\n","        79           0.1187            0.02s\n","        80           0.1166            0.02s\n","        81           0.1140            0.02s\n","        82           0.1109            0.02s\n","        83           0.1090            0.02s\n","        84           0.1075            0.02s\n","        85           0.1053            0.01s\n","        86           0.1038            0.01s\n","        87           0.1023            0.01s\n","        88           0.1002            0.01s\n","        89           0.0986            0.01s\n","        90           0.0962            0.01s\n","        91           0.0938            0.01s\n","        92           0.0920            0.01s\n","        93           0.0905            0.01s\n","        94           0.0892            0.01s\n","        95           0.0877            0.00s\n","        96           0.0861            0.00s\n","        97           0.0842            0.00s\n","        98           0.0829            0.00s\n","        99           0.0812            0.00s\n","       100           0.0807            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2709            0.09s\n","         2           1.1767            0.09s\n","         3           1.0985            0.09s\n","         4           1.0413            0.09s\n","         5           0.9863            0.09s\n","         6           0.9334            0.10s\n","         7           0.8820            0.09s\n","         8           0.8409            0.09s\n","         9           0.7998            0.09s\n","        10           0.7614            0.09s\n","        11           0.7259            0.09s\n","        12           0.6972            0.09s\n","        13           0.6640            0.09s\n","        14           0.6388            0.09s\n","        15           0.6124            0.08s\n","        16           0.5894            0.08s\n","        17           0.5697            0.08s\n","        18           0.5466            0.08s\n","        19           0.5269            0.08s\n","        20           0.5042            0.08s\n","        21           0.4864            0.08s\n","        22           0.4693            0.08s\n","        23           0.4549            0.08s\n","        24           0.4413            0.07s\n","        25           0.4285            0.07s\n","        26           0.4162            0.07s\n","        27           0.4057            0.07s\n","        28           0.3950            0.07s\n","        29           0.3804            0.07s\n","        30           0.3683            0.07s\n","        31           0.3577            0.07s\n","        32           0.3444            0.07s\n","        33           0.3349            0.07s\n","        34           0.3240            0.06s\n","        35           0.3153            0.06s\n","        36           0.3050            0.06s\n","        37           0.2973            0.06s\n","        38           0.2919            0.06s\n","        39           0.2834            0.06s\n","        40           0.2752            0.06s\n","        41           0.2669            0.06s\n","        42           0.2604            0.06s\n","        43           0.2538            0.06s\n","        44           0.2485            0.06s\n","        45           0.2399            0.06s\n","        46           0.2338            0.05s\n","        47           0.2280            0.05s\n","        48           0.2209            0.05s\n","        49           0.2164            0.05s\n","        50           0.2092            0.05s\n","        51           0.2042            0.05s\n","        52           0.1992            0.05s\n","        53           0.1938            0.05s\n","        54           0.1893            0.05s\n","        55           0.1846            0.05s\n","        56           0.1789            0.05s\n","        57           0.1729            0.04s\n","        58           0.1698            0.04s\n","        59           0.1658            0.04s\n","        60           0.1615            0.04s\n","        61           0.1576            0.04s\n","        62           0.1539            0.04s\n","        63           0.1509            0.04s\n","        64           0.1472            0.04s\n","        65           0.1438            0.04s\n","        66           0.1399            0.04s\n","        67           0.1368            0.03s\n","        68           0.1333            0.03s\n","        69           0.1304            0.03s\n","        70           0.1273            0.03s\n","        71           0.1247            0.03s\n","        72           0.1223            0.03s\n","        73           0.1202            0.03s\n","        74           0.1165            0.03s\n","        75           0.1140            0.03s\n","        76           0.1115            0.02s\n","        77           0.1084            0.02s\n","        78           0.1055            0.02s\n","        79           0.1028            0.02s\n","        80           0.1001            0.02s\n","        81           0.0982            0.02s\n","        82           0.0958            0.02s\n","        83           0.0941            0.02s\n","        84           0.0919            0.02s\n","        85           0.0903            0.02s\n","        86           0.0879            0.01s\n","        87           0.0860            0.01s\n","        88           0.0845            0.01s\n","        89           0.0827            0.01s\n","        90           0.0807            0.01s\n","        91           0.0783            0.01s\n","        92           0.0768            0.01s\n","        93           0.0753            0.01s\n","        94           0.0730            0.01s\n","        95           0.0713            0.01s\n","        96           0.0696            0.00s\n","        97           0.0680            0.00s\n","        98           0.0666            0.00s\n","        99           0.0653            0.00s\n","       100           0.0643            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2790            0.11s\n","         2           1.2093            0.11s\n","         3           1.1292            0.12s\n","         4           1.0620            0.12s\n","         5           1.0141            0.12s\n","         6           0.9604            0.12s\n","         7           0.9157            0.13s\n","         8           0.8686            0.12s\n","         9           0.8306            0.12s\n","        10           0.7930            0.11s\n","        11           0.7558            0.11s\n","        12           0.7266            0.11s\n","        13           0.6967            0.11s\n","        14           0.6715            0.10s\n","        15           0.6425            0.10s\n","        16           0.6202            0.10s\n","        17           0.5981            0.10s\n","        18           0.5739            0.10s\n","        19           0.5521            0.10s\n","        20           0.5317            0.09s\n","        21           0.5140            0.09s\n","        22           0.4961            0.09s\n","        23           0.4827            0.09s\n","        24           0.4675            0.09s\n","        25           0.4516            0.09s\n","        26           0.4390            0.08s\n","        27           0.4250            0.08s\n","        28           0.4112            0.08s\n","        29           0.4008            0.08s\n","        30           0.3887            0.08s\n","        31           0.3781            0.08s\n","        32           0.3680            0.07s\n","        33           0.3575            0.07s\n","        34           0.3464            0.07s\n","        35           0.3359            0.07s\n","        36           0.3275            0.07s\n","        37           0.3173            0.07s\n","        38           0.3098            0.07s\n","        39           0.3022            0.07s\n","        40           0.2942            0.06s\n","        41           0.2863            0.06s\n","        42           0.2817            0.06s\n","        43           0.2736            0.06s\n","        44           0.2665            0.06s\n","        45           0.2593            0.06s\n","        46           0.2525            0.06s\n","        47           0.2458            0.06s\n","        48           0.2424            0.06s\n","        49           0.2373            0.05s\n","        50           0.2312            0.05s\n","        51           0.2245            0.05s\n","        52           0.2206            0.05s\n","        53           0.2151            0.05s\n","        54           0.2103            0.05s\n","        55           0.2060            0.05s\n","        56           0.2021            0.05s\n","        57           0.1973            0.05s\n","        58           0.1931            0.04s\n","        59           0.1886            0.04s\n","        60           0.1854            0.04s\n","        61           0.1815            0.04s\n","        62           0.1770            0.04s\n","        63           0.1727            0.04s\n","        64           0.1687            0.04s\n","        65           0.1647            0.04s\n","        66           0.1611            0.04s\n","        67           0.1580            0.03s\n","        68           0.1554            0.03s\n","        69           0.1507            0.03s\n","        70           0.1473            0.03s\n","        71           0.1438            0.03s\n","        72           0.1410            0.03s\n","        73           0.1386            0.03s\n","        74           0.1364            0.03s\n","        75           0.1322            0.03s\n","        76           0.1294            0.02s\n","        77           0.1265            0.02s\n","        78           0.1233            0.02s\n","        79           0.1204            0.02s\n","        80           0.1190            0.02s\n","        81           0.1162            0.02s\n","        82           0.1139            0.02s\n","        83           0.1123            0.02s\n","        84           0.1103            0.02s\n","        85           0.1079            0.02s\n","        86           0.1059            0.01s\n","        87           0.1040            0.01s\n","        88           0.1025            0.01s\n","        89           0.1003            0.01s\n","        90           0.0985            0.01s\n","        91           0.0968            0.01s\n","        92           0.0955            0.01s\n","        93           0.0934            0.01s\n","        94           0.0917            0.01s\n","        95           0.0903            0.01s\n","        96           0.0883            0.00s\n","        97           0.0869            0.00s\n","        98           0.0853            0.00s\n","        99           0.0836            0.00s\n","       100           0.0822            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2749            0.10s\n","         2           1.1813            0.10s\n","         3           1.1033            0.10s\n","         4           1.0337            0.10s\n","         5           0.9831            0.10s\n","         6           0.9342            0.10s\n","         7           0.8836            0.10s\n","         8           0.8434            0.10s\n","         9           0.8020            0.10s\n","        10           0.7619            0.10s\n","        11           0.7303            0.10s\n","        12           0.7004            0.10s\n","        13           0.6716            0.09s\n","        14           0.6422            0.09s\n","        15           0.6170            0.09s\n","        16           0.5945            0.09s\n","        17           0.5713            0.09s\n","        18           0.5491            0.09s\n","        19           0.5278            0.08s\n","        20           0.5077            0.08s\n","        21           0.4907            0.08s\n","        22           0.4758            0.08s\n","        23           0.4593            0.08s\n","        24           0.4425            0.08s\n","        25           0.4293            0.08s\n","        26           0.4154            0.07s\n","        27           0.4032            0.07s\n","        28           0.3896            0.07s\n","        29           0.3769            0.07s\n","        30           0.3688            0.07s\n","        31           0.3602            0.07s\n","        32           0.3515            0.07s\n","        33           0.3404            0.07s\n","        34           0.3296            0.07s\n","        35           0.3227            0.07s\n","        36           0.3148            0.07s\n","        37           0.3040            0.07s\n","        38           0.2961            0.07s\n","        39           0.2869            0.07s\n","        40           0.2789            0.07s\n","        41           0.2715            0.07s\n","        42           0.2639            0.07s\n","        43           0.2575            0.06s\n","        44           0.2517            0.06s\n","        45           0.2447            0.06s\n","        46           0.2390            0.06s\n","        47           0.2343            0.06s\n","        48           0.2274            0.06s\n","        49           0.2213            0.06s\n","        50           0.2161            0.06s\n","        51           0.2090            0.06s\n","        52           0.2049            0.05s\n","        53           0.2002            0.05s\n","        54           0.1949            0.05s\n","        55           0.1900            0.05s\n","        56           0.1845            0.05s\n","        57           0.1803            0.05s\n","        58           0.1754            0.05s\n","        59           0.1710            0.05s\n","        60           0.1668            0.04s\n","        61           0.1623            0.04s\n","        62           0.1593            0.04s\n","        63           0.1562            0.04s\n","        64           0.1538            0.04s\n","        65           0.1499            0.04s\n","        66           0.1469            0.04s\n","        67           0.1435            0.04s\n","        68           0.1413            0.03s\n","        69           0.1370            0.03s\n","        70           0.1338            0.03s\n","        71           0.1307            0.03s\n","        72           0.1286            0.03s\n","        73           0.1265            0.03s\n","        74           0.1241            0.03s\n","        75           0.1214            0.03s\n","        76           0.1188            0.03s\n","        77           0.1161            0.02s\n","        78           0.1135            0.02s\n","        79           0.1111            0.02s\n","        80           0.1076            0.02s\n","        81           0.1054            0.02s\n","        82           0.1039            0.02s\n","        83           0.1023            0.02s\n","        84           0.1004            0.02s\n","        85           0.0978            0.02s\n","        86           0.0955            0.01s\n","        87           0.0930            0.01s\n","        88           0.0911            0.01s\n","        89           0.0886            0.01s\n","        90           0.0873            0.01s\n","        91           0.0848            0.01s\n","        92           0.0835            0.01s\n","        93           0.0817            0.01s\n","        94           0.0796            0.01s\n","        95           0.0778            0.01s\n","        96           0.0766            0.00s\n","        97           0.0757            0.00s\n","        98           0.0737            0.00s\n","        99           0.0725            0.00s\n","       100           0.0711            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2778            0.14s\n","         2           1.1885            0.14s\n","         3           1.1093            0.12s\n","         4           1.0434            0.11s\n","         5           0.9845            0.11s\n","         6           0.9351            0.11s\n","         7           0.8926            0.10s\n","         8           0.8534            0.10s\n","         9           0.8133            0.10s\n","        10           0.7789            0.09s\n","        11           0.7451            0.09s\n","        12           0.7151            0.09s\n","        13           0.6872            0.09s\n","        14           0.6619            0.09s\n","        15           0.6414            0.09s\n","        16           0.6193            0.09s\n","        17           0.5996            0.08s\n","        18           0.5824            0.08s\n","        19           0.5619            0.08s\n","        20           0.5457            0.08s\n","        21           0.5264            0.08s\n","        22           0.5094            0.08s\n","        23           0.4937            0.08s\n","        24           0.4794            0.08s\n","        25           0.4653            0.08s\n","        26           0.4488            0.07s\n","        27           0.4360            0.07s\n","        28           0.4204            0.07s\n","        29           0.4072            0.07s\n","        30           0.3974            0.07s\n","        31           0.3873            0.07s\n","        32           0.3762            0.07s\n","        33           0.3633            0.07s\n","        34           0.3524            0.07s\n","        35           0.3421            0.06s\n","        36           0.3318            0.06s\n","        37           0.3226            0.06s\n","        38           0.3140            0.06s\n","        39           0.3060            0.06s\n","        40           0.2967            0.06s\n","        41           0.2898            0.06s\n","        42           0.2818            0.06s\n","        43           0.2728            0.06s\n","        44           0.2639            0.06s\n","        45           0.2570            0.05s\n","        46           0.2496            0.05s\n","        47           0.2436            0.05s\n","        48           0.2385            0.05s\n","        49           0.2322            0.05s\n","        50           0.2265            0.05s\n","        51           0.2211            0.05s\n","        52           0.2164            0.05s\n","        53           0.2119            0.05s\n","        54           0.2063            0.05s\n","        55           0.2011            0.04s\n","        56           0.1972            0.04s\n","        57           0.1919            0.04s\n","        58           0.1869            0.04s\n","        59           0.1823            0.04s\n","        60           0.1782            0.04s\n","        61           0.1731            0.04s\n","        62           0.1693            0.04s\n","        63           0.1665            0.04s\n","        64           0.1639            0.04s\n","        65           0.1600            0.03s\n","        66           0.1566            0.03s\n","        67           0.1534            0.03s\n","        68           0.1494            0.03s\n","        69           0.1461            0.03s\n","        70           0.1439            0.03s\n","        71           0.1408            0.03s\n","        72           0.1374            0.03s\n","        73           0.1348            0.03s\n","        74           0.1318            0.03s\n","        75           0.1285            0.02s\n","        76           0.1253            0.02s\n","        77           0.1222            0.02s\n","        78           0.1199            0.02s\n","        79           0.1179            0.02s\n","        80           0.1154            0.02s\n","        81           0.1123            0.02s\n","        82           0.1102            0.02s\n","        83           0.1078            0.02s\n","        84           0.1051            0.02s\n","        85           0.1026            0.01s\n","        86           0.1009            0.01s\n","        87           0.0989            0.01s\n","        88           0.0971            0.01s\n","        89           0.0950            0.01s\n","        90           0.0933            0.01s\n","        91           0.0918            0.01s\n","        92           0.0898            0.01s\n","        93           0.0882            0.01s\n","        94           0.0864            0.01s\n","        95           0.0850            0.00s\n","        96           0.0834            0.00s\n","        97           0.0818            0.00s\n","        98           0.0800            0.00s\n","        99           0.0782            0.00s\n","       100           0.0764            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2790            0.11s\n","         2           1.1925            0.11s\n","         3           1.1269            0.10s\n","         4           1.0664            0.10s\n","         5           1.0012            0.10s\n","         6           0.9416            0.09s\n","         7           0.8907            0.09s\n","         8           0.8423            0.09s\n","         9           0.8030            0.09s\n","        10           0.7666            0.09s\n","        11           0.7372            0.09s\n","        12           0.7057            0.09s\n","        13           0.6821            0.08s\n","        14           0.6509            0.08s\n","        15           0.6278            0.08s\n","        16           0.6068            0.08s\n","        17           0.5831            0.08s\n","        18           0.5637            0.08s\n","        19           0.5434            0.08s\n","        20           0.5269            0.08s\n","        21           0.5063            0.08s\n","        22           0.4932            0.08s\n","        23           0.4752            0.08s\n","        24           0.4596            0.08s\n","        25           0.4440            0.07s\n","        26           0.4298            0.07s\n","        27           0.4182            0.07s\n","        28           0.4041            0.07s\n","        29           0.3923            0.07s\n","        30           0.3824            0.07s\n","        31           0.3707            0.07s\n","        32           0.3596            0.07s\n","        33           0.3472            0.07s\n","        34           0.3392            0.06s\n","        35           0.3302            0.06s\n","        36           0.3200            0.06s\n","        37           0.3120            0.06s\n","        38           0.3049            0.06s\n","        39           0.2960            0.06s\n","        40           0.2880            0.06s\n","        41           0.2798            0.06s\n","        42           0.2730            0.06s\n","        43           0.2652            0.06s\n","        44           0.2584            0.06s\n","        45           0.2532            0.05s\n","        46           0.2486            0.05s\n","        47           0.2433            0.05s\n","        48           0.2366            0.05s\n","        49           0.2320            0.05s\n","        50           0.2245            0.05s\n","        51           0.2202            0.05s\n","        52           0.2158            0.05s\n","        53           0.2095            0.05s\n","        54           0.2057            0.05s\n","        55           0.2018            0.04s\n","        56           0.1974            0.04s\n","        57           0.1924            0.04s\n","        58           0.1881            0.04s\n","        59           0.1841            0.04s\n","        60           0.1806            0.04s\n","        61           0.1778            0.04s\n","        62           0.1748            0.04s\n","        63           0.1694            0.04s\n","        64           0.1660            0.04s\n","        65           0.1622            0.03s\n","        66           0.1590            0.03s\n","        67           0.1558            0.03s\n","        68           0.1520            0.03s\n","        69           0.1496            0.03s\n","        70           0.1470            0.03s\n","        71           0.1434            0.03s\n","        72           0.1415            0.03s\n","        73           0.1387            0.03s\n","        74           0.1362            0.03s\n","        75           0.1324            0.02s\n","        76           0.1295            0.02s\n","        77           0.1281            0.02s\n","        78           0.1250            0.02s\n","        79           0.1221            0.02s\n","        80           0.1197            0.02s\n","        81           0.1163            0.02s\n","        82           0.1138            0.02s\n","        83           0.1123            0.02s\n","        84           0.1097            0.02s\n","        85           0.1078            0.01s\n","        86           0.1060            0.01s\n","        87           0.1037            0.01s\n","        88           0.1021            0.01s\n","        89           0.0996            0.01s\n","        90           0.0981            0.01s\n","        91           0.0967            0.01s\n","        92           0.0956            0.01s\n","        93           0.0930            0.01s\n","        94           0.0911            0.01s\n","        95           0.0898            0.00s\n","        96           0.0882            0.00s\n","        97           0.0870            0.00s\n","        98           0.0853            0.00s\n","        99           0.0840            0.00s\n","       100           0.0827            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2725            0.09s\n","         2           1.1777            0.13s\n","         3           1.1084            0.12s\n","         4           1.0520            0.12s\n","         5           0.9860            0.12s\n","         6           0.9282            0.13s\n","         7           0.8763            0.12s\n","         8           0.8398            0.12s\n","         9           0.7965            0.12s\n","        10           0.7581            0.12s\n","        11           0.7249            0.11s\n","        12           0.6916            0.11s\n","        13           0.6637            0.11s\n","        14           0.6396            0.10s\n","        15           0.6153            0.10s\n","        16           0.5905            0.10s\n","        17           0.5708            0.10s\n","        18           0.5470            0.09s\n","        19           0.5231            0.09s\n","        20           0.5051            0.09s\n","        21           0.4856            0.09s\n","        22           0.4720            0.09s\n","        23           0.4554            0.09s\n","        24           0.4378            0.08s\n","        25           0.4220            0.08s\n","        26           0.4106            0.08s\n","        27           0.3986            0.08s\n","        28           0.3852            0.08s\n","        29           0.3728            0.08s\n","        30           0.3630            0.08s\n","        31           0.3540            0.07s\n","        32           0.3426            0.07s\n","        33           0.3319            0.07s\n","        34           0.3215            0.07s\n","        35           0.3128            0.07s\n","        36           0.3027            0.07s\n","        37           0.2955            0.07s\n","        38           0.2877            0.07s\n","        39           0.2775            0.06s\n","        40           0.2714            0.06s\n","        41           0.2638            0.06s\n","        42           0.2573            0.06s\n","        43           0.2507            0.06s\n","        44           0.2438            0.06s\n","        45           0.2387            0.06s\n","        46           0.2325            0.06s\n","        47           0.2276            0.05s\n","        48           0.2205            0.05s\n","        49           0.2148            0.05s\n","        50           0.2103            0.05s\n","        51           0.2043            0.05s\n","        52           0.2003            0.05s\n","        53           0.1958            0.05s\n","        54           0.1912            0.05s\n","        55           0.1871            0.05s\n","        56           0.1835            0.05s\n","        57           0.1797            0.04s\n","        58           0.1760            0.04s\n","        59           0.1712            0.04s\n","        60           0.1672            0.04s\n","        61           0.1634            0.04s\n","        62           0.1593            0.04s\n","        63           0.1559            0.04s\n","        64           0.1532            0.04s\n","        65           0.1489            0.04s\n","        66           0.1459            0.03s\n","        67           0.1419            0.03s\n","        68           0.1392            0.03s\n","        69           0.1360            0.03s\n","        70           0.1337            0.03s\n","        71           0.1317            0.03s\n","        72           0.1281            0.03s\n","        73           0.1251            0.03s\n","        74           0.1221            0.03s\n","        75           0.1197            0.03s\n","        76           0.1170            0.02s\n","        77           0.1144            0.02s\n","        78           0.1112            0.02s\n","        79           0.1087            0.02s\n","        80           0.1069            0.02s\n","        81           0.1046            0.02s\n","        82           0.1025            0.02s\n","        83           0.1003            0.02s\n","        84           0.0987            0.02s\n","        85           0.0971            0.02s\n","        86           0.0951            0.02s\n","        87           0.0933            0.01s\n","        88           0.0916            0.01s\n","        89           0.0899            0.01s\n","        90           0.0876            0.01s\n","        91           0.0860            0.01s\n","        92           0.0841            0.01s\n","        93           0.0822            0.01s\n","        94           0.0804            0.01s\n","        95           0.0788            0.01s\n","        96           0.0770            0.00s\n","        97           0.0755            0.00s\n","        98           0.0741            0.00s\n","        99           0.0730            0.00s\n","       100           0.0718            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2777            0.11s\n","         2           1.1861            0.10s\n","         3           1.1042            0.10s\n","         4           1.0426            0.10s\n","         5           0.9916            0.10s\n","         6           0.9360            0.10s\n","         7           0.8913            0.10s\n","         8           0.8470            0.10s\n","         9           0.8065            0.10s\n","        10           0.7698            0.10s\n","        11           0.7335            0.10s\n","        12           0.6984            0.09s\n","        13           0.6735            0.09s\n","        14           0.6473            0.09s\n","        15           0.6214            0.09s\n","        16           0.6000            0.09s\n","        17           0.5780            0.09s\n","        18           0.5561            0.09s\n","        19           0.5355            0.09s\n","        20           0.5195            0.08s\n","        21           0.5017            0.08s\n","        22           0.4867            0.08s\n","        23           0.4736            0.08s\n","        24           0.4577            0.08s\n","        25           0.4471            0.08s\n","        26           0.4334            0.08s\n","        27           0.4207            0.08s\n","        28           0.4073            0.08s\n","        29           0.3953            0.08s\n","        30           0.3823            0.08s\n","        31           0.3722            0.07s\n","        32           0.3606            0.07s\n","        33           0.3529            0.07s\n","        34           0.3441            0.07s\n","        35           0.3350            0.07s\n","        36           0.3262            0.07s\n","        37           0.3152            0.07s\n","        38           0.3067            0.07s\n","        39           0.2986            0.07s\n","        40           0.2896            0.06s\n","        41           0.2811            0.06s\n","        42           0.2733            0.06s\n","        43           0.2683            0.06s\n","        44           0.2626            0.06s\n","        45           0.2566            0.06s\n","        46           0.2510            0.06s\n","        47           0.2444            0.06s\n","        48           0.2374            0.06s\n","        49           0.2308            0.06s\n","        50           0.2234            0.05s\n","        51           0.2191            0.05s\n","        52           0.2146            0.05s\n","        53           0.2095            0.05s\n","        54           0.2036            0.05s\n","        55           0.1996            0.05s\n","        56           0.1958            0.05s\n","        57           0.1915            0.05s\n","        58           0.1859            0.05s\n","        59           0.1824            0.04s\n","        60           0.1785            0.04s\n","        61           0.1732            0.04s\n","        62           0.1695            0.04s\n","        63           0.1658            0.04s\n","        64           0.1622            0.04s\n","        65           0.1592            0.04s\n","        66           0.1555            0.04s\n","        67           0.1525            0.04s\n","        68           0.1494            0.03s\n","        69           0.1456            0.03s\n","        70           0.1431            0.03s\n","        71           0.1398            0.03s\n","        72           0.1372            0.03s\n","        73           0.1330            0.03s\n","        74           0.1299            0.03s\n","        75           0.1277            0.03s\n","        76           0.1254            0.03s\n","        77           0.1220            0.02s\n","        78           0.1195            0.02s\n","        79           0.1172            0.02s\n","        80           0.1147            0.02s\n","        81           0.1121            0.02s\n","        82           0.1096            0.02s\n","        83           0.1077            0.02s\n","        84           0.1062            0.02s\n","        85           0.1035            0.02s\n","        86           0.1018            0.02s\n","        87           0.0981            0.01s\n","        88           0.0964            0.01s\n","        89           0.0951            0.01s\n","        90           0.0921            0.01s\n","        91           0.0906            0.01s\n","        92           0.0883            0.01s\n","        93           0.0853            0.01s\n","        94           0.0831            0.01s\n","        95           0.0819            0.01s\n","        96           0.0806            0.00s\n","        97           0.0789            0.00s\n","        98           0.0776            0.00s\n","        99           0.0765            0.00s\n","       100           0.0756            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2797            0.10s\n","         2           1.1866            0.10s\n","         3           1.1096            0.10s\n","         4           1.0465            0.10s\n","         5           0.9868            0.10s\n","         6           0.9405            0.10s\n","         7           0.8956            0.10s\n","         8           0.8520            0.10s\n","         9           0.8166            0.10s\n","        10           0.7866            0.09s\n","        11           0.7553            0.09s\n","        12           0.7230            0.09s\n","        13           0.6965            0.09s\n","        14           0.6702            0.09s\n","        15           0.6476            0.09s\n","        16           0.6228            0.09s\n","        17           0.6009            0.09s\n","        18           0.5775            0.09s\n","        19           0.5599            0.09s\n","        20           0.5418            0.08s\n","        21           0.5232            0.08s\n","        22           0.5053            0.08s\n","        23           0.4903            0.08s\n","        24           0.4726            0.08s\n","        25           0.4570            0.08s\n","        26           0.4459            0.08s\n","        27           0.4349            0.08s\n","        28           0.4200            0.08s\n","        29           0.4073            0.07s\n","        30           0.3957            0.07s\n","        31           0.3845            0.07s\n","        32           0.3758            0.07s\n","        33           0.3656            0.07s\n","        34           0.3574            0.07s\n","        35           0.3466            0.07s\n","        36           0.3359            0.07s\n","        37           0.3281            0.07s\n","        38           0.3203            0.07s\n","        39           0.3118            0.06s\n","        40           0.3040            0.06s\n","        41           0.2953            0.06s\n","        42           0.2869            0.06s\n","        43           0.2805            0.06s\n","        44           0.2735            0.06s\n","        45           0.2648            0.06s\n","        46           0.2598            0.06s\n","        47           0.2524            0.06s\n","        48           0.2466            0.06s\n","        49           0.2410            0.05s\n","        50           0.2350            0.05s\n","        51           0.2313            0.05s\n","        52           0.2246            0.05s\n","        53           0.2205            0.05s\n","        54           0.2168            0.05s\n","        55           0.2114            0.05s\n","        56           0.2074            0.05s\n","        57           0.2035            0.05s\n","        58           0.1958            0.04s\n","        59           0.1908            0.04s\n","        60           0.1863            0.04s\n","        61           0.1814            0.04s\n","        62           0.1791            0.04s\n","        63           0.1745            0.04s\n","        64           0.1699            0.04s\n","        65           0.1656            0.04s\n","        66           0.1627            0.04s\n","        67           0.1594            0.04s\n","        68           0.1562            0.03s\n","        69           0.1536            0.03s\n","        70           0.1498            0.03s\n","        71           0.1470            0.03s\n","        72           0.1430            0.03s\n","        73           0.1403            0.03s\n","        74           0.1371            0.03s\n","        75           0.1338            0.03s\n","        76           0.1310            0.03s\n","        77           0.1286            0.02s\n","        78           0.1258            0.02s\n","        79           0.1233            0.02s\n","        80           0.1210            0.02s\n","        81           0.1181            0.02s\n","        82           0.1157            0.02s\n","        83           0.1132            0.02s\n","        84           0.1113            0.02s\n","        85           0.1089            0.02s\n","        86           0.1066            0.01s\n","        87           0.1040            0.01s\n","        88           0.1028            0.01s\n","        89           0.1013            0.01s\n","        90           0.0989            0.01s\n","        91           0.0971            0.01s\n","        92           0.0950            0.01s\n","        93           0.0932            0.01s\n","        94           0.0913            0.01s\n","        95           0.0897            0.01s\n","        96           0.0885            0.00s\n","        97           0.0872            0.00s\n","        98           0.0855            0.00s\n","        99           0.0834            0.00s\n","       100           0.0821            0.00s\n","     Unnamed: 0  preg  plas  pres  skin  insu  mass   pedi  age  class\n","0             0     6   148    72    35     0  33.6  0.627   50      1\n","1             1     1    85    66    29     0  26.6  0.351   31      0\n","2             2     8   183    64     0     0  23.3  0.672   32      1\n","3             3     1    89    66    23    94  28.1  0.167   21      0\n","4             4     0   137    40    35   168  43.1  2.288   33      1\n","..          ...   ...   ...   ...   ...   ...   ...    ...  ...    ...\n","763         763    10   101    76    48   180  32.9  0.171   63      0\n","764         764     2   122    70    27     0  36.8  0.340   27      0\n","765         765     5   121    72    23   112  26.2  0.245   30      0\n","766         766     1   126    60     0     0  30.1  0.349   47      1\n","767         767     1    93    70    31     0  30.4  0.315   23      0\n","\n","[768 rows x 10 columns]\n","      Iter       Train Loss   Remaining Time \n","         1           1.2268            0.19s\n","         2           1.1728            0.19s\n","         3           1.1282            0.19s\n","         4           1.0894            0.19s\n","         5           1.0568            0.19s\n","         6           1.0271            0.19s\n","         7           1.0023            0.18s\n","         8           0.9797            0.18s\n","         9           0.9581            0.18s\n","        10           0.9400            0.18s\n","        11           0.9221            0.18s\n","        12           0.9073            0.18s\n","        13           0.8927            0.18s\n","        14           0.8785            0.18s\n","        15           0.8668            0.18s\n","        16           0.8551            0.17s\n","        17           0.8436            0.17s\n","        18           0.8329            0.17s\n","        19           0.8238            0.17s\n","        20           0.8128            0.16s\n","        21           0.8045            0.16s\n","        22           0.7962            0.16s\n","        23           0.7879            0.16s\n","        24           0.7785            0.15s\n","        25           0.7712            0.15s\n","        26           0.7623            0.15s\n","        27           0.7557            0.15s\n","        28           0.7492            0.15s\n","        29           0.7415            0.14s\n","        30           0.7360            0.14s\n","        31           0.7295            0.14s\n","        32           0.7229            0.14s\n","        33           0.7180            0.14s\n","        34           0.7117            0.14s\n","        35           0.7056            0.14s\n","        36           0.7017            0.13s\n","        37           0.6966            0.13s\n","        38           0.6897            0.13s\n","        39           0.6853            0.13s\n","        40           0.6808            0.12s\n","        41           0.6757            0.12s\n","        42           0.6705            0.12s\n","        43           0.6671            0.12s\n","        44           0.6624            0.12s\n","        45           0.6547            0.11s\n","        46           0.6517            0.11s\n","        47           0.6490            0.11s\n","        48           0.6455            0.11s\n","        49           0.6410            0.10s\n","        50           0.6359            0.10s\n","        51           0.6312            0.10s\n","        52           0.6287            0.10s\n","        53           0.6264            0.10s\n","        54           0.6225            0.09s\n","        55           0.6186            0.09s\n","        56           0.6151            0.09s\n","        57           0.6102            0.09s\n","        58           0.6075            0.09s\n","        59           0.6024            0.08s\n","        60           0.5993            0.08s\n","        61           0.5968            0.08s\n","        62           0.5926            0.08s\n","        63           0.5894            0.08s\n","        64           0.5874            0.07s\n","        65           0.5838            0.07s\n","        66           0.5795            0.07s\n","        67           0.5770            0.07s\n","        68           0.5743            0.06s\n","        69           0.5724            0.06s\n","        70           0.5698            0.06s\n","        71           0.5681            0.06s\n","        72           0.5645            0.06s\n","        73           0.5609            0.05s\n","        74           0.5593            0.05s\n","        75           0.5558            0.05s\n","        76           0.5512            0.05s\n","        77           0.5481            0.05s\n","        78           0.5468            0.04s\n","        79           0.5447            0.04s\n","        80           0.5405            0.04s\n","        81           0.5368            0.04s\n","        82           0.5327            0.04s\n","        83           0.5312            0.03s\n","        84           0.5288            0.03s\n","        85           0.5250            0.03s\n","        86           0.5225            0.03s\n","        87           0.5203            0.03s\n","        88           0.5190            0.02s\n","        89           0.5127            0.02s\n","        90           0.5106            0.02s\n","        91           0.5090            0.02s\n","        92           0.5079            0.02s\n","        93           0.5046            0.01s\n","        94           0.5026            0.01s\n","        95           0.4992            0.01s\n","        96           0.4975            0.01s\n","        97           0.4949            0.01s\n","        98           0.4939            0.00s\n","        99           0.4916            0.00s\n","       100           0.4891            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2241            0.20s\n","         2           1.1696            0.20s\n","         3           1.1239            0.20s\n","         4           1.0859            0.19s\n","         5           1.0528            0.19s\n","         6           1.0247            0.19s\n","         7           0.9998            0.19s\n","         8           0.9774            0.18s\n","         9           0.9579            0.18s\n","        10           0.9388            0.18s\n","        11           0.9224            0.18s\n","        12           0.9062            0.18s\n","        13           0.8916            0.17s\n","        14           0.8798            0.17s\n","        15           0.8671            0.17s\n","        16           0.8555            0.17s\n","        17           0.8449            0.16s\n","        18           0.8343            0.16s\n","        19           0.8261            0.16s\n","        20           0.8177            0.16s\n","        21           0.8101            0.16s\n","        22           0.8009            0.15s\n","        23           0.7941            0.15s\n","        24           0.7861            0.15s\n","        25           0.7796            0.15s\n","        26           0.7722            0.15s\n","        27           0.7652            0.14s\n","        28           0.7577            0.14s\n","        29           0.7523            0.14s\n","        30           0.7443            0.14s\n","        31           0.7396            0.14s\n","        32           0.7322            0.14s\n","        33           0.7259            0.14s\n","        34           0.7203            0.13s\n","        35           0.7136            0.13s\n","        36           0.7096            0.13s\n","        37           0.7069            0.13s\n","        38           0.7013            0.13s\n","        39           0.6972            0.12s\n","        40           0.6928            0.12s\n","        41           0.6885            0.12s\n","        42           0.6843            0.12s\n","        43           0.6801            0.11s\n","        44           0.6777            0.11s\n","        45           0.6743            0.11s\n","        46           0.6714            0.11s\n","        47           0.6618            0.11s\n","        48           0.6578            0.10s\n","        49           0.6542            0.10s\n","        50           0.6484            0.10s\n","        51           0.6455            0.10s\n","        52           0.6434            0.10s\n","        53           0.6400            0.09s\n","        54           0.6368            0.09s\n","        55           0.6319            0.09s\n","        56           0.6286            0.09s\n","        57           0.6238            0.08s\n","        58           0.6153            0.08s\n","        59           0.6114            0.08s\n","        60           0.6074            0.08s\n","        61           0.6050            0.08s\n","        62           0.6022            0.07s\n","        63           0.6004            0.07s\n","        64           0.5962            0.07s\n","        65           0.5941            0.07s\n","        66           0.5921            0.07s\n","        67           0.5869            0.06s\n","        68           0.5833            0.06s\n","        69           0.5802            0.06s\n","        70           0.5764            0.06s\n","        71           0.5702            0.06s\n","        72           0.5677            0.05s\n","        73           0.5650            0.05s\n","        74           0.5620            0.05s\n","        75           0.5583            0.05s\n","        76           0.5553            0.05s\n","        77           0.5521            0.04s\n","        78           0.5488            0.04s\n","        79           0.5461            0.04s\n","        80           0.5398            0.04s\n","        81           0.5379            0.04s\n","        82           0.5359            0.03s\n","        83           0.5341            0.03s\n","        84           0.5312            0.03s\n","        85           0.5279            0.03s\n","        86           0.5264            0.03s\n","        87           0.5237            0.03s\n","        88           0.5190            0.02s\n","        89           0.5152            0.02s\n","        90           0.5120            0.02s\n","        91           0.5095            0.02s\n","        92           0.5072            0.02s\n","        93           0.5043            0.01s\n","        94           0.5022            0.01s\n","        95           0.4987            0.01s\n","        96           0.4976            0.01s\n","        97           0.4961            0.01s\n","        98           0.4921            0.00s\n","        99           0.4872            0.00s\n","       100           0.4853            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2300            0.23s\n","         2           1.1707            0.26s\n","         3           1.1221            0.25s\n","         4           1.0820            0.23s\n","         5           1.0451            0.22s\n","         6           1.0155            0.21s\n","         7           0.9889            0.20s\n","         8           0.9656            0.20s\n","         9           0.9441            0.19s\n","        10           0.9253            0.19s\n","        11           0.9067            0.18s\n","        12           0.8916            0.18s\n","        13           0.8783            0.18s\n","        14           0.8640            0.17s\n","        15           0.8519            0.17s\n","        16           0.8403            0.17s\n","        17           0.8313            0.17s\n","        18           0.8210            0.16s\n","        19           0.8089            0.16s\n","        20           0.8015            0.16s\n","        21           0.7913            0.16s\n","        22           0.7848            0.15s\n","        23           0.7766            0.15s\n","        24           0.7688            0.15s\n","        25           0.7637            0.15s\n","        26           0.7563            0.15s\n","        27           0.7487            0.14s\n","        28           0.7444            0.14s\n","        29           0.7376            0.14s\n","        30           0.7308            0.14s\n","        31           0.7232            0.13s\n","        32           0.7181            0.13s\n","        33           0.7121            0.13s\n","        34           0.7063            0.13s\n","        35           0.6987            0.13s\n","        36           0.6942            0.13s\n","        37           0.6900            0.12s\n","        38           0.6874            0.12s\n","        39           0.6830            0.12s\n","        40           0.6803            0.12s\n","        41           0.6783            0.12s\n","        42           0.6745            0.11s\n","        43           0.6707            0.11s\n","        44           0.6669            0.11s\n","        45           0.6642            0.11s\n","        46           0.6578            0.11s\n","        47           0.6541            0.10s\n","        48           0.6493            0.10s\n","        49           0.6477            0.10s\n","        50           0.6434            0.10s\n","        51           0.6399            0.10s\n","        52           0.6333            0.09s\n","        53           0.6301            0.09s\n","        54           0.6249            0.09s\n","        55           0.6221            0.09s\n","        56           0.6191            0.09s\n","        57           0.6176            0.08s\n","        58           0.6136            0.08s\n","        59           0.6101            0.08s\n","        60           0.6065            0.08s\n","        61           0.6041            0.08s\n","        62           0.6005            0.07s\n","        63           0.5954            0.07s\n","        64           0.5937            0.07s\n","        65           0.5916            0.07s\n","        66           0.5888            0.07s\n","        67           0.5847            0.06s\n","        68           0.5817            0.06s\n","        69           0.5771            0.06s\n","        70           0.5725            0.06s\n","        71           0.5697            0.06s\n","        72           0.5673            0.05s\n","        73           0.5639            0.05s\n","        74           0.5629            0.05s\n","        75           0.5605            0.05s\n","        76           0.5574            0.05s\n","        77           0.5545            0.04s\n","        78           0.5512            0.04s\n","        79           0.5486            0.04s\n","        80           0.5464            0.04s\n","        81           0.5426            0.04s\n","        82           0.5402            0.03s\n","        83           0.5376            0.03s\n","        84           0.5355            0.03s\n","        85           0.5289            0.03s\n","        86           0.5239            0.03s\n","        87           0.5231            0.03s\n","        88           0.5203            0.02s\n","        89           0.5186            0.02s\n","        90           0.5163            0.02s\n","        91           0.5108            0.02s\n","        92           0.5089            0.02s\n","        93           0.5051            0.01s\n","        94           0.5037            0.01s\n","        95           0.5019            0.01s\n","        96           0.4992            0.01s\n","        97           0.4951            0.01s\n","        98           0.4920            0.00s\n","        99           0.4876            0.00s\n","       100           0.4867            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2425            0.19s\n","         2           1.1951            0.19s\n","         3           1.1499            0.19s\n","         4           1.1116            0.19s\n","         5           1.0796            0.19s\n","         6           1.0521            0.19s\n","         7           1.0280            0.18s\n","         8           1.0045            0.18s\n","         9           0.9827            0.18s\n","        10           0.9663            0.18s\n","        11           0.9492            0.18s\n","        12           0.9334            0.17s\n","        13           0.9197            0.17s\n","        14           0.9075            0.17s\n","        15           0.8950            0.17s\n","        16           0.8838            0.17s\n","        17           0.8715            0.16s\n","        18           0.8606            0.16s\n","        19           0.8507            0.16s\n","        20           0.8413            0.16s\n","        21           0.8326            0.16s\n","        22           0.8231            0.15s\n","        23           0.8146            0.15s\n","        24           0.8042            0.15s\n","        25           0.7975            0.15s\n","        26           0.7907            0.15s\n","        27           0.7837            0.15s\n","        28           0.7753            0.14s\n","        29           0.7691            0.14s\n","        30           0.7634            0.14s\n","        31           0.7573            0.14s\n","        32           0.7516            0.14s\n","        33           0.7455            0.13s\n","        34           0.7404            0.13s\n","        35           0.7350            0.13s\n","        36           0.7295            0.13s\n","        37           0.7251            0.13s\n","        38           0.7204            0.12s\n","        39           0.7170            0.12s\n","        40           0.7080            0.12s\n","        41           0.7027            0.12s\n","        42           0.7003            0.12s\n","        43           0.6969            0.11s\n","        44           0.6921            0.11s\n","        45           0.6889            0.11s\n","        46           0.6845            0.11s\n","        47           0.6805            0.11s\n","        48           0.6772            0.10s\n","        49           0.6741            0.10s\n","        50           0.6696            0.10s\n","        51           0.6669            0.10s\n","        52           0.6619            0.10s\n","        53           0.6594            0.09s\n","        54           0.6563            0.09s\n","        55           0.6526            0.09s\n","        56           0.6484            0.09s\n","        57           0.6461            0.09s\n","        58           0.6424            0.08s\n","        59           0.6401            0.08s\n","        60           0.6371            0.08s\n","        61           0.6330            0.08s\n","        62           0.6285            0.08s\n","        63           0.6248            0.07s\n","        64           0.6231            0.07s\n","        65           0.6199            0.07s\n","        66           0.6134            0.07s\n","        67           0.6120            0.07s\n","        68           0.6086            0.07s\n","        69           0.6066            0.06s\n","        70           0.6034            0.06s\n","        71           0.6005            0.06s\n","        72           0.5931            0.06s\n","        73           0.5898            0.06s\n","        74           0.5879            0.05s\n","        75           0.5854            0.05s\n","        76           0.5823            0.05s\n","        77           0.5811            0.05s\n","        78           0.5769            0.04s\n","        79           0.5723            0.04s\n","        80           0.5710            0.04s\n","        81           0.5683            0.04s\n","        82           0.5639            0.04s\n","        83           0.5595            0.03s\n","        84           0.5580            0.03s\n","        85           0.5561            0.03s\n","        86           0.5525            0.03s\n","        87           0.5507            0.03s\n","        88           0.5486            0.02s\n","        89           0.5461            0.02s\n","        90           0.5433            0.02s\n","        91           0.5401            0.02s\n","        92           0.5358            0.02s\n","        93           0.5336            0.01s\n","        94           0.5316            0.01s\n","        95           0.5296            0.01s\n","        96           0.5283            0.01s\n","        97           0.5239            0.01s\n","        98           0.5223            0.00s\n","        99           0.5206            0.00s\n","       100           0.5180            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2281            0.21s\n","         2           1.1772            0.20s\n","         3           1.1353            0.19s\n","         4           1.0995            0.19s\n","         5           1.0667            0.18s\n","         6           1.0388            0.18s\n","         7           1.0147            0.18s\n","         8           0.9930            0.17s\n","         9           0.9713            0.17s\n","        10           0.9516            0.17s\n","        11           0.9357            0.17s\n","        12           0.9203            0.17s\n","        13           0.9075            0.17s\n","        14           0.8933            0.16s\n","        15           0.8817            0.16s\n","        16           0.8698            0.16s\n","        17           0.8596            0.16s\n","        18           0.8496            0.16s\n","        19           0.8384            0.15s\n","        20           0.8291            0.15s\n","        21           0.8215            0.15s\n","        22           0.8119            0.15s\n","        23           0.8018            0.15s\n","        24           0.7940            0.14s\n","        25           0.7868            0.14s\n","        26           0.7778            0.14s\n","        27           0.7697            0.14s\n","        28           0.7641            0.14s\n","        29           0.7568            0.13s\n","        30           0.7503            0.13s\n","        31           0.7442            0.13s\n","        32           0.7394            0.13s\n","        33           0.7332            0.13s\n","        34           0.7280            0.12s\n","        35           0.7225            0.12s\n","        36           0.7181            0.12s\n","        37           0.7122            0.12s\n","        38           0.7066            0.12s\n","        39           0.7025            0.12s\n","        40           0.6960            0.11s\n","        41           0.6906            0.11s\n","        42           0.6869            0.11s\n","        43           0.6823            0.11s\n","        44           0.6777            0.11s\n","        45           0.6728            0.11s\n","        46           0.6705            0.10s\n","        47           0.6655            0.10s\n","        48           0.6616            0.10s\n","        49           0.6587            0.10s\n","        50           0.6524            0.10s\n","        51           0.6444            0.09s\n","        52           0.6414            0.09s\n","        53           0.6356            0.09s\n","        54           0.6325            0.09s\n","        55           0.6274            0.09s\n","        56           0.6255            0.08s\n","        57           0.6221            0.08s\n","        58           0.6195            0.08s\n","        59           0.6155            0.08s\n","        60           0.6116            0.08s\n","        61           0.6088            0.07s\n","        62           0.6072            0.07s\n","        63           0.6029            0.07s\n","        64           0.6007            0.07s\n","        65           0.5975            0.07s\n","        66           0.5952            0.06s\n","        67           0.5915            0.06s\n","        68           0.5901            0.06s\n","        69           0.5882            0.06s\n","        70           0.5850            0.06s\n","        71           0.5832            0.06s\n","        72           0.5794            0.05s\n","        73           0.5762            0.05s\n","        74           0.5741            0.05s\n","        75           0.5700            0.05s\n","        76           0.5643            0.05s\n","        77           0.5627            0.04s\n","        78           0.5606            0.04s\n","        79           0.5580            0.04s\n","        80           0.5564            0.04s\n","        81           0.5525            0.04s\n","        82           0.5492            0.03s\n","        83           0.5456            0.03s\n","        84           0.5435            0.03s\n","        85           0.5389            0.03s\n","        86           0.5366            0.03s\n","        87           0.5333            0.02s\n","        88           0.5305            0.02s\n","        89           0.5281            0.02s\n","        90           0.5267            0.02s\n","        91           0.5250            0.02s\n","        92           0.5232            0.02s\n","        93           0.5190            0.01s\n","        94           0.5147            0.01s\n","        95           0.5102            0.01s\n","        96           0.5072            0.01s\n","        97           0.5060            0.01s\n","        98           0.5030            0.00s\n","        99           0.5019            0.00s\n","       100           0.5005            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2136            0.18s\n","         2           1.1585            0.18s\n","         3           1.1133            0.18s\n","         4           1.0758            0.18s\n","         5           1.0436            0.18s\n","         6           1.0148            0.18s\n","         7           0.9899            0.18s\n","         8           0.9663            0.17s\n","         9           0.9470            0.17s\n","        10           0.9282            0.17s\n","        11           0.9108            0.17s\n","        12           0.8941            0.17s\n","        13           0.8802            0.17s\n","        14           0.8659            0.16s\n","        15           0.8524            0.16s\n","        16           0.8430            0.16s\n","        17           0.8314            0.16s\n","        18           0.8201            0.16s\n","        19           0.8098            0.15s\n","        20           0.8012            0.15s\n","        21           0.7931            0.15s\n","        22           0.7847            0.15s\n","        23           0.7765            0.15s\n","        24           0.7698            0.14s\n","        25           0.7631            0.14s\n","        26           0.7550            0.14s\n","        27           0.7484            0.14s\n","        28           0.7413            0.14s\n","        29           0.7357            0.13s\n","        30           0.7291            0.13s\n","        31           0.7228            0.13s\n","        32           0.7168            0.13s\n","        33           0.7083            0.13s\n","        34           0.7013            0.12s\n","        35           0.6956            0.12s\n","        36           0.6875            0.12s\n","        37           0.6823            0.12s\n","        38           0.6770            0.12s\n","        39           0.6744            0.12s\n","        40           0.6679            0.11s\n","        41           0.6624            0.11s\n","        42           0.6594            0.11s\n","        43           0.6551            0.11s\n","        44           0.6502            0.11s\n","        45           0.6465            0.10s\n","        46           0.6430            0.10s\n","        47           0.6408            0.10s\n","        48           0.6358            0.10s\n","        49           0.6314            0.10s\n","        50           0.6272            0.10s\n","        51           0.6234            0.09s\n","        52           0.6214            0.09s\n","        53           0.6169            0.09s\n","        54           0.6123            0.09s\n","        55           0.6077            0.09s\n","        56           0.6041            0.08s\n","        57           0.5994            0.08s\n","        58           0.5959            0.08s\n","        59           0.5942            0.08s\n","        60           0.5908            0.08s\n","        61           0.5860            0.07s\n","        62           0.5826            0.07s\n","        63           0.5766            0.07s\n","        64           0.5734            0.07s\n","        65           0.5702            0.07s\n","        66           0.5657            0.06s\n","        67           0.5616            0.06s\n","        68           0.5589            0.06s\n","        69           0.5554            0.06s\n","        70           0.5521            0.06s\n","        71           0.5503            0.06s\n","        72           0.5480            0.05s\n","        73           0.5466            0.05s\n","        74           0.5421            0.05s\n","        75           0.5394            0.05s\n","        76           0.5362            0.05s\n","        77           0.5330            0.04s\n","        78           0.5295            0.04s\n","        79           0.5237            0.04s\n","        80           0.5214            0.04s\n","        81           0.5203            0.04s\n","        82           0.5181            0.03s\n","        83           0.5162            0.03s\n","        84           0.5139            0.03s\n","        85           0.5107            0.03s\n","        86           0.5064            0.03s\n","        87           0.5037            0.02s\n","        88           0.5026            0.02s\n","        89           0.5016            0.02s\n","        90           0.4977            0.02s\n","        91           0.4968            0.02s\n","        92           0.4949            0.02s\n","        93           0.4932            0.01s\n","        94           0.4905            0.01s\n","        95           0.4887            0.01s\n","        96           0.4869            0.01s\n","        97           0.4859            0.01s\n","        98           0.4826            0.00s\n","        99           0.4792            0.00s\n","       100           0.4755            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2318            0.19s\n","         2           1.1820            0.20s\n","         3           1.1409            0.20s\n","         4           1.1060            0.20s\n","         5           1.0753            0.20s\n","         6           1.0471            0.20s\n","         7           1.0231            0.19s\n","         8           0.9995            0.19s\n","         9           0.9783            0.19s\n","        10           0.9601            0.18s\n","        11           0.9432            0.18s\n","        12           0.9284            0.18s\n","        13           0.9140            0.17s\n","        14           0.9004            0.17s\n","        15           0.8877            0.17s\n","        16           0.8764            0.16s\n","        17           0.8663            0.16s\n","        18           0.8576            0.16s\n","        19           0.8471            0.16s\n","        20           0.8363            0.16s\n","        21           0.8280            0.15s\n","        22           0.8189            0.15s\n","        23           0.8085            0.15s\n","        24           0.8006            0.15s\n","        25           0.7942            0.15s\n","        26           0.7887            0.14s\n","        27           0.7815            0.14s\n","        28           0.7743            0.14s\n","        29           0.7694            0.14s\n","        30           0.7634            0.14s\n","        31           0.7558            0.13s\n","        32           0.7500            0.13s\n","        33           0.7440            0.13s\n","        34           0.7382            0.13s\n","        35           0.7348            0.12s\n","        36           0.7293            0.12s\n","        37           0.7249            0.12s\n","        38           0.7175            0.12s\n","        39           0.7138            0.12s\n","        40           0.7080            0.12s\n","        41           0.7019            0.11s\n","        42           0.6995            0.11s\n","        43           0.6945            0.11s\n","        44           0.6910            0.11s\n","        45           0.6851            0.11s\n","        46           0.6812            0.10s\n","        47           0.6763            0.10s\n","        48           0.6710            0.10s\n","        49           0.6681            0.10s\n","        50           0.6621            0.10s\n","        51           0.6597            0.09s\n","        52           0.6567            0.09s\n","        53           0.6528            0.09s\n","        54           0.6467            0.09s\n","        55           0.6431            0.09s\n","        56           0.6379            0.08s\n","        57           0.6357            0.08s\n","        58           0.6311            0.08s\n","        59           0.6268            0.08s\n","        60           0.6231            0.08s\n","        61           0.6199            0.07s\n","        62           0.6177            0.07s\n","        63           0.6137            0.07s\n","        64           0.6094            0.07s\n","        65           0.6061            0.07s\n","        66           0.6033            0.07s\n","        67           0.5995            0.06s\n","        68           0.5976            0.06s\n","        69           0.5960            0.06s\n","        70           0.5944            0.06s\n","        71           0.5918            0.06s\n","        72           0.5891            0.05s\n","        73           0.5869            0.05s\n","        74           0.5806            0.05s\n","        75           0.5789            0.05s\n","        76           0.5760            0.05s\n","        77           0.5730            0.04s\n","        78           0.5692            0.04s\n","        79           0.5648            0.04s\n","        80           0.5606            0.04s\n","        81           0.5576            0.04s\n","        82           0.5557            0.03s\n","        83           0.5528            0.03s\n","        84           0.5497            0.03s\n","        85           0.5460            0.03s\n","        86           0.5439            0.03s\n","        87           0.5400            0.02s\n","        88           0.5367            0.02s\n","        89           0.5347            0.02s\n","        90           0.5305            0.02s\n","        91           0.5292            0.02s\n","        92           0.5277            0.02s\n","        93           0.5261            0.01s\n","        94           0.5237            0.01s\n","        95           0.5220            0.01s\n","        96           0.5208            0.01s\n","        97           0.5180            0.01s\n","        98           0.5150            0.00s\n","        99           0.5119            0.00s\n","       100           0.5100            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2384            0.18s\n","         2           1.1843            0.18s\n","         3           1.1393            0.18s\n","         4           1.1016            0.18s\n","         5           1.0670            0.18s\n","         6           1.0376            0.17s\n","         7           1.0122            0.17s\n","         8           0.9883            0.17s\n","         9           0.9672            0.17s\n","        10           0.9483            0.17s\n","        11           0.9292            0.17s\n","        12           0.9127            0.16s\n","        13           0.8991            0.16s\n","        14           0.8847            0.16s\n","        15           0.8718            0.17s\n","        16           0.8574            0.17s\n","        17           0.8480            0.16s\n","        18           0.8365            0.16s\n","        19           0.8248            0.16s\n","        20           0.8169            0.16s\n","        21           0.8076            0.16s\n","        22           0.7994            0.16s\n","        23           0.7903            0.16s\n","        24           0.7818            0.15s\n","        25           0.7738            0.15s\n","        26           0.7654            0.15s\n","        27           0.7586            0.15s\n","        28           0.7517            0.14s\n","        29           0.7462            0.14s\n","        30           0.7386            0.14s\n","        31           0.7331            0.14s\n","        32           0.7270            0.14s\n","        33           0.7223            0.13s\n","        34           0.7167            0.13s\n","        35           0.7103            0.13s\n","        36           0.7047            0.13s\n","        37           0.7002            0.12s\n","        38           0.6949            0.12s\n","        39           0.6900            0.12s\n","        40           0.6874            0.12s\n","        41           0.6827            0.12s\n","        42           0.6773            0.11s\n","        43           0.6740            0.11s\n","        44           0.6702            0.11s\n","        45           0.6654            0.11s\n","        46           0.6618            0.11s\n","        47           0.6568            0.10s\n","        48           0.6523            0.10s\n","        49           0.6481            0.10s\n","        50           0.6459            0.10s\n","        51           0.6433            0.10s\n","        52           0.6383            0.09s\n","        53           0.6330            0.09s\n","        54           0.6224            0.09s\n","        55           0.6187            0.09s\n","        56           0.6134            0.09s\n","        57           0.6111            0.08s\n","        58           0.6084            0.08s\n","        59           0.6033            0.08s\n","        60           0.5965            0.08s\n","        61           0.5942            0.08s\n","        62           0.5887            0.07s\n","        63           0.5844            0.07s\n","        64           0.5812            0.07s\n","        65           0.5762            0.07s\n","        66           0.5724            0.07s\n","        67           0.5700            0.06s\n","        68           0.5661            0.06s\n","        69           0.5639            0.06s\n","        70           0.5587            0.06s\n","        71           0.5554            0.06s\n","        72           0.5511            0.06s\n","        73           0.5484            0.05s\n","        74           0.5467            0.05s\n","        75           0.5437            0.05s\n","        76           0.5408            0.05s\n","        77           0.5371            0.05s\n","        78           0.5353            0.04s\n","        79           0.5300            0.04s\n","        80           0.5262            0.04s\n","        81           0.5247            0.04s\n","        82           0.5215            0.04s\n","        83           0.5181            0.03s\n","        84           0.5157            0.03s\n","        85           0.5119            0.03s\n","        86           0.5076            0.03s\n","        87           0.5046            0.03s\n","        88           0.5017            0.02s\n","        89           0.4994            0.02s\n","        90           0.4979            0.02s\n","        91           0.4966            0.02s\n","        92           0.4949            0.02s\n","        93           0.4914            0.01s\n","        94           0.4874            0.01s\n","        95           0.4846            0.01s\n","        96           0.4821            0.01s\n","        97           0.4777            0.01s\n","        98           0.4755            0.00s\n","        99           0.4731            0.00s\n","       100           0.4692            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2156            0.18s\n","         2           1.1603            0.18s\n","         3           1.1155            0.18s\n","         4           1.0770            0.18s\n","         5           1.0448            0.18s\n","         6           1.0147            0.18s\n","         7           0.9892            0.17s\n","         8           0.9657            0.17s\n","         9           0.9454            0.17s\n","        10           0.9272            0.17s\n","        11           0.9084            0.17s\n","        12           0.8931            0.17s\n","        13           0.8799            0.16s\n","        14           0.8659            0.16s\n","        15           0.8526            0.16s\n","        16           0.8397            0.16s\n","        17           0.8293            0.15s\n","        18           0.8177            0.15s\n","        19           0.8096            0.15s\n","        20           0.8015            0.15s\n","        21           0.7921            0.15s\n","        22           0.7825            0.15s\n","        23           0.7753            0.14s\n","        24           0.7676            0.14s\n","        25           0.7605            0.14s\n","        26           0.7535            0.14s\n","        27           0.7455            0.14s\n","        28           0.7389            0.13s\n","        29           0.7326            0.13s\n","        30           0.7271            0.13s\n","        31           0.7210            0.13s\n","        32           0.7119            0.13s\n","        33           0.7069            0.13s\n","        34           0.7020            0.12s\n","        35           0.6959            0.12s\n","        36           0.6891            0.12s\n","        37           0.6860            0.12s\n","        38           0.6821            0.12s\n","        39           0.6780            0.11s\n","        40           0.6717            0.11s\n","        41           0.6677            0.11s\n","        42           0.6654            0.11s\n","        43           0.6602            0.11s\n","        44           0.6545            0.10s\n","        45           0.6512            0.10s\n","        46           0.6477            0.10s\n","        47           0.6456            0.10s\n","        48           0.6418            0.10s\n","        49           0.6354            0.10s\n","        50           0.6326            0.09s\n","        51           0.6276            0.09s\n","        52           0.6254            0.09s\n","        53           0.6210            0.09s\n","        54           0.6185            0.09s\n","        55           0.6144            0.08s\n","        56           0.6103            0.08s\n","        57           0.6069            0.08s\n","        58           0.6016            0.08s\n","        59           0.5997            0.08s\n","        60           0.5954            0.07s\n","        61           0.5927            0.07s\n","        62           0.5892            0.07s\n","        63           0.5851            0.07s\n","        64           0.5828            0.07s\n","        65           0.5778            0.07s\n","        66           0.5760            0.06s\n","        67           0.5729            0.06s\n","        68           0.5700            0.06s\n","        69           0.5651            0.06s\n","        70           0.5617            0.06s\n","        71           0.5596            0.05s\n","        72           0.5584            0.05s\n","        73           0.5552            0.05s\n","        74           0.5511            0.05s\n","        75           0.5455            0.05s\n","        76           0.5435            0.05s\n","        77           0.5401            0.04s\n","        78           0.5385            0.04s\n","        79           0.5314            0.04s\n","        80           0.5289            0.04s\n","        81           0.5275            0.04s\n","        82           0.5219            0.03s\n","        83           0.5178            0.03s\n","        84           0.5151            0.03s\n","        85           0.5138            0.03s\n","        86           0.5121            0.03s\n","        87           0.5093            0.02s\n","        88           0.5063            0.02s\n","        89           0.5043            0.02s\n","        90           0.5004            0.02s\n","        91           0.4969            0.02s\n","        92           0.4929            0.02s\n","        93           0.4908            0.01s\n","        94           0.4889            0.01s\n","        95           0.4862            0.01s\n","        96           0.4846            0.01s\n","        97           0.4828            0.01s\n","        98           0.4807            0.00s\n","        99           0.4785            0.00s\n","       100           0.4750            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.2287            0.18s\n","         2           1.1773            0.19s\n","         3           1.1361            0.19s\n","         4           1.1007            0.19s\n","         5           1.0665            0.18s\n","         6           1.0393            0.18s\n","         7           1.0140            0.18s\n","         8           0.9903            0.18s\n","         9           0.9685            0.17s\n","        10           0.9491            0.17s\n","        11           0.9325            0.17s\n","        12           0.9161            0.17s\n","        13           0.9011            0.17s\n","        14           0.8884            0.16s\n","        15           0.8762            0.16s\n","        16           0.8664            0.16s\n","        17           0.8554            0.16s\n","        18           0.8456            0.16s\n","        19           0.8335            0.15s\n","        20           0.8239            0.15s\n","        21           0.8158            0.15s\n","        22           0.8075            0.15s\n","        23           0.7986            0.15s\n","        24           0.7925            0.14s\n","        25           0.7844            0.14s\n","        26           0.7766            0.14s\n","        27           0.7703            0.14s\n","        28           0.7639            0.14s\n","        29           0.7569            0.13s\n","        30           0.7511            0.13s\n","        31           0.7471            0.13s\n","        32           0.7411            0.13s\n","        33           0.7372            0.13s\n","        34           0.7322            0.12s\n","        35           0.7257            0.12s\n","        36           0.7226            0.12s\n","        37           0.7165            0.12s\n","        38           0.7132            0.12s\n","        39           0.7111            0.12s\n","        40           0.7080            0.11s\n","        41           0.7007            0.11s\n","        42           0.6979            0.11s\n","        43           0.6926            0.11s\n","        44           0.6879            0.11s\n","        45           0.6833            0.10s\n","        46           0.6777            0.10s\n","        47           0.6737            0.10s\n","        48           0.6695            0.10s\n","        49           0.6662            0.10s\n","        50           0.6636            0.09s\n","        51           0.6587            0.09s\n","        52           0.6546            0.09s\n","        53           0.6497            0.09s\n","        54           0.6470            0.09s\n","        55           0.6439            0.09s\n","        56           0.6400            0.08s\n","        57           0.6357            0.08s\n","        58           0.6324            0.08s\n","        59           0.6269            0.08s\n","        60           0.6237            0.08s\n","        61           0.6210            0.07s\n","        62           0.6190            0.07s\n","        63           0.6137            0.07s\n","        64           0.6121            0.07s\n","        65           0.6098            0.07s\n","        66           0.6056            0.06s\n","        67           0.6013            0.06s\n","        68           0.5988            0.06s\n","        69           0.5953            0.06s\n","        70           0.5922            0.06s\n","        71           0.5883            0.06s\n","        72           0.5865            0.05s\n","        73           0.5847            0.05s\n","        74           0.5819            0.05s\n","        75           0.5801            0.05s\n","        76           0.5759            0.05s\n","        77           0.5730            0.04s\n","        78           0.5717            0.04s\n","        79           0.5682            0.04s\n","        80           0.5667            0.04s\n","        81           0.5642            0.04s\n","        82           0.5596            0.03s\n","        83           0.5564            0.03s\n","        84           0.5503            0.03s\n","        85           0.5483            0.03s\n","        86           0.5468            0.03s\n","        87           0.5434            0.02s\n","        88           0.5420            0.02s\n","        89           0.5382            0.02s\n","        90           0.5352            0.02s\n","        91           0.5335            0.02s\n","        92           0.5301            0.02s\n","        93           0.5291            0.01s\n","        94           0.5249            0.01s\n","        95           0.5237            0.01s\n","        96           0.5226            0.01s\n","        97           0.5211            0.01s\n","        98           0.5181            0.00s\n","        99           0.5168            0.00s\n","       100           0.5127            0.00s\n","     Unnamed: 0    SEEDED    TE    TW    NC    SC   NWC  binaryClass\n","0             0  0.306122  1.69  3.73  1.65  1.80  3.33            0\n","1             1  0.295455  0.74  0.78  1.09  0.79  1.59            0\n","2             2  0.276596  0.81  0.86  2.39  0.36  2.06            0\n","3             3  0.291667  1.44  2.01  2.96  1.27  4.05            0\n","4             4  0.291667  2.48  4.61  4.16  2.16  6.00            0\n","..          ...       ...   ...   ...   ...   ...   ...          ...\n","103         103  0.295455  1.36  3.43  1.38  1.86  2.91            1\n","104         104  0.291667  1.17  1.65  1.22  2.28  1.58            1\n","105         105  0.295455  2.37  1.94  2.46  2.47  2.39            1\n","106         106  0.291667  0.02  0.08  0.05  0.02  0.09            1\n","107         107  0.265306  0.92  2.09  0.61  0.87  1.35            1\n","\n","[108 rows x 8 columns]\n","      Iter       Train Loss   Remaining Time \n","         1           1.1369            0.06s\n","         2           1.0700            0.07s\n","         3           1.0181            0.07s\n","         4           0.9731            0.07s\n","         5           0.8986            0.07s\n","         6           0.8398            0.07s\n","         7           0.8066            0.07s\n","         8           0.7613            0.07s\n","         9           0.7384            0.07s\n","        10           0.7097            0.07s\n","        11           0.6855            0.07s\n","        12           0.6528            0.07s\n","        13           0.6207            0.07s\n","        14           0.5825            0.07s\n","        15           0.5621            0.07s\n","        16           0.5446            0.07s\n","        17           0.5140            0.07s\n","        18           0.4917            0.07s\n","        19           0.4746            0.07s\n","        20           0.4507            0.07s\n","        21           0.4363            0.07s\n","        22           0.4231            0.06s\n","        23           0.4084            0.06s\n","        24           0.3920            0.06s\n","        25           0.3751            0.06s\n","        26           0.3616            0.06s\n","        27           0.3485            0.06s\n","        28           0.3378            0.06s\n","        29           0.3263            0.06s\n","        30           0.3162            0.06s\n","        31           0.2965            0.06s\n","        32           0.2861            0.06s\n","        33           0.2779            0.06s\n","        34           0.2697            0.06s\n","        35           0.2553            0.05s\n","        36           0.2469            0.05s\n","        37           0.2397            0.05s\n","        38           0.2292            0.05s\n","        39           0.2228            0.05s\n","        40           0.2124            0.05s\n","        41           0.2056            0.05s\n","        42           0.2018            0.05s\n","        43           0.1913            0.05s\n","        44           0.1858            0.05s\n","        45           0.1807            0.05s\n","        46           0.1733            0.05s\n","        47           0.1679            0.05s\n","        48           0.1631            0.04s\n","        49           0.1549            0.04s\n","        50           0.1507            0.04s\n","        51           0.1436            0.04s\n","        52           0.1379            0.04s\n","        53           0.1344            0.04s\n","        54           0.1274            0.04s\n","        55           0.1239            0.04s\n","        56           0.1179            0.04s\n","        57           0.1147            0.04s\n","        58           0.1117            0.04s\n","        59           0.1065            0.03s\n","        60           0.1038            0.03s\n","        61           0.0993            0.03s\n","        62           0.0969            0.03s\n","        63           0.0926            0.03s\n","        64           0.0878            0.03s\n","        65           0.0857            0.03s\n","        66           0.0821            0.03s\n","        67           0.0802            0.03s\n","        68           0.0759            0.03s\n","        69           0.0743            0.03s\n","        70           0.0711            0.03s\n","        71           0.0696            0.02s\n","        72           0.0668            0.02s\n","        73           0.0633            0.02s\n","        74           0.0620            0.02s\n","        75           0.0602            0.02s\n","        76           0.0573            0.02s\n","        77           0.0557            0.02s\n","        78           0.0529            0.02s\n","        79           0.0517            0.02s\n","        80           0.0492            0.02s\n","        81           0.0478            0.02s\n","        82           0.0469            0.02s\n","        83           0.0444            0.01s\n","        84           0.0433            0.01s\n","        85           0.0411            0.01s\n","        86           0.0402            0.01s\n","        87           0.0386            0.01s\n","        88           0.0369            0.01s\n","        89           0.0361            0.01s\n","        90           0.0343            0.01s\n","        91           0.0338            0.01s\n","        92           0.0328            0.01s\n","        93           0.0312            0.01s\n","        94           0.0303            0.01s\n","        95           0.0297            0.00s\n","        96           0.0283            0.00s\n","        97           0.0275            0.00s\n","        98           0.0261            0.00s\n","        99           0.0254            0.00s\n","       100           0.0242            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1210            0.07s\n","         2           1.0609            0.07s\n","         3           0.9852            0.07s\n","         4           0.9271            0.07s\n","         5           0.8870            0.07s\n","         6           0.8422            0.07s\n","         7           0.8106            0.07s\n","         8           0.7752            0.07s\n","         9           0.7497            0.07s\n","        10           0.7170            0.07s\n","        11           0.6573            0.07s\n","        12           0.6366            0.07s\n","        13           0.6002            0.07s\n","        14           0.5764            0.07s\n","        15           0.5384            0.07s\n","        16           0.5216            0.07s\n","        17           0.4965            0.07s\n","        18           0.4785            0.07s\n","        19           0.4527            0.07s\n","        20           0.4387            0.07s\n","        21           0.4205            0.07s\n","        22           0.4062            0.06s\n","        23           0.3860            0.06s\n","        24           0.3681            0.06s\n","        25           0.3579            0.06s\n","        26           0.3399            0.06s\n","        27           0.3286            0.06s\n","        28           0.3191            0.06s\n","        29           0.3040            0.06s\n","        30           0.2952            0.06s\n","        31           0.2819            0.06s\n","        32           0.2726            0.06s\n","        33           0.2611            0.06s\n","        34           0.2497            0.06s\n","        35           0.2427            0.06s\n","        36           0.2296            0.06s\n","        37           0.2223            0.06s\n","        38           0.2123            0.05s\n","        39           0.2065            0.05s\n","        40           0.1976            0.05s\n","        41           0.1913            0.05s\n","        42           0.1838            0.05s\n","        43           0.1803            0.05s\n","        44           0.1713            0.05s\n","        45           0.1669            0.05s\n","        46           0.1593            0.05s\n","        47           0.1544            0.05s\n","        48           0.1476            0.05s\n","        49           0.1438            0.05s\n","        50           0.1378            0.04s\n","        51           0.1334            0.04s\n","        52           0.1280            0.04s\n","        53           0.1246            0.04s\n","        54           0.1181            0.04s\n","        55           0.1152            0.04s\n","        56           0.1104            0.04s\n","        57           0.1069            0.04s\n","        58           0.1026            0.04s\n","        59           0.0985            0.04s\n","        60           0.0960            0.04s\n","        61           0.0912            0.03s\n","        62           0.0884            0.03s\n","        63           0.0847            0.03s\n","        64           0.0826            0.03s\n","        65           0.0792            0.03s\n","        66           0.0766            0.03s\n","        67           0.0742            0.03s\n","        68           0.0725            0.03s\n","        69           0.0707            0.03s\n","        70           0.0687            0.03s\n","        71           0.0653            0.03s\n","        72           0.0634            0.02s\n","        73           0.0616            0.02s\n","        74           0.0587            0.02s\n","        75           0.0573            0.02s\n","        76           0.0557            0.02s\n","        77           0.0534            0.02s\n","        78           0.0519            0.02s\n","        79           0.0499            0.02s\n","        80           0.0485            0.02s\n","        81           0.0462            0.02s\n","        82           0.0454            0.02s\n","        83           0.0432            0.02s\n","        84           0.0421            0.01s\n","        85           0.0402            0.01s\n","        86           0.0389            0.01s\n","        87           0.0379            0.01s\n","        88           0.0361            0.01s\n","        89           0.0351            0.01s\n","        90           0.0343            0.01s\n","        91           0.0327            0.01s\n","        92           0.0320            0.01s\n","        93           0.0307            0.01s\n","        94           0.0300            0.01s\n","        95           0.0285            0.00s\n","        96           0.0278            0.00s\n","        97           0.0270            0.00s\n","        98           0.0264            0.00s\n","        99           0.0250            0.00s\n","       100           0.0243            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1302            0.08s\n","         2           1.0621            0.07s\n","         3           1.0145            0.07s\n","         4           0.9470            0.08s\n","         5           0.9116            0.07s\n","         6           0.8618            0.07s\n","         7           0.8235            0.07s\n","         8           0.7908            0.07s\n","         9           0.7420            0.07s\n","        10           0.7081            0.07s\n","        11           0.6716            0.07s\n","        12           0.6448            0.07s\n","        13           0.6042            0.07s\n","        14           0.5820            0.07s\n","        15           0.5586            0.07s\n","        16           0.5297            0.07s\n","        17           0.5051            0.07s\n","        18           0.4895            0.07s\n","        19           0.4712            0.07s\n","        20           0.4552            0.07s\n","        21           0.4478            0.07s\n","        22           0.4322            0.07s\n","        23           0.4042            0.06s\n","        24           0.3912            0.06s\n","        25           0.3767            0.06s\n","        26           0.3644            0.06s\n","        27           0.3532            0.06s\n","        28           0.3321            0.06s\n","        29           0.3211            0.06s\n","        30           0.3100            0.06s\n","        31           0.3012            0.06s\n","        32           0.2872            0.06s\n","        33           0.2803            0.06s\n","        34           0.2758            0.06s\n","        35           0.2690            0.06s\n","        36           0.2591            0.05s\n","        37           0.2512            0.05s\n","        38           0.2461            0.05s\n","        39           0.2340            0.05s\n","        40           0.2287            0.05s\n","        41           0.2156            0.05s\n","        42           0.2115            0.05s\n","        43           0.2032            0.05s\n","        44           0.1913            0.05s\n","        45           0.1871            0.05s\n","        46           0.1787            0.05s\n","        47           0.1758            0.05s\n","        48           0.1710            0.05s\n","        49           0.1658            0.04s\n","        50           0.1564            0.04s\n","        51           0.1530            0.04s\n","        52           0.1486            0.04s\n","        53           0.1406            0.04s\n","        54           0.1362            0.04s\n","        55           0.1311            0.04s\n","        56           0.1274            0.04s\n","        57           0.1247            0.04s\n","        58           0.1179            0.04s\n","        59           0.1143            0.04s\n","        60           0.1118            0.04s\n","        61           0.1061            0.03s\n","        62           0.1031            0.03s\n","        63           0.0980            0.03s\n","        64           0.0952            0.03s\n","        65           0.0906            0.03s\n","        66           0.0888            0.03s\n","        67           0.0842            0.03s\n","        68           0.0823            0.03s\n","        69           0.0800            0.03s\n","        70           0.0759            0.03s\n","        71           0.0736            0.03s\n","        72           0.0722            0.02s\n","        73           0.0703            0.02s\n","        74           0.0687            0.02s\n","        75           0.0652            0.02s\n","        76           0.0629            0.02s\n","        77           0.0618            0.02s\n","        78           0.0586            0.02s\n","        79           0.0570            0.02s\n","        80           0.0542            0.02s\n","        81           0.0526            0.02s\n","        82           0.0513            0.02s\n","        83           0.0500            0.01s\n","        84           0.0488            0.01s\n","        85           0.0464            0.01s\n","        86           0.0450            0.01s\n","        87           0.0430            0.01s\n","        88           0.0418            0.01s\n","        89           0.0398            0.01s\n","        90           0.0390            0.01s\n","        91           0.0373            0.01s\n","        92           0.0365            0.01s\n","        93           0.0358            0.01s\n","        94           0.0343            0.01s\n","        95           0.0336            0.00s\n","        96           0.0322            0.00s\n","        97           0.0317            0.00s\n","        98           0.0311            0.00s\n","        99           0.0299            0.00s\n","       100           0.0289            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1212            0.07s\n","         2           1.0591            0.07s\n","         3           1.0028            0.07s\n","         4           0.9345            0.07s\n","         5           0.8942            0.08s\n","         6           0.8522            0.08s\n","         7           0.8164            0.08s\n","         8           0.7697            0.08s\n","         9           0.7215            0.08s\n","        10           0.6904            0.08s\n","        11           0.6547            0.08s\n","        12           0.6291            0.07s\n","        13           0.5882            0.07s\n","        14           0.5656            0.07s\n","        15           0.5318            0.07s\n","        16           0.5137            0.07s\n","        17           0.4850            0.07s\n","        18           0.4713            0.07s\n","        19           0.4412            0.07s\n","        20           0.4278            0.07s\n","        21           0.3957            0.07s\n","        22           0.3856            0.07s\n","        23           0.3626            0.07s\n","        24           0.3523            0.06s\n","        25           0.3269            0.06s\n","        26           0.3191            0.06s\n","        27           0.3012            0.06s\n","        28           0.2930            0.06s\n","        29           0.2739            0.06s\n","        30           0.2595            0.06s\n","        31           0.2528            0.06s\n","        32           0.2410            0.06s\n","        33           0.2261            0.06s\n","        34           0.2167            0.06s\n","        35           0.2117            0.06s\n","        36           0.2015            0.06s\n","        37           0.1965            0.05s\n","        38           0.1838            0.05s\n","        39           0.1753            0.05s\n","        40           0.1715            0.05s\n","        41           0.1679            0.05s\n","        42           0.1575            0.05s\n","        43           0.1504            0.05s\n","        44           0.1467            0.05s\n","        45           0.1383            0.05s\n","        46           0.1337            0.05s\n","        47           0.1260            0.05s\n","        48           0.1216            0.04s\n","        49           0.1166            0.04s\n","        50           0.1139            0.04s\n","        51           0.1094            0.04s\n","        52           0.1070            0.04s\n","        53           0.1018            0.04s\n","        54           0.0992            0.04s\n","        55           0.0946            0.04s\n","        56           0.0922            0.04s\n","        57           0.0880            0.04s\n","        58           0.0858            0.04s\n","        59           0.0820            0.04s\n","        60           0.0802            0.03s\n","        61           0.0783            0.03s\n","        62           0.0744            0.03s\n","        63           0.0711            0.03s\n","        64           0.0690            0.03s\n","        65           0.0661            0.03s\n","        66           0.0633            0.03s\n","        67           0.0616            0.03s\n","        68           0.0595            0.03s\n","        69           0.0580            0.03s\n","        70           0.0546            0.03s\n","        71           0.0522            0.03s\n","        72           0.0511            0.03s\n","        73           0.0488            0.02s\n","        74           0.0466            0.02s\n","        75           0.0455            0.02s\n","        76           0.0431            0.02s\n","        77           0.0412            0.02s\n","        78           0.0402            0.02s\n","        79           0.0384            0.02s\n","        80           0.0368            0.02s\n","        81           0.0359            0.02s\n","        82           0.0350            0.02s\n","        83           0.0344            0.02s\n","        84           0.0328            0.01s\n","        85           0.0319            0.01s\n","        86           0.0306            0.01s\n","        87           0.0298            0.01s\n","        88           0.0282            0.01s\n","        89           0.0276            0.01s\n","        90           0.0265            0.01s\n","        91           0.0257            0.01s\n","        92           0.0246            0.01s\n","        93           0.0242            0.01s\n","        94           0.0232            0.01s\n","        95           0.0220            0.00s\n","        96           0.0214            0.00s\n","        97           0.0206            0.00s\n","        98           0.0197            0.00s\n","        99           0.0189            0.00s\n","       100           0.0184            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1203            0.07s\n","         2           1.0555            0.07s\n","         3           1.0004            0.07s\n","         4           0.9342            0.07s\n","         5           0.8948            0.07s\n","         6           0.8554            0.07s\n","         7           0.8083            0.07s\n","         8           0.7803            0.07s\n","         9           0.7490            0.07s\n","        10           0.7197            0.07s\n","        11           0.6941            0.07s\n","        12           0.6591            0.07s\n","        13           0.6354            0.07s\n","        14           0.5982            0.07s\n","        15           0.5720            0.07s\n","        16           0.5452            0.07s\n","        17           0.5259            0.07s\n","        18           0.5087            0.07s\n","        19           0.4914            0.07s\n","        20           0.4699            0.07s\n","        21           0.4530            0.07s\n","        22           0.4316            0.06s\n","        23           0.4196            0.06s\n","        24           0.3954            0.06s\n","        25           0.3818            0.06s\n","        26           0.3687            0.06s\n","        27           0.3481            0.06s\n","        28           0.3373            0.06s\n","        29           0.3203            0.06s\n","        30           0.3113            0.06s\n","        31           0.2909            0.06s\n","        32           0.2846            0.06s\n","        33           0.2715            0.06s\n","        34           0.2582            0.06s\n","        35           0.2527            0.05s\n","        36           0.2405            0.05s\n","        37           0.2255            0.05s\n","        38           0.2178            0.05s\n","        39           0.2056            0.05s\n","        40           0.1991            0.05s\n","        41           0.1944            0.05s\n","        42           0.1843            0.05s\n","        43           0.1795            0.05s\n","        44           0.1710            0.05s\n","        45           0.1673            0.05s\n","        46           0.1603            0.05s\n","        47           0.1565            0.05s\n","        48           0.1492            0.04s\n","        49           0.1464            0.04s\n","        50           0.1388            0.04s\n","        51           0.1342            0.04s\n","        52           0.1286            0.04s\n","        53           0.1256            0.04s\n","        54           0.1185            0.04s\n","        55           0.1147            0.04s\n","        56           0.1127            0.04s\n","        57           0.1064            0.04s\n","        58           0.1033            0.04s\n","        59           0.1012            0.03s\n","        60           0.0960            0.03s\n","        61           0.0938            0.03s\n","        62           0.0900            0.03s\n","        63           0.0862            0.03s\n","        64           0.0842            0.03s\n","        65           0.0799            0.03s\n","        66           0.0775            0.03s\n","        67           0.0752            0.03s\n","        68           0.0733            0.03s\n","        69           0.0720            0.03s\n","        70           0.0697            0.03s\n","        71           0.0662            0.02s\n","        72           0.0647            0.02s\n","        73           0.0632            0.02s\n","        74           0.0606            0.02s\n","        75           0.0591            0.02s\n","        76           0.0581            0.02s\n","        77           0.0556            0.02s\n","        78           0.0548            0.02s\n","        79           0.0530            0.02s\n","        80           0.0504            0.02s\n","        81           0.0488            0.02s\n","        82           0.0475            0.02s\n","        83           0.0465            0.01s\n","        84           0.0455            0.01s\n","        85           0.0432            0.01s\n","        86           0.0419            0.01s\n","        87           0.0410            0.01s\n","        88           0.0392            0.01s\n","        89           0.0381            0.01s\n","        90           0.0366            0.01s\n","        91           0.0358            0.01s\n","        92           0.0339            0.01s\n","        93           0.0333            0.01s\n","        94           0.0320            0.01s\n","        95           0.0311            0.00s\n","        96           0.0298            0.00s\n","        97           0.0291            0.00s\n","        98           0.0279            0.00s\n","        99           0.0273            0.00s\n","       100           0.0260            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1352            0.08s\n","         2           1.0715            0.08s\n","         3           0.9883            0.08s\n","         4           0.9231            0.08s\n","         5           0.8811            0.07s\n","         6           0.8314            0.07s\n","         7           0.7983            0.07s\n","         8           0.7587            0.08s\n","         9           0.7295            0.09s\n","        10           0.6934            0.09s\n","        11           0.6682            0.08s\n","        12           0.6388            0.08s\n","        13           0.5971            0.09s\n","        14           0.5763            0.09s\n","        15           0.5514            0.09s\n","        16           0.5303            0.08s\n","        17           0.5018            0.08s\n","        18           0.4849            0.08s\n","        19           0.4621            0.08s\n","        20           0.4447            0.08s\n","        21           0.4254            0.08s\n","        22           0.4119            0.08s\n","        23           0.3957            0.07s\n","        24           0.3714            0.07s\n","        25           0.3592            0.07s\n","        26           0.3460            0.07s\n","        27           0.3353            0.07s\n","        28           0.3249            0.07s\n","        29           0.3102            0.07s\n","        30           0.3009            0.07s\n","        31           0.2860            0.06s\n","        32           0.2782            0.06s\n","        33           0.2628            0.06s\n","        34           0.2520            0.06s\n","        35           0.2453            0.06s\n","        36           0.2343            0.06s\n","        37           0.2284            0.06s\n","        38           0.2155            0.06s\n","        39           0.2109            0.06s\n","        40           0.2016            0.06s\n","        41           0.1968            0.05s\n","        42           0.1858            0.05s\n","        43           0.1822            0.05s\n","        44           0.1720            0.05s\n","        45           0.1682            0.05s\n","        46           0.1608            0.05s\n","        47           0.1574            0.05s\n","        48           0.1487            0.05s\n","        49           0.1437            0.05s\n","        50           0.1361            0.05s\n","        51           0.1319            0.05s\n","        52           0.1289            0.05s\n","        53           0.1237            0.04s\n","        54           0.1183            0.04s\n","        55           0.1157            0.04s\n","        56           0.1111            0.04s\n","        57           0.1051            0.04s\n","        58           0.1028            0.04s\n","        59           0.0984            0.04s\n","        60           0.0963            0.04s\n","        61           0.0912            0.04s\n","        62           0.0884            0.04s\n","        63           0.0868            0.04s\n","        64           0.0822            0.03s\n","        65           0.0805            0.03s\n","        66           0.0771            0.03s\n","        67           0.0759            0.03s\n","        68           0.0735            0.03s\n","        69           0.0701            0.03s\n","        70           0.0680            0.03s\n","        71           0.0645            0.03s\n","        72           0.0631            0.03s\n","        73           0.0604            0.03s\n","        74           0.0592            0.02s\n","        75           0.0568            0.02s\n","        76           0.0544            0.02s\n","        77           0.0534            0.02s\n","        78           0.0517            0.02s\n","        79           0.0495            0.02s\n","        80           0.0485            0.02s\n","        81           0.0465            0.02s\n","        82           0.0456            0.02s\n","        83           0.0431            0.02s\n","        84           0.0412            0.02s\n","        85           0.0405            0.01s\n","        86           0.0387            0.01s\n","        87           0.0379            0.01s\n","        88           0.0361            0.01s\n","        89           0.0350            0.01s\n","        90           0.0339            0.01s\n","        91           0.0322            0.01s\n","        92           0.0313            0.01s\n","        93           0.0306            0.01s\n","        94           0.0293            0.01s\n","        95           0.0287            0.00s\n","        96           0.0275            0.00s\n","        97           0.0269            0.00s\n","        98           0.0258            0.00s\n","        99           0.0253            0.00s\n","       100           0.0240            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1290            0.08s\n","         2           1.0413            0.08s\n","         3           0.9929            0.08s\n","         4           0.9287            0.08s\n","         5           0.8920            0.08s\n","         6           0.8606            0.07s\n","         7           0.8129            0.07s\n","         8           0.7882            0.07s\n","         9           0.7657            0.07s\n","        10           0.7199            0.07s\n","        11           0.6913            0.07s\n","        12           0.6526            0.07s\n","        13           0.6236            0.07s\n","        14           0.5922            0.07s\n","        15           0.5719            0.07s\n","        16           0.5484            0.07s\n","        17           0.5251            0.07s\n","        18           0.5030            0.07s\n","        19           0.4919            0.07s\n","        20           0.4742            0.07s\n","        21           0.4588            0.07s\n","        22           0.4341            0.06s\n","        23           0.4214            0.06s\n","        24           0.3938            0.06s\n","        25           0.3805            0.06s\n","        26           0.3699            0.06s\n","        27           0.3514            0.06s\n","        28           0.3435            0.06s\n","        29           0.3229            0.06s\n","        30           0.3147            0.06s\n","        31           0.2992            0.06s\n","        32           0.2864            0.06s\n","        33           0.2809            0.06s\n","        34           0.2682            0.06s\n","        35           0.2624            0.06s\n","        36           0.2562            0.06s\n","        37           0.2409            0.05s\n","        38           0.2330            0.05s\n","        39           0.2199            0.05s\n","        40           0.2145            0.05s\n","        41           0.2049            0.05s\n","        42           0.2008            0.05s\n","        43           0.1899            0.05s\n","        44           0.1855            0.05s\n","        45           0.1780            0.05s\n","        46           0.1735            0.05s\n","        47           0.1659            0.05s\n","        48           0.1622            0.04s\n","        49           0.1531            0.04s\n","        50           0.1503            0.04s\n","        51           0.1420            0.04s\n","        52           0.1376            0.04s\n","        53           0.1345            0.04s\n","        54           0.1287            0.04s\n","        55           0.1253            0.04s\n","        56           0.1199            0.04s\n","        57           0.1171            0.04s\n","        58           0.1146            0.04s\n","        59           0.1099            0.04s\n","        60           0.1074            0.03s\n","        61           0.1031            0.03s\n","        62           0.1002            0.03s\n","        63           0.0963            0.03s\n","        64           0.0927            0.03s\n","        65           0.0891            0.03s\n","        66           0.0870            0.03s\n","        67           0.0837            0.03s\n","        68           0.0819            0.03s\n","        69           0.0790            0.03s\n","        70           0.0776            0.03s\n","        71           0.0755            0.03s\n","        72           0.0735            0.02s\n","        73           0.0697            0.02s\n","        74           0.0662            0.02s\n","        75           0.0635            0.02s\n","        76           0.0604            0.02s\n","        77           0.0578            0.02s\n","        78           0.0551            0.02s\n","        79           0.0522            0.02s\n","        80           0.0499            0.02s\n","        81           0.0478            0.02s\n","        82           0.0458            0.02s\n","        83           0.0432            0.01s\n","        84           0.0419            0.01s\n","        85           0.0398            0.01s\n","        86           0.0381            0.01s\n","        87           0.0369            0.01s\n","        88           0.0352            0.01s\n","        89           0.0338            0.01s\n","        90           0.0329            0.01s\n","        91           0.0314            0.01s\n","        92           0.0300            0.01s\n","        93           0.0287            0.01s\n","        94           0.0274            0.01s\n","        95           0.0262            0.00s\n","        96           0.0251            0.00s\n","        97           0.0238            0.00s\n","        98           0.0229            0.00s\n","        99           0.0218            0.00s\n","       100           0.0209            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1650            0.07s\n","         2           1.0725            0.07s\n","         3           1.0236            0.07s\n","         4           0.9562            0.07s\n","         5           0.9026            0.07s\n","         6           0.8631            0.07s\n","         7           0.8216            0.07s\n","         8           0.7546            0.07s\n","         9           0.7245            0.07s\n","        10           0.6888            0.07s\n","        11           0.6652            0.07s\n","        12           0.6252            0.07s\n","        13           0.5987            0.07s\n","        14           0.5665            0.07s\n","        15           0.5371            0.07s\n","        16           0.5189            0.07s\n","        17           0.4916            0.07s\n","        18           0.4698            0.07s\n","        19           0.4506            0.07s\n","        20           0.4363            0.07s\n","        21           0.4177            0.07s\n","        22           0.3945            0.06s\n","        23           0.3776            0.06s\n","        24           0.3633            0.06s\n","        25           0.3446            0.06s\n","        26           0.3316            0.06s\n","        27           0.3145            0.06s\n","        28           0.3030            0.06s\n","        29           0.2931            0.06s\n","        30           0.2780            0.06s\n","        31           0.2696            0.06s\n","        32           0.2531            0.06s\n","        33           0.2440            0.06s\n","        34           0.2325            0.06s\n","        35           0.2263            0.05s\n","        36           0.2151            0.05s\n","        37           0.2088            0.05s\n","        38           0.1966            0.05s\n","        39           0.1918            0.05s\n","        40           0.1854            0.05s\n","        41           0.1764            0.05s\n","        42           0.1691            0.05s\n","        43           0.1645            0.05s\n","        44           0.1568            0.05s\n","        45           0.1525            0.05s\n","        46           0.1450            0.05s\n","        47           0.1414            0.05s\n","        48           0.1332            0.04s\n","        49           0.1306            0.04s\n","        50           0.1261            0.04s\n","        51           0.1219            0.04s\n","        52           0.1181            0.04s\n","        53           0.1116            0.04s\n","        54           0.1089            0.04s\n","        55           0.1057            0.04s\n","        56           0.0999            0.04s\n","        57           0.0968            0.04s\n","        58           0.0931            0.04s\n","        59           0.0904            0.03s\n","        60           0.0882            0.03s\n","        61           0.0855            0.03s\n","        62           0.0824            0.03s\n","        63           0.0800            0.03s\n","        64           0.0775            0.03s\n","        65           0.0746            0.03s\n","        66           0.0725            0.03s\n","        67           0.0706            0.03s\n","        68           0.0684            0.03s\n","        69           0.0665            0.03s\n","        70           0.0631            0.03s\n","        71           0.0615            0.02s\n","        72           0.0600            0.02s\n","        73           0.0571            0.02s\n","        74           0.0553            0.02s\n","        75           0.0539            0.02s\n","        76           0.0524            0.02s\n","        77           0.0500            0.02s\n","        78           0.0488            0.02s\n","        79           0.0467            0.02s\n","        80           0.0456            0.02s\n","        81           0.0437            0.02s\n","        82           0.0420            0.02s\n","        83           0.0406            0.01s\n","        84           0.0387            0.01s\n","        85           0.0376            0.01s\n","        86           0.0367            0.01s\n","        87           0.0347            0.01s\n","        88           0.0341            0.01s\n","        89           0.0333            0.01s\n","        90           0.0319            0.01s\n","        91           0.0311            0.01s\n","        92           0.0305            0.01s\n","        93           0.0291            0.01s\n","        94           0.0279            0.01s\n","        95           0.0272            0.00s\n","        96           0.0266            0.00s\n","        97           0.0255            0.00s\n","        98           0.0249            0.00s\n","        99           0.0238            0.00s\n","       100           0.0233            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1736            0.07s\n","         2           1.1136            0.07s\n","         3           1.0656            0.08s\n","         4           0.9968            0.08s\n","         5           0.9459            0.08s\n","         6           0.8941            0.08s\n","         7           0.8620            0.07s\n","         8           0.8244            0.07s\n","         9           0.7707            0.07s\n","        10           0.7339            0.07s\n","        11           0.7047            0.07s\n","        12           0.6633            0.07s\n","        13           0.6356            0.08s\n","        14           0.6118            0.07s\n","        15           0.5846            0.08s\n","        16           0.5613            0.08s\n","        17           0.5386            0.08s\n","        18           0.5200            0.08s\n","        19           0.5023            0.07s\n","        20           0.4904            0.07s\n","        21           0.4569            0.07s\n","        22           0.4401            0.07s\n","        23           0.4268            0.07s\n","        24           0.4089            0.07s\n","        25           0.3955            0.07s\n","        26           0.3772            0.07s\n","        27           0.3655            0.07s\n","        28           0.3458            0.07s\n","        29           0.3361            0.06s\n","        30           0.3170            0.06s\n","        31           0.3068            0.06s\n","        32           0.2913            0.06s\n","        33           0.2832            0.06s\n","        34           0.2708            0.06s\n","        35           0.2636            0.06s\n","        36           0.2478            0.06s\n","        37           0.2372            0.06s\n","        38           0.2311            0.06s\n","        39           0.2207            0.05s\n","        40           0.2155            0.05s\n","        41           0.2080            0.05s\n","        42           0.2039            0.05s\n","        43           0.1921            0.05s\n","        44           0.1864            0.05s\n","        45           0.1764            0.05s\n","        46           0.1705            0.05s\n","        47           0.1664            0.05s\n","        48           0.1590            0.05s\n","        49           0.1559            0.05s\n","        50           0.1475            0.05s\n","        51           0.1442            0.04s\n","        52           0.1378            0.04s\n","        53           0.1355            0.04s\n","        54           0.1282            0.04s\n","        55           0.1240            0.04s\n","        56           0.1206            0.04s\n","        57           0.1181            0.04s\n","        58           0.1156            0.04s\n","        59           0.1095            0.04s\n","        60           0.1061            0.04s\n","        61           0.1014            0.04s\n","        62           0.0992            0.04s\n","        63           0.0949            0.03s\n","        64           0.0922            0.03s\n","        65           0.0903            0.03s\n","        66           0.0874            0.03s\n","        67           0.0855            0.03s\n","        68           0.0830            0.03s\n","        69           0.0803            0.03s\n","        70           0.0761            0.03s\n","        71           0.0738            0.03s\n","        72           0.0722            0.03s\n","        73           0.0691            0.03s\n","        74           0.0676            0.02s\n","        75           0.0642            0.02s\n","        76           0.0624            0.02s\n","        77           0.0592            0.02s\n","        78           0.0579            0.02s\n","        79           0.0563            0.02s\n","        80           0.0539            0.02s\n","        81           0.0530            0.02s\n","        82           0.0506            0.02s\n","        83           0.0492            0.02s\n","        84           0.0481            0.01s\n","        85           0.0470            0.01s\n","        86           0.0446            0.01s\n","        87           0.0434            0.01s\n","        88           0.0420            0.01s\n","        89           0.0407            0.01s\n","        90           0.0390            0.01s\n","        91           0.0382            0.01s\n","        92           0.0362            0.01s\n","        93           0.0351            0.01s\n","        94           0.0344            0.01s\n","        95           0.0326            0.00s\n","        96           0.0317            0.00s\n","        97           0.0301            0.00s\n","        98           0.0296            0.00s\n","        99           0.0283            0.00s\n","       100           0.0275            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1128            0.07s\n","         2           1.0489            0.07s\n","         3           0.9799            0.08s\n","         4           0.9352            0.08s\n","         5           0.8986            0.07s\n","         6           0.8492            0.07s\n","         7           0.8158            0.07s\n","         8           0.7765            0.07s\n","         9           0.7515            0.07s\n","        10           0.7227            0.07s\n","        11           0.6804            0.07s\n","        12           0.6510            0.07s\n","        13           0.6204            0.07s\n","        14           0.5968            0.07s\n","        15           0.5761            0.07s\n","        16           0.5449            0.07s\n","        17           0.5233            0.07s\n","        18           0.5039            0.07s\n","        19           0.4856            0.07s\n","        20           0.4675            0.07s\n","        21           0.4440            0.06s\n","        22           0.4290            0.06s\n","        23           0.4138            0.06s\n","        24           0.3928            0.06s\n","        25           0.3804            0.06s\n","        26           0.3615            0.06s\n","        27           0.3511            0.06s\n","        28           0.3353            0.06s\n","        29           0.3266            0.06s\n","        30           0.3065            0.06s\n","        31           0.2994            0.06s\n","        32           0.2816            0.06s\n","        33           0.2753            0.06s\n","        34           0.2631            0.06s\n","        35           0.2567            0.05s\n","        36           0.2416            0.05s\n","        37           0.2367            0.05s\n","        38           0.2298            0.05s\n","        39           0.2248            0.05s\n","        40           0.2144            0.05s\n","        41           0.2023            0.05s\n","        42           0.1984            0.05s\n","        43           0.1870            0.05s\n","        44           0.1810            0.05s\n","        45           0.1769            0.05s\n","        46           0.1696            0.05s\n","        47           0.1664            0.04s\n","        48           0.1629            0.04s\n","        49           0.1555            0.04s\n","        50           0.1506            0.04s\n","        51           0.1471            0.04s\n","        52           0.1391            0.04s\n","        53           0.1348            0.04s\n","        54           0.1319            0.04s\n","        55           0.1260            0.04s\n","        56           0.1233            0.04s\n","        57           0.1178            0.04s\n","        58           0.1146            0.04s\n","        59           0.1096            0.03s\n","        60           0.1076            0.03s\n","        61           0.1031            0.03s\n","        62           0.1008            0.03s\n","        63           0.0968            0.03s\n","        64           0.0931            0.03s\n","        65           0.0895            0.03s\n","        66           0.0875            0.03s\n","        67           0.0836            0.03s\n","        68           0.0818            0.03s\n","        69           0.0773            0.03s\n","        70           0.0755            0.03s\n","        71           0.0738            0.02s\n","        72           0.0707            0.02s\n","        73           0.0682            0.02s\n","        74           0.0645            0.02s\n","        75           0.0632            0.02s\n","        76           0.0599            0.02s\n","        77           0.0582            0.02s\n","        78           0.0557            0.02s\n","        79           0.0545            0.02s\n","        80           0.0521            0.02s\n","        81           0.0506            0.02s\n","        82           0.0489            0.02s\n","        83           0.0469            0.01s\n","        84           0.0459            0.01s\n","        85           0.0441            0.01s\n","        86           0.0429            0.01s\n","        87           0.0420            0.01s\n","        88           0.0398            0.01s\n","        89           0.0390            0.01s\n","        90           0.0379            0.01s\n","        91           0.0363            0.01s\n","        92           0.0351            0.01s\n","        93           0.0336            0.01s\n","        94           0.0328            0.01s\n","        95           0.0311            0.00s\n","        96           0.0305            0.00s\n","        97           0.0292            0.00s\n","        98           0.0277            0.00s\n","        99           0.0268            0.00s\n","       100           0.0260            0.00s\n","     Unnamed: 0  LOW  AGE  LWT  RACE  SMOKE  PTL  HT  UI  FTV  binaryClass\n","0             0    0   19  182     2      0    0   0   1    0            1\n","1             1    0   33  155     3      0    0   0   0    3            1\n","2             2    0   20  105     1      1    0   0   0    1            1\n","3             3    0   21  108     1      1    0   0   1    2            1\n","4             4    0   18  107     1      1    0   0   1    0            1\n","..          ...  ...  ...  ...   ...    ...  ...  ..  ..  ...          ...\n","184         184    1   28   95     1      1    0   0   0    2            1\n","185         185    1   14  100     3      0    0   0   0    2            1\n","186         186    1   23   94     3      1    0   0   0    0            1\n","187         187    1   17  142     2      0    0   1   0    0            1\n","188         188    1   21  130     1      1    0   1   0    3            1\n","\n","[189 rows x 11 columns]\n","      Iter       Train Loss   Remaining Time \n","         1           1.1941            0.06s\n","         2           1.0386            0.07s\n","         3           0.9090            0.06s\n","         4           0.7995            0.07s\n","         5           0.7059            0.07s\n","         6           0.6254            0.07s\n","         7           0.5555            0.07s\n","         8           0.4946            0.06s\n","         9           0.4412            0.06s\n","        10           0.3942            0.06s\n","        11           0.3528            0.06s\n","        12           0.3160            0.06s\n","        13           0.2835            0.06s\n","        14           0.2545            0.06s\n","        15           0.2287            0.06s\n","        16           0.2056            0.06s\n","        17           0.1850            0.06s\n","        18           0.1666            0.06s\n","        19           0.1500            0.06s\n","        20           0.1352            0.06s\n","        21           0.1219            0.05s\n","        22           0.1099            0.05s\n","        23           0.0992            0.05s\n","        24           0.0895            0.05s\n","        25           0.0808            0.05s\n","        26           0.0729            0.05s\n","        27           0.0659            0.05s\n","        28           0.0595            0.05s\n","        29           0.0538            0.05s\n","        30           0.0486            0.05s\n","        31           0.0439            0.05s\n","        32           0.0397            0.05s\n","        33           0.0359            0.05s\n","        34           0.0324            0.05s\n","        35           0.0293            0.05s\n","        36           0.0265            0.05s\n","        37           0.0240            0.05s\n","        38           0.0217            0.05s\n","        39           0.0196            0.04s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0119            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0044            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1895            0.07s\n","         2           1.0343            0.07s\n","         3           0.9051            0.07s\n","         4           0.7959            0.07s\n","         5           0.7027            0.07s\n","         6           0.6225            0.07s\n","         7           0.5529            0.07s\n","         8           0.4923            0.06s\n","         9           0.4391            0.06s\n","        10           0.3924            0.06s\n","        11           0.3511            0.06s\n","        12           0.3146            0.06s\n","        13           0.2821            0.06s\n","        14           0.2533            0.06s\n","        15           0.2276            0.06s\n","        16           0.2046            0.06s\n","        17           0.1841            0.06s\n","        18           0.1658            0.06s\n","        19           0.1493            0.06s\n","        20           0.1346            0.06s\n","        21           0.1213            0.06s\n","        22           0.1094            0.06s\n","        23           0.0987            0.06s\n","        24           0.0891            0.05s\n","        25           0.0804            0.05s\n","        26           0.0726            0.05s\n","        27           0.0656            0.05s\n","        28           0.0592            0.05s\n","        29           0.0535            0.05s\n","        30           0.0483            0.05s\n","        31           0.0437            0.05s\n","        32           0.0395            0.05s\n","        33           0.0357            0.05s\n","        34           0.0323            0.05s\n","        35           0.0292            0.05s\n","        36           0.0264            0.05s\n","        37           0.0238            0.04s\n","        38           0.0216            0.04s\n","        39           0.0195            0.04s\n","        40           0.0176            0.04s\n","        41           0.0159            0.04s\n","        42           0.0144            0.04s\n","        43           0.0130            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0087            0.04s\n","        48           0.0079            0.04s\n","        49           0.0071            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.03s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0043            0.03s\n","        55           0.0039            0.03s\n","        56           0.0035            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0019            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.02s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.00s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1961            0.07s\n","         2           1.0405            0.07s\n","         3           0.9108            0.07s\n","         4           0.8011            0.07s\n","         5           0.7074            0.07s\n","         6           0.6267            0.07s\n","         7           0.5567            0.06s\n","         8           0.4956            0.06s\n","         9           0.4421            0.06s\n","        10           0.3951            0.06s\n","        11           0.3535            0.06s\n","        12           0.3167            0.06s\n","        13           0.2841            0.06s\n","        14           0.2550            0.06s\n","        15           0.2292            0.06s\n","        16           0.2061            0.06s\n","        17           0.1854            0.06s\n","        18           0.1669            0.06s\n","        19           0.1504            0.06s\n","        20           0.1355            0.05s\n","        21           0.1222            0.05s\n","        22           0.1102            0.05s\n","        23           0.0994            0.05s\n","        24           0.0897            0.05s\n","        25           0.0810            0.05s\n","        26           0.0731            0.05s\n","        27           0.0660            0.05s\n","        28           0.0596            0.05s\n","        29           0.0539            0.05s\n","        30           0.0487            0.05s\n","        31           0.0440            0.05s\n","        32           0.0398            0.05s\n","        33           0.0359            0.05s\n","        34           0.0325            0.05s\n","        35           0.0294            0.05s\n","        36           0.0266            0.04s\n","        37           0.0240            0.04s\n","        38           0.0217            0.04s\n","        39           0.0196            0.04s\n","        40           0.0178            0.04s\n","        41           0.0161            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0119            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0080            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.03s\n","        51           0.0059            0.03s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0044            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0015            0.02s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.00s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1950            0.06s\n","         2           1.0395            0.06s\n","         3           0.9098            0.06s\n","         4           0.8002            0.06s\n","         5           0.7066            0.06s\n","         6           0.6260            0.06s\n","         7           0.5561            0.06s\n","         8           0.4951            0.06s\n","         9           0.4416            0.06s\n","        10           0.3946            0.06s\n","        11           0.3531            0.06s\n","        12           0.3164            0.06s\n","        13           0.2838            0.06s\n","        14           0.2547            0.06s\n","        15           0.2289            0.06s\n","        16           0.2058            0.06s\n","        17           0.1852            0.07s\n","        18           0.1667            0.06s\n","        19           0.1502            0.06s\n","        20           0.1353            0.06s\n","        21           0.1220            0.06s\n","        22           0.1100            0.06s\n","        23           0.0993            0.06s\n","        24           0.0896            0.06s\n","        25           0.0809            0.06s\n","        26           0.0730            0.06s\n","        27           0.0659            0.05s\n","        28           0.0596            0.05s\n","        29           0.0538            0.05s\n","        30           0.0486            0.05s\n","        31           0.0439            0.05s\n","        32           0.0397            0.05s\n","        33           0.0359            0.05s\n","        34           0.0324            0.05s\n","        35           0.0293            0.05s\n","        36           0.0265            0.05s\n","        37           0.0240            0.05s\n","        38           0.0217            0.05s\n","        39           0.0196            0.04s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0119            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0044            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.00s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1874            0.08s\n","         2           1.0323            0.08s\n","         3           0.9033            0.07s\n","         4           0.7943            0.07s\n","         5           0.7013            0.07s\n","         6           0.6212            0.07s\n","         7           0.5518            0.07s\n","         8           0.4912            0.07s\n","         9           0.4382            0.07s\n","        10           0.3915            0.07s\n","        11           0.3503            0.07s\n","        12           0.3139            0.07s\n","        13           0.2815            0.07s\n","        14           0.2527            0.07s\n","        15           0.2271            0.07s\n","        16           0.2042            0.06s\n","        17           0.1837            0.06s\n","        18           0.1654            0.06s\n","        19           0.1490            0.06s\n","        20           0.1343            0.06s\n","        21           0.1211            0.06s\n","        22           0.1092            0.06s\n","        23           0.0985            0.06s\n","        24           0.0889            0.06s\n","        25           0.0802            0.06s\n","        26           0.0724            0.06s\n","        27           0.0654            0.06s\n","        28           0.0591            0.05s\n","        29           0.0534            0.05s\n","        30           0.0482            0.05s\n","        31           0.0436            0.05s\n","        32           0.0394            0.05s\n","        33           0.0356            0.05s\n","        34           0.0322            0.05s\n","        35           0.0291            0.05s\n","        36           0.0263            0.05s\n","        37           0.0238            0.05s\n","        38           0.0215            0.05s\n","        39           0.0195            0.04s\n","        40           0.0176            0.04s\n","        41           0.0159            0.04s\n","        42           0.0144            0.04s\n","        43           0.0130            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0096            0.04s\n","        47           0.0087            0.04s\n","        48           0.0079            0.04s\n","        49           0.0071            0.04s\n","        50           0.0065            0.04s\n","        51           0.0058            0.04s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0043            0.03s\n","        55           0.0039            0.03s\n","        56           0.0035            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0021            0.03s\n","        62           0.0019            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.00s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1950            0.06s\n","         2           1.0395            0.06s\n","         3           0.9098            0.06s\n","         4           0.8002            0.07s\n","         5           0.7066            0.07s\n","         6           0.6260            0.07s\n","         7           0.5561            0.07s\n","         8           0.4951            0.06s\n","         9           0.4416            0.06s\n","        10           0.3946            0.06s\n","        11           0.3531            0.06s\n","        12           0.3164            0.06s\n","        13           0.2838            0.06s\n","        14           0.2547            0.06s\n","        15           0.2289            0.06s\n","        16           0.2058            0.06s\n","        17           0.1852            0.06s\n","        18           0.1667            0.06s\n","        19           0.1502            0.06s\n","        20           0.1353            0.06s\n","        21           0.1220            0.06s\n","        22           0.1100            0.05s\n","        23           0.0993            0.05s\n","        24           0.0896            0.05s\n","        25           0.0809            0.05s\n","        26           0.0730            0.05s\n","        27           0.0659            0.05s\n","        28           0.0596            0.05s\n","        29           0.0538            0.05s\n","        30           0.0486            0.05s\n","        31           0.0439            0.05s\n","        32           0.0397            0.05s\n","        33           0.0359            0.05s\n","        34           0.0324            0.05s\n","        35           0.0293            0.04s\n","        36           0.0265            0.04s\n","        37           0.0240            0.04s\n","        38           0.0217            0.04s\n","        39           0.0196            0.04s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0119            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.03s\n","        51           0.0059            0.03s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0044            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.02s\n","        65           0.0014            0.02s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.00s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1928            0.06s\n","         2           1.0374            0.06s\n","         3           0.9079            0.06s\n","         4           0.7985            0.06s\n","         5           0.7051            0.06s\n","         6           0.6246            0.06s\n","         7           0.5548            0.06s\n","         8           0.4940            0.06s\n","         9           0.4406            0.06s\n","        10           0.3937            0.06s\n","        11           0.3523            0.06s\n","        12           0.3156            0.06s\n","        13           0.2831            0.06s\n","        14           0.2542            0.06s\n","        15           0.2284            0.06s\n","        16           0.2053            0.06s\n","        17           0.1848            0.06s\n","        18           0.1663            0.06s\n","        19           0.1498            0.06s\n","        20           0.1350            0.06s\n","        21           0.1217            0.06s\n","        22           0.1098            0.06s\n","        23           0.0991            0.05s\n","        24           0.0894            0.05s\n","        25           0.0807            0.05s\n","        26           0.0729            0.05s\n","        27           0.0658            0.05s\n","        28           0.0594            0.05s\n","        29           0.0537            0.05s\n","        30           0.0485            0.05s\n","        31           0.0438            0.05s\n","        32           0.0396            0.05s\n","        33           0.0358            0.05s\n","        34           0.0324            0.05s\n","        35           0.0293            0.05s\n","        36           0.0265            0.04s\n","        37           0.0239            0.04s\n","        38           0.0216            0.04s\n","        39           0.0196            0.04s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.03s\n","        51           0.0059            0.03s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0043            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.02s\n","        65           0.0014            0.02s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.00s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1928            0.06s\n","         2           1.0374            0.06s\n","         3           0.9079            0.06s\n","         4           0.7985            0.06s\n","         5           0.7051            0.06s\n","         6           0.6246            0.06s\n","         7           0.5548            0.06s\n","         8           0.4940            0.06s\n","         9           0.4406            0.06s\n","        10           0.3937            0.06s\n","        11           0.3523            0.06s\n","        12           0.3156            0.06s\n","        13           0.2831            0.06s\n","        14           0.2542            0.06s\n","        15           0.2284            0.06s\n","        16           0.2053            0.06s\n","        17           0.1848            0.06s\n","        18           0.1663            0.06s\n","        19           0.1498            0.06s\n","        20           0.1350            0.05s\n","        21           0.1217            0.05s\n","        22           0.1098            0.05s\n","        23           0.0991            0.05s\n","        24           0.0894            0.05s\n","        25           0.0807            0.05s\n","        26           0.0729            0.05s\n","        27           0.0658            0.05s\n","        28           0.0594            0.05s\n","        29           0.0537            0.05s\n","        30           0.0485            0.05s\n","        31           0.0438            0.05s\n","        32           0.0396            0.05s\n","        33           0.0358            0.05s\n","        34           0.0324            0.05s\n","        35           0.0293            0.04s\n","        36           0.0265            0.04s\n","        37           0.0239            0.04s\n","        38           0.0216            0.04s\n","        39           0.0196            0.04s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.03s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0043            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.03s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.02s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1941            0.07s\n","         2           1.0386            0.07s\n","         3           0.9090            0.07s\n","         4           0.7995            0.07s\n","         5           0.7059            0.07s\n","         6           0.6254            0.07s\n","         7           0.5555            0.06s\n","         8           0.4946            0.06s\n","         9           0.4412            0.06s\n","        10           0.3942            0.06s\n","        11           0.3528            0.06s\n","        12           0.3160            0.06s\n","        13           0.2835            0.06s\n","        14           0.2545            0.06s\n","        15           0.2287            0.06s\n","        16           0.2056            0.06s\n","        17           0.1850            0.06s\n","        18           0.1666            0.06s\n","        19           0.1500            0.06s\n","        20           0.1352            0.06s\n","        21           0.1219            0.05s\n","        22           0.1099            0.05s\n","        23           0.0992            0.05s\n","        24           0.0895            0.05s\n","        25           0.0808            0.05s\n","        26           0.0729            0.05s\n","        27           0.0659            0.05s\n","        28           0.0595            0.06s\n","        29           0.0538            0.05s\n","        30           0.0486            0.05s\n","        31           0.0439            0.05s\n","        32           0.0397            0.05s\n","        33           0.0359            0.05s\n","        34           0.0324            0.05s\n","        35           0.0293            0.05s\n","        36           0.0265            0.05s\n","        37           0.0240            0.05s\n","        38           0.0217            0.05s\n","        39           0.0196            0.05s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0119            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0044            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1954            0.07s\n","         2           1.0399            0.07s\n","         3           0.9102            0.07s\n","         4           0.8005            0.07s\n","         5           0.7069            0.07s\n","         6           0.6262            0.07s\n","         7           0.5563            0.07s\n","         8           0.4953            0.07s\n","         9           0.4418            0.07s\n","        10           0.3948            0.07s\n","        11           0.3533            0.07s\n","        12           0.3165            0.07s\n","        13           0.2839            0.06s\n","        14           0.2548            0.06s\n","        15           0.2290            0.06s\n","        16           0.2059            0.06s\n","        17           0.1853            0.06s\n","        18           0.1668            0.06s\n","        19           0.1502            0.06s\n","        20           0.1354            0.06s\n","        21           0.1221            0.06s\n","        22           0.1101            0.06s\n","        23           0.0993            0.06s\n","        24           0.0896            0.05s\n","        25           0.0809            0.05s\n","        26           0.0731            0.05s\n","        27           0.0660            0.05s\n","        28           0.0596            0.05s\n","        29           0.0538            0.05s\n","        30           0.0486            0.05s\n","        31           0.0440            0.05s\n","        32           0.0397            0.05s\n","        33           0.0359            0.05s\n","        34           0.0325            0.05s\n","        35           0.0293            0.05s\n","        36           0.0265            0.05s\n","        37           0.0240            0.05s\n","        38           0.0217            0.04s\n","        39           0.0196            0.04s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0119            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0080            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.03s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0044            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.02s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0007            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.00s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","     Unnamed: 0  col_1  col_2  col_3  ...   col_6   col_7   col_8  binaryClass\n","0             0     76     33     33  ...  1.1718  5.5683  5.7268            1\n","1             1     76     34     34  ...  1.1815  5.5568  5.7236            1\n","2             2     76     35     35  ...  1.1907  5.5491  5.7236            1\n","3             3     76     36     36  ...  1.1679  5.5683  5.7236            1\n","4             4     76     37     37  ...  1.1591  5.5759  5.7236            1\n","..          ...    ...    ...    ...  ...     ...     ...     ...          ...\n","305         305     84     20    436  ...  1.5879  6.2046  6.6670            0\n","306         306     84     21    437  ...  1.5879  6.2046  6.6670            0\n","307         307     84     22    438  ...  1.5815  6.2086  6.6670            0\n","308         308     84     25    441  ...  1.5847  6.2066  6.6670            0\n","309         309     84     26    442  ...  1.5752  6.2126  6.6670            0\n","\n","[310 rows x 10 columns]\n","      Iter       Train Loss   Remaining Time \n","         1           1.1916            0.06s\n","         2           1.0363            0.06s\n","         3           0.9069            0.06s\n","         4           0.7976            0.06s\n","         5           0.7042            0.07s\n","         6           0.6239            0.06s\n","         7           0.5542            0.06s\n","         8           0.4934            0.06s\n","         9           0.4401            0.06s\n","        10           0.3932            0.06s\n","        11           0.3519            0.06s\n","        12           0.3153            0.06s\n","        13           0.2828            0.06s\n","        14           0.2539            0.06s\n","        15           0.2281            0.06s\n","        16           0.2051            0.06s\n","        17           0.1845            0.06s\n","        18           0.1661            0.06s\n","        19           0.1497            0.05s\n","        20           0.1349            0.05s\n","        21           0.1216            0.05s\n","        22           0.1097            0.05s\n","        23           0.0989            0.05s\n","        24           0.0893            0.05s\n","        25           0.0806            0.05s\n","        26           0.0728            0.05s\n","        27           0.0657            0.05s\n","        28           0.0594            0.05s\n","        29           0.0536            0.05s\n","        30           0.0485            0.05s\n","        31           0.0438            0.05s\n","        32           0.0396            0.05s\n","        33           0.0358            0.05s\n","        34           0.0323            0.05s\n","        35           0.0292            0.04s\n","        36           0.0264            0.04s\n","        37           0.0239            0.04s\n","        38           0.0216            0.04s\n","        39           0.0195            0.04s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.03s\n","        50           0.0065            0.03s\n","        51           0.0059            0.03s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0043            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0019            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.02s\n","        65           0.0014            0.02s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0006            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.00s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1906            0.07s\n","         2           1.0353            0.07s\n","         3           0.9060            0.08s\n","         4           0.7968            0.07s\n","         5           0.7035            0.07s\n","         6           0.6232            0.07s\n","         7           0.5536            0.07s\n","         8           0.4928            0.07s\n","         9           0.4396            0.07s\n","        10           0.3928            0.07s\n","        11           0.3515            0.07s\n","        12           0.3149            0.07s\n","        13           0.2825            0.07s\n","        14           0.2536            0.06s\n","        15           0.2279            0.06s\n","        16           0.2049            0.06s\n","        17           0.1843            0.06s\n","        18           0.1660            0.06s\n","        19           0.1495            0.06s\n","        20           0.1347            0.06s\n","        21           0.1215            0.06s\n","        22           0.1095            0.06s\n","        23           0.0988            0.06s\n","        24           0.0892            0.06s\n","        25           0.0805            0.06s\n","        26           0.0727            0.06s\n","        27           0.0656            0.06s\n","        28           0.0593            0.06s\n","        29           0.0536            0.06s\n","        30           0.0484            0.06s\n","        31           0.0437            0.06s\n","        32           0.0395            0.06s\n","        33           0.0357            0.06s\n","        34           0.0323            0.05s\n","        35           0.0292            0.05s\n","        36           0.0264            0.05s\n","        37           0.0239            0.05s\n","        38           0.0216            0.05s\n","        39           0.0195            0.05s\n","        40           0.0177            0.05s\n","        41           0.0160            0.05s\n","        42           0.0144            0.05s\n","        43           0.0131            0.05s\n","        44           0.0118            0.05s\n","        45           0.0107            0.05s\n","        46           0.0097            0.05s\n","        47           0.0087            0.05s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.04s\n","        53           0.0048            0.04s\n","        54           0.0043            0.04s\n","        55           0.0039            0.04s\n","        56           0.0036            0.04s\n","        57           0.0032            0.04s\n","        58           0.0029            0.04s\n","        59           0.0026            0.04s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0019            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.03s\n","        67           0.0012            0.03s\n","        68           0.0011            0.03s\n","        69           0.0010            0.03s\n","        70           0.0009            0.03s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0006            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.02s\n","        81           0.0006            0.02s\n","        82           0.0006            0.02s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.01s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1926            0.07s\n","         2           1.0372            0.07s\n","         3           0.9077            0.07s\n","         4           0.7983            0.07s\n","         5           0.7049            0.07s\n","         6           0.6244            0.07s\n","         7           0.5547            0.07s\n","         8           0.4938            0.07s\n","         9           0.4405            0.07s\n","        10           0.3936            0.07s\n","        11           0.3522            0.07s\n","        12           0.3156            0.06s\n","        13           0.2830            0.06s\n","        14           0.2541            0.06s\n","        15           0.2283            0.06s\n","        16           0.2053            0.06s\n","        17           0.1847            0.06s\n","        18           0.1663            0.06s\n","        19           0.1498            0.06s\n","        20           0.1350            0.06s\n","        21           0.1217            0.06s\n","        22           0.1098            0.06s\n","        23           0.0990            0.06s\n","        24           0.0894            0.06s\n","        25           0.0807            0.06s\n","        26           0.0728            0.06s\n","        27           0.0658            0.05s\n","        28           0.0594            0.05s\n","        29           0.0537            0.05s\n","        30           0.0485            0.05s\n","        31           0.0438            0.05s\n","        32           0.0396            0.05s\n","        33           0.0358            0.05s\n","        34           0.0324            0.05s\n","        35           0.0293            0.05s\n","        36           0.0265            0.05s\n","        37           0.0239            0.05s\n","        38           0.0216            0.05s\n","        39           0.0196            0.05s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.04s\n","        53           0.0048            0.04s\n","        54           0.0043            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.03s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0006            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.02s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1916            0.07s\n","         2           1.0363            0.08s\n","         3           0.9069            0.07s\n","         4           0.7976            0.07s\n","         5           0.7042            0.07s\n","         6           0.6239            0.07s\n","         7           0.5542            0.07s\n","         8           0.4934            0.07s\n","         9           0.4401            0.07s\n","        10           0.3932            0.07s\n","        11           0.3519            0.07s\n","        12           0.3153            0.07s\n","        13           0.2828            0.07s\n","        14           0.2539            0.06s\n","        15           0.2281            0.06s\n","        16           0.2051            0.06s\n","        17           0.1845            0.06s\n","        18           0.1661            0.06s\n","        19           0.1497            0.06s\n","        20           0.1349            0.06s\n","        21           0.1216            0.06s\n","        22           0.1097            0.06s\n","        23           0.0989            0.06s\n","        24           0.0893            0.06s\n","        25           0.0806            0.06s\n","        26           0.0728            0.06s\n","        27           0.0657            0.05s\n","        28           0.0594            0.05s\n","        29           0.0536            0.05s\n","        30           0.0485            0.05s\n","        31           0.0438            0.05s\n","        32           0.0396            0.05s\n","        33           0.0358            0.05s\n","        34           0.0323            0.05s\n","        35           0.0292            0.05s\n","        36           0.0264            0.05s\n","        37           0.0239            0.05s\n","        38           0.0216            0.05s\n","        39           0.0195            0.05s\n","        40           0.0177            0.05s\n","        41           0.0160            0.05s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.04s\n","        53           0.0048            0.04s\n","        54           0.0043            0.04s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0019            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.03s\n","        67           0.0012            0.03s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0006            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.02s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1960            0.07s\n","         2           1.0404            0.07s\n","         3           0.9106            0.07s\n","         4           0.8009            0.07s\n","         5           0.7073            0.07s\n","         6           0.6266            0.07s\n","         7           0.5566            0.07s\n","         8           0.4955            0.07s\n","         9           0.4421            0.07s\n","        10           0.3950            0.07s\n","        11           0.3534            0.07s\n","        12           0.3167            0.07s\n","        13           0.2840            0.07s\n","        14           0.2550            0.06s\n","        15           0.2291            0.06s\n","        16           0.2060            0.06s\n","        17           0.1854            0.06s\n","        18           0.1669            0.06s\n","        19           0.1503            0.06s\n","        20           0.1355            0.06s\n","        21           0.1221            0.06s\n","        22           0.1102            0.06s\n","        23           0.0994            0.06s\n","        24           0.0897            0.06s\n","        25           0.0810            0.06s\n","        26           0.0731            0.06s\n","        27           0.0660            0.05s\n","        28           0.0596            0.05s\n","        29           0.0539            0.05s\n","        30           0.0487            0.05s\n","        31           0.0440            0.05s\n","        32           0.0397            0.05s\n","        33           0.0359            0.05s\n","        34           0.0325            0.05s\n","        35           0.0294            0.05s\n","        36           0.0265            0.05s\n","        37           0.0240            0.05s\n","        38           0.0217            0.05s\n","        39           0.0196            0.05s\n","        40           0.0178            0.05s\n","        41           0.0161            0.04s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0119            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0080            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.04s\n","        53           0.0048            0.04s\n","        54           0.0044            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0015            0.03s\n","        66           0.0013            0.03s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0007            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.02s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1906            0.07s\n","         2           1.0353            0.07s\n","         3           0.9060            0.07s\n","         4           0.7968            0.07s\n","         5           0.7035            0.07s\n","         6           0.6232            0.07s\n","         7           0.5536            0.07s\n","         8           0.4928            0.07s\n","         9           0.4396            0.07s\n","        10           0.3928            0.07s\n","        11           0.3515            0.07s\n","        12           0.3149            0.06s\n","        13           0.2825            0.06s\n","        14           0.2536            0.06s\n","        15           0.2279            0.06s\n","        16           0.2049            0.06s\n","        17           0.1843            0.06s\n","        18           0.1660            0.06s\n","        19           0.1495            0.06s\n","        20           0.1347            0.06s\n","        21           0.1215            0.06s\n","        22           0.1095            0.06s\n","        23           0.0988            0.06s\n","        24           0.0892            0.06s\n","        25           0.0805            0.06s\n","        26           0.0727            0.05s\n","        27           0.0656            0.05s\n","        28           0.0593            0.05s\n","        29           0.0536            0.05s\n","        30           0.0484            0.05s\n","        31           0.0437            0.05s\n","        32           0.0395            0.05s\n","        33           0.0357            0.05s\n","        34           0.0323            0.05s\n","        35           0.0292            0.05s\n","        36           0.0264            0.05s\n","        37           0.0239            0.05s\n","        38           0.0216            0.05s\n","        39           0.0195            0.05s\n","        40           0.0177            0.04s\n","        41           0.0160            0.04s\n","        42           0.0144            0.04s\n","        43           0.0131            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0087            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.04s\n","        53           0.0048            0.03s\n","        54           0.0043            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0019            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.03s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0006            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1916            0.07s\n","         2           1.0363            0.07s\n","         3           0.9069            0.07s\n","         4           0.7976            0.07s\n","         5           0.7042            0.07s\n","         6           0.6239            0.07s\n","         7           0.5542            0.07s\n","         8           0.4934            0.07s\n","         9           0.4401            0.07s\n","        10           0.3932            0.07s\n","        11           0.3519            0.06s\n","        12           0.3153            0.06s\n","        13           0.2828            0.06s\n","        14           0.2539            0.06s\n","        15           0.2281            0.06s\n","        16           0.2051            0.06s\n","        17           0.1845            0.06s\n","        18           0.1661            0.06s\n","        19           0.1497            0.06s\n","        20           0.1349            0.06s\n","        21           0.1216            0.06s\n","        22           0.1097            0.06s\n","        23           0.0989            0.06s\n","        24           0.0893            0.06s\n","        25           0.0806            0.06s\n","        26           0.0728            0.05s\n","        27           0.0657            0.05s\n","        28           0.0594            0.05s\n","        29           0.0536            0.05s\n","        30           0.0485            0.05s\n","        31           0.0438            0.05s\n","        32           0.0396            0.05s\n","        33           0.0358            0.05s\n","        34           0.0323            0.05s\n","        35           0.0292            0.05s\n","        36           0.0264            0.05s\n","        37           0.0239            0.05s\n","        38           0.0216            0.05s\n","        39           0.0195            0.05s\n","        40           0.0177            0.05s\n","        41           0.0160            0.05s\n","        42           0.0145            0.05s\n","        43           0.0131            0.05s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.04s\n","        53           0.0048            0.04s\n","        54           0.0043            0.04s\n","        55           0.0039            0.04s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0019            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.03s\n","        67           0.0012            0.03s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0006            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.02s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1916            0.07s\n","         2           1.0363            0.07s\n","         3           0.9069            0.07s\n","         4           0.7976            0.07s\n","         5           0.7042            0.07s\n","         6           0.6239            0.07s\n","         7           0.5542            0.07s\n","         8           0.4934            0.07s\n","         9           0.4401            0.07s\n","        10           0.3932            0.07s\n","        11           0.3519            0.07s\n","        12           0.3153            0.06s\n","        13           0.2828            0.06s\n","        14           0.2539            0.06s\n","        15           0.2281            0.06s\n","        16           0.2051            0.06s\n","        17           0.1845            0.07s\n","        18           0.1661            0.07s\n","        19           0.1497            0.07s\n","        20           0.1349            0.07s\n","        21           0.1216            0.06s\n","        22           0.1097            0.06s\n","        23           0.0989            0.06s\n","        24           0.0893            0.06s\n","        25           0.0806            0.06s\n","        26           0.0728            0.06s\n","        27           0.0657            0.06s\n","        28           0.0594            0.06s\n","        29           0.0536            0.06s\n","        30           0.0485            0.06s\n","        31           0.0438            0.05s\n","        32           0.0396            0.05s\n","        33           0.0358            0.05s\n","        34           0.0323            0.05s\n","        35           0.0292            0.05s\n","        36           0.0264            0.05s\n","        37           0.0239            0.05s\n","        38           0.0216            0.05s\n","        39           0.0195            0.05s\n","        40           0.0177            0.05s\n","        41           0.0160            0.05s\n","        42           0.0145            0.05s\n","        43           0.0131            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.04s\n","        53           0.0048            0.04s\n","        54           0.0043            0.04s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0019            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.03s\n","        67           0.0012            0.03s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0006            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1895            0.06s\n","         2           1.0343            0.06s\n","         3           0.9050            0.06s\n","         4           0.7959            0.06s\n","         5           0.7027            0.06s\n","         6           0.6225            0.06s\n","         7           0.5529            0.06s\n","         8           0.4923            0.06s\n","         9           0.4391            0.06s\n","        10           0.3924            0.06s\n","        11           0.3511            0.06s\n","        12           0.3146            0.06s\n","        13           0.2821            0.06s\n","        14           0.2533            0.06s\n","        15           0.2276            0.06s\n","        16           0.2046            0.06s\n","        17           0.1841            0.06s\n","        18           0.1658            0.06s\n","        19           0.1493            0.06s\n","        20           0.1346            0.06s\n","        21           0.1213            0.06s\n","        22           0.1094            0.06s\n","        23           0.0987            0.06s\n","        24           0.0891            0.06s\n","        25           0.0804            0.06s\n","        26           0.0726            0.06s\n","        27           0.0656            0.05s\n","        28           0.0592            0.05s\n","        29           0.0535            0.05s\n","        30           0.0483            0.05s\n","        31           0.0437            0.05s\n","        32           0.0395            0.05s\n","        33           0.0357            0.05s\n","        34           0.0323            0.05s\n","        35           0.0292            0.05s\n","        36           0.0264            0.05s\n","        37           0.0238            0.05s\n","        38           0.0216            0.05s\n","        39           0.0195            0.04s\n","        40           0.0176            0.04s\n","        41           0.0159            0.04s\n","        42           0.0144            0.04s\n","        43           0.0130            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0087            0.04s\n","        48           0.0079            0.04s\n","        49           0.0071            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.03s\n","        53           0.0048            0.03s\n","        54           0.0043            0.03s\n","        55           0.0039            0.03s\n","        56           0.0035            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0019            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.02s\n","        66           0.0013            0.02s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0006            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.01s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.00s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n","      Iter       Train Loss   Remaining Time \n","         1           1.1926            0.07s\n","         2           1.0372            0.06s\n","         3           0.9077            0.08s\n","         4           0.7983            0.13s\n","         5           0.7049            0.13s\n","         6           0.6244            0.12s\n","         7           0.5547            0.11s\n","         8           0.4938            0.10s\n","         9           0.4405            0.10s\n","        10           0.3936            0.09s\n","        11           0.3522            0.09s\n","        12           0.3156            0.08s\n","        13           0.2830            0.08s\n","        14           0.2541            0.08s\n","        15           0.2283            0.08s\n","        16           0.2053            0.07s\n","        17           0.1847            0.07s\n","        18           0.1663            0.07s\n","        19           0.1498            0.07s\n","        20           0.1350            0.07s\n","        21           0.1217            0.07s\n","        22           0.1098            0.07s\n","        23           0.0990            0.06s\n","        24           0.0894            0.06s\n","        25           0.0807            0.06s\n","        26           0.0728            0.06s\n","        27           0.0658            0.06s\n","        28           0.0594            0.06s\n","        29           0.0537            0.06s\n","        30           0.0485            0.06s\n","        31           0.0438            0.06s\n","        32           0.0396            0.05s\n","        33           0.0358            0.05s\n","        34           0.0324            0.05s\n","        35           0.0293            0.05s\n","        36           0.0265            0.05s\n","        37           0.0239            0.05s\n","        38           0.0216            0.05s\n","        39           0.0196            0.05s\n","        40           0.0177            0.05s\n","        41           0.0160            0.05s\n","        42           0.0145            0.04s\n","        43           0.0131            0.04s\n","        44           0.0118            0.04s\n","        45           0.0107            0.04s\n","        46           0.0097            0.04s\n","        47           0.0088            0.04s\n","        48           0.0079            0.04s\n","        49           0.0072            0.04s\n","        50           0.0065            0.04s\n","        51           0.0059            0.04s\n","        52           0.0053            0.04s\n","        53           0.0048            0.04s\n","        54           0.0043            0.03s\n","        55           0.0039            0.03s\n","        56           0.0036            0.03s\n","        57           0.0032            0.03s\n","        58           0.0029            0.03s\n","        59           0.0026            0.03s\n","        60           0.0024            0.03s\n","        61           0.0022            0.03s\n","        62           0.0020            0.03s\n","        63           0.0018            0.03s\n","        64           0.0016            0.03s\n","        65           0.0014            0.03s\n","        66           0.0013            0.03s\n","        67           0.0012            0.02s\n","        68           0.0011            0.02s\n","        69           0.0010            0.02s\n","        70           0.0009            0.02s\n","        71           0.0008            0.02s\n","        72           0.0007            0.02s\n","        73           0.0006            0.02s\n","        74           0.0006            0.02s\n","        75           0.0006            0.02s\n","        76           0.0006            0.02s\n","        77           0.0006            0.02s\n","        78           0.0006            0.02s\n","        79           0.0006            0.02s\n","        80           0.0006            0.01s\n","        81           0.0006            0.01s\n","        82           0.0006            0.01s\n","        83           0.0006            0.01s\n","        84           0.0006            0.01s\n","        85           0.0006            0.01s\n","        86           0.0006            0.01s\n","        87           0.0006            0.01s\n","        88           0.0006            0.01s\n","        89           0.0006            0.01s\n","        90           0.0006            0.01s\n","        91           0.0006            0.01s\n","        92           0.0006            0.01s\n","        93           0.0006            0.01s\n","        94           0.0006            0.00s\n","        95           0.0006            0.00s\n","        96           0.0006            0.00s\n","        97           0.0006            0.00s\n","        98           0.0006            0.00s\n","        99           0.0006            0.00s\n","       100           0.0006            0.00s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y_0dTq1TR-oR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1597598484651,"user_tz":-180,"elapsed":1092,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"6e832c1e-25e5-4b5e-92e4-7d1571dbaf66"},"source":["kigb_res= pd.DataFrame(result_list).drop(['AUC','PR-Curve'],axis=1)\n","kigb_res"],"execution_count":228,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Dataset Name</th>\n","      <th>Algorithm Name</th>\n","      <th>Cross Validation</th>\n","      <th>Hyper-Parameters Values</th>\n","      <th>Accuracy</th>\n","      <th>TPR</th>\n","      <th>FPR</th>\n","      <th>Precision</th>\n","      <th>Training Time</th>\n","      <th>Inference Time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>analcatdata_lawsuit.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>1</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>0.962963</td>\n","      <td>[0.96, 1.0]</td>\n","      <td>[0.0, 0.04]</td>\n","      <td>0.833333</td>\n","      <td>0.070809</td>\n","      <td>0.010799</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>analcatdata_lawsuit.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>2</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>1.000000</td>\n","      <td>[1.0, 1.0]</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>1.000000</td>\n","      <td>0.150288</td>\n","      <td>0.010552</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>analcatdata_lawsuit.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>3</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>1.000000</td>\n","      <td>[1.0, 1.0]</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>1.000000</td>\n","      <td>0.223799</td>\n","      <td>0.014685</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>analcatdata_lawsuit.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>4</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>1.000000</td>\n","      <td>[1.0, 1.0]</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>1.000000</td>\n","      <td>0.296001</td>\n","      <td>0.016795</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>analcatdata_lawsuit.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>5</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>1.000000</td>\n","      <td>[1.0, 1.0]</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>1.000000</td>\n","      <td>0.369383</td>\n","      <td>0.018716</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>diggle_table_a2.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>6</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>1.000000</td>\n","      <td>[1.0, 1.0]</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>1.000000</td>\n","      <td>0.479929</td>\n","      <td>0.013328</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>diggle_table_a2.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>7</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>1.000000</td>\n","      <td>[1.0, 1.0]</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>1.000000</td>\n","      <td>0.560545</td>\n","      <td>0.009706</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>diggle_table_a2.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>8</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>1.000000</td>\n","      <td>[1.0, 1.0]</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>1.000000</td>\n","      <td>0.639417</td>\n","      <td>0.010798</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>diggle_table_a2.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>9</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>1.000000</td>\n","      <td>[1.0, 1.0]</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>1.000000</td>\n","      <td>0.712374</td>\n","      <td>0.010498</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>diggle_table_a2.csv</td>\n","      <td>Gradient Boosting</td>\n","      <td>10</td>\n","      <td>{'criterion': 'friedman_mse', 'init': None, 'l...</td>\n","      <td>1.000000</td>\n","      <td>[1.0, 1.0]</td>\n","      <td>[0.0, 0.0]</td>\n","      <td>1.000000</td>\n","      <td>0.788830</td>\n","      <td>0.009191</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100 rows × 10 columns</p>\n","</div>"],"text/plain":["               Dataset Name     Algorithm Name  ...  Training Time Inference Time\n","0   analcatdata_lawsuit.csv  Gradient Boosting  ...       0.070809       0.010799\n","1   analcatdata_lawsuit.csv  Gradient Boosting  ...       0.150288       0.010552\n","2   analcatdata_lawsuit.csv  Gradient Boosting  ...       0.223799       0.014685\n","3   analcatdata_lawsuit.csv  Gradient Boosting  ...       0.296001       0.016795\n","4   analcatdata_lawsuit.csv  Gradient Boosting  ...       0.369383       0.018716\n","..                      ...                ...  ...            ...            ...\n","95      diggle_table_a2.csv  Gradient Boosting  ...       0.479929       0.013328\n","96      diggle_table_a2.csv  Gradient Boosting  ...       0.560545       0.009706\n","97      diggle_table_a2.csv  Gradient Boosting  ...       0.639417       0.010798\n","98      diggle_table_a2.csv  Gradient Boosting  ...       0.712374       0.010498\n","99      diggle_table_a2.csv  Gradient Boosting  ...       0.788830       0.009191\n","\n","[100 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":228}]},{"cell_type":"markdown","metadata":{"id":"CltdR2GRfIVt","colab_type":"text"},"source":["##EDiT"]},{"cell_type":"markdown","metadata":{"id":"DBvydzftgrtB","colab_type":"text"},"source":["###EDiT data"]},{"cell_type":"code","metadata":{"id":"5UfasEwSfIAm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590697277,"user_tz":-180,"elapsed":961,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["\n","def read_dfs(path, dataset):\n","    df_list = []\n","    for mode in ['-', 'train', 'test']:\n","        if mode == '-':\n","            filename = '{}_R.dat'.format(dataset)\n","        else:\n","            filename = '{}_{}_R.dat'.format(dataset, mode)\n","        file = os.path.join(path, dataset, filename)\n","\n","        if os.path.exists(file):\n","            df = pd.read_csv(file, sep='\\t', index_col=0)\n","            df_list.append(df.reset_index(drop=True))\n","    return df_list\n","\n","\n","def split(num_data, ratio, seed=138):\n","    shuffled_index = np.arange(num_data)\n","    np.random.seed(seed)\n","    np.random.shuffle(shuffled_index)\n","    index1 = shuffled_index[:int(num_data * ratio)]\n","    index2 = shuffled_index[int(num_data * ratio):]\n","    return index1, index2\n","\n","\n","def normalize(arr):\n","    avg = np.mean(arr, axis=0)\n","    std = np.std(arr, axis=0)\n","    arr2 = arr - avg\n","    arr2[:, std != 0] /= std[std != 0]\n","    return arr2\n","\n","\n","def read_data(path, dataset, validation):\n","  # print(os.path.join(path, dataset))\n","\n","  if not os.path.exists(os.path.join(path, dataset)):\n","    raise ValueError(dataset)\n","\n","  df_list = read_dfs(path, dataset)\n","\n","  if len(df_list) == 1:\n","    df = df_list[0]\n","    arr_x = df.iloc[:, :-1].values.astype(np.float32)\n","    arr_y = df.iloc[:, -1].values\n","\n","    trn_idx, test_idx = split(arr_x.shape[0], ratio=0.8)\n","\n","    trn_x = arr_x[trn_idx]\n","    trn_y = arr_y[trn_idx]\n","    test_x = arr_x[test_idx]\n","    test_y = arr_y[test_idx]\n","\n","  elif len(df_list) == 2:\n","    trn_df = df_list[0]\n","    test_df = df_list[1]\n","\n","    trn_x = trn_df.iloc[:, :-1].values.astype(np.float32)\n","    trn_x = normalize(trn_x)\n","    trn_y = trn_df.iloc[:, -1].values\n","    test_x = test_df.iloc[:, :-1].values.astype(np.float32)\n","    test_x = normalize(test_x)\n","    test_y = test_df.iloc[:, -1].values\n","\n","  else:\n","    raise ValueError(dataset)\n","\n","  nx = trn_x.shape[1]\n","  ny = trn_y.max() + 1\n","\n","  if validation:\n","    trn_idx, val_idx = split(trn_x.shape[0], ratio=0.875)\n","\n","    val_x = trn_x[val_idx, :]\n","    val_y = trn_y[val_idx]\n","    trn_x = trn_x[trn_idx, :]\n","    trn_y = trn_y[trn_idx]\n","  else:\n","    val_x = None\n","    val_y = None\n","\n","  return dict(trn_x=trn_x,\n","              trn_y=trn_y,\n","              val_x=val_x,\n","              val_y=val_y,\n","              test_x=test_x,\n","              test_y=test_y,\n","              nx=nx, ny=ny)\n","\n","\n","def to_loader(x, y, batch_size, shuffle=False):\n","  x = torch.tensor(x)\n","  y_type = torch.long if y.dtype == np.int else torch.float\n","  y = torch.tensor(y, dtype=y_type)\n","  return DataLoader(TensorDataset(x, y), batch_size, shuffle)"],"execution_count":64,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xEYykv0qgvR5","colab_type":"text"},"source":["###EDiT Model"]},{"cell_type":"code","metadata":{"id":"tZ8d3E0RgGbr","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590699791,"user_tz":-180,"elapsed":1504,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def count_leaves(depth):\n","  return int(2 ** depth)\n","\n","\n","def reshape_mask(mask):\n","  return mask.unsqueeze(1).reshape((int(mask.size(0) / 2), 2))\n","\n","\n","class Layer(nn.Module):\n","  def __init__(self, in_features, depth, tying_ratio):\n","    super().__init__()\n","    out_nodes = count_leaves(depth)\n","    mask_ones = torch.ones((out_nodes, in_features))\n","    mask = torch.bernoulli(mask_ones * (1 - tying_ratio)).bool()\n","    self.register_buffer('mask', mask)  # self.mask = mask\n","    self.linear = nn.Linear(in_features, out_nodes)\n","    self.apply_mask()\n","\n","  def apply_mask(self):\n","    def backward_hook(grad):\n","      out = grad.clone()\n","      out[self.mask] = 0\n","      return out\n","\n","    self.linear.weight.data[self.mask] = 0\n","    self.linear.weight.register_hook(backward_hook)\n","\n","  def forward(self, x, path, mask):\n","    mask_zero = reshape_mask(mask)\n","    mask_one = torch.zeros_like(mask_zero)\n","    mask_one[mask_zero.sum(dim=1) == 1, :] = 1\n","\n","    prob_right = torch.sigmoid(self.linear(x))\n","    prob_left = 1 - prob_right\n","    new_prob = torch.stack((prob_left, prob_right), dim=2)\n","    new_prob.masked_fill_(mask_one, 1)\n","    new_prob.masked_fill_(mask_zero, 0)\n","\n","    new_path = path.unsqueeze(2).repeat((1, 1, 2))  # N x D x 2\n","    return (new_path * new_prob).view((new_path.size(0), -1))  # N x 2D\n","\n","  def size(self):\n","    mask = self.mask.clone()\n","    mask[self.linear.weight.abs() < EPSILON] = 1\n","    return (~mask).sum(dim=1) + 1  # 1 for the bias\n","\n","  def l1_loss(self):\n","    sum1 = self.linear.weight.abs().sum(dim=1)\n","    sum2 = self.linear.bias.abs()\n","    return sum1 + sum2\n","\n","  def prune(self, ratio):\n","    abs_weight = torch.abs(self.linear.weight.data)\n","    abs_weight_np = abs_weight.cpu().numpy()\n","    for n in range(self.linear.weight.shape[0]):\n","      threshold = np.percentile(abs_weight_np[n, :], (1 - ratio) * 100)\n","      self.mask[n, abs_weight[n, :] < threshold] = 1\n","    self.apply_mask()\n","\n","\n","class CompactSDT(nn.Module):\n","  def __init__(self, in_features, out_classes, depth=8, tying=1.0):\n","    super().__init__()\n","    self.depth = depth\n","    self.logit = nn.Parameter(torch.randn(count_leaves(depth), out_classes))\n","    self.layers = nn.ModuleList(\n","        Layer(in_features, d, tying) for d in range(depth))\n","\n","    # branch pruning\n","    for i, d in enumerate(range(1, depth + 1)):\n","        self.register_buffer(f'mask{i}', torch.zeros(2 ** d, dtype=torch.bool))\n","        self.register_buffer(f'path{i}', torch.zeros(2 ** d))\n","\n","    # loss functions\n","    self.ce_loss = torch.nn.CrossEntropyLoss(reduction='none')\n","    self.kld_loss = torch.nn.KLDivLoss(reduction='none')\n","    self.log_softmax = torch.nn.LogSoftmax(dim=1)\n","\n","  def get_masks(self):\n","    return [self.__getattr__(f'mask{i}') for i in range(self.depth)]\n","\n","  def get_paths(self):\n","    return [self.__getattr__(f'path{i}') for i in range(self.depth)]\n","\n","  def propagate(self, x, accumulate=False):\n","    path = torch.ones((x.size(0), 1), device=x.device)\n","    zipped = zip(self.get_paths(), self.get_masks(), self.layers)\n","    for acc, mask, layer in zipped:\n","      path = layer(x, path, mask)\n","      if accumulate:\n","        acc += path.sum(dim=0).detach()\n","    return path\n","\n","  def predict(self, path, mode):\n","    if mode == 'train':\n","      return self.logit.expand((path.size(0), -1, -1))\n","    elif mode == 'test':\n","      return self.logit[path.argmax(dim=1), :]\n","    else:\n","      raise ValueError(mode)\n","\n","  def forward(self, x):\n","    path_probs = self.propagate(x, accumulate=False)\n","    return self.predict(path_probs, mode='test')\n","\n","  def get_loss(self, x, y, accumulate=False):\n","    n_nodes = count_leaves(self.depth)\n","    path_probs = self.propagate(x, accumulate=accumulate)\n","    pred = self.predict(path_probs, mode='train').permute((0, 2, 1))\n","\n","    if len(y.shape) == 1:\n","      y_ = y.unsqueeze(1).expand((-1, n_nodes))\n","      tq = self.ce_loss(pred, y_)\n","    else:\n","      log_pred = self.log_softmax(pred)\n","      y_ = y.unsqueeze(2).expand((*y.shape, n_nodes))\n","      tq = self.kld_loss(log_pred, y_).sum(dim=1)\n","\n","    loss = (path_probs * tq).sum(dim=1).mean()\n","    output = self.predict(path_probs, mode='test')\n","    return loss, output\n","\n","  def prune_nodes(self, threshold):\n","    rev_masks = reversed(self.get_masks())\n","    rev_paths = reversed(self.get_paths())\n","\n","    acc_mask = None\n","    for mask, path in zip(rev_masks, rev_paths):\n","      if acc_mask is not None:\n","        mask[acc_mask] = 1\n","\n","      path /= path.sum()\n","      mask[path < threshold] = 1\n","      path.fill_(0)\n","      acc_mask = reshape_mask(mask).sum(dim=1) == 2\n","\n","  def prune_weights(self, ratio):\n","    for layer in self.layers:\n","      layer.prune(ratio)\n","\n","  def size(self):\n","    def is_single_path(m):\n","      return reshape_mask(m).sum(dim=1) == 1\n","\n","    size = self.layers[0].size().sum()\n","    rev_masks = reversed(self.get_masks()[:-1])\n","    rev_layers = reversed(self.layers[1:])\n","\n","    add_mask = is_single_path(self.get_masks()[-1])\n","    for mask, layer in zip(rev_masks, rev_layers):\n","      size += layer.size()[~(mask + add_mask > 0)].sum()\n","      add_mask = is_single_path(mask)\n","    return size.item()\n","\n","  def get_l1_loss(self):\n","    loss = self.layers[0].l1_loss().sum()\n","    for mask, layer in zip(self.get_masks(), self.layers[1:]):\n","      loss += layer.l1_loss()[~mask].sum()\n","    return loss\n","\n","  def active_nodes(self):\n","    return sum((~m).sum().item() for m in self.get_masks())"],"execution_count":65,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"woPt47WTgnI2","colab_type":"text"},"source":["###EDit Example"]},{"cell_type":"code","metadata":{"id":"Wnpm6FtqwJTI","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560059,"user_tz":-180,"elapsed":8750,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["# p = project_dir_path + 'EDiT/datasets'\n","# for dp, dn, fn in os.walk(p,):\n","#   dn.sort()\n","#   print(dn)\n","#   with open(project_dir_path + 'EDiT/datasets.txt',mode='a') as f:\n","#     for x in dn:\n","#       f.write(x+'\\n')\n","#   break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtPEYETHg-LK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597607094309,"user_tz":-180,"elapsed":1690,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["DEVICE = None\n","\n","def set_device():\n","  global DEVICE\n","  DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","def set_seeds(seed):\n","  np.random.seed(np.random.randint(0,41))\n","  torch.manual_seed(np.random.randint(0,41))\n","  torch.cuda.manual_seed(np.random.randint(0,41))\n","\n","\n","def get_valid_datasets():\n","  with open(project_dir_path + 'EDiT/datasets.txt') as f:\n","    return [e.strip() for e in f.readlines()]\n","\n","\n","def evaluate(model, loader, l1reg=0) -> tuple:\n","  model.eval()\n","\n","  sum_loss, sum_correct = 0, 0\n","  # print('loader',loader)\n","  for x, y in loader:\n","    batch_size = x.size(0)\n","    x = x.to(DEVICE).view(batch_size, -1)\n","    y = y.to(DEVICE)\n","\n","    loss, output = model.get_loss(x, y)\n","    # print('output',output)\n","    if l1reg > 0:\n","        loss = loss + l1reg * model.get_l1_loss()\n","    pred = torch.argmax(output, dim=1)\n","    # print('pred',pred)\n","    if len(y.shape) > 1:\n","        y = torch.argmax(y, dim=1)\n","    sum_loss += loss.item() * batch_size\n","    sum_correct += torch.eq(pred, y).sum().item()\n","\n","  num_data = len(loader.dataset)\n","  loss = sum_loss / num_data\n","  acc = sum_correct / num_data\n","  return loss, acc\n","\n","\n","def train(model, loaders, l1reg, pruning, logs):\n","  lr = 1e-2\n","  epochs = 500\n","  val_epochs = 40\n","  optimizer = optim.Adam(model.parameters(), lr)\n","\n","  if not os.path.exists(logs):\n","    with open(logs, 'w') as f:\n","      f.write('epoch\\ttrn_loss\\ttrn_acc\\tval_loss\\tval_acc\\tparams\\t'\n","              'is_best\\n')\n","\n","  best_epoch, best_loss = -1, 1e10\n","  saved_model = None\n","  for epoch in range(epochs + 1):\n","    if epoch > 0:\n","      model.train()\n","\n","      for x, y in loaders[0]:\n","        x = x.to(DEVICE).view(x.size(0), -1)\n","        y = y.to(DEVICE)\n","\n","        optimizer.zero_grad()\n","        loss, _ = model.get_loss(x, y, accumulate=True)\n","        if l1reg > 0:\n","          loss = loss + l1reg * model.get_l1_loss()\n","        loss.backward()\n","        optimizer.step()\n","\n","    trn_loss, trn_acc = evaluate(model, loaders[0], l1reg)\n","    val_loss, val_acc = evaluate(model, loaders[1], l1reg)\n","    size = model.size()\n","\n","    if pruning > 0:\n","      model.prune_nodes(threshold=pruning)  # 1e-6 originally\n","\n","    if val_loss < best_loss:\n","      best_epoch = epoch\n","      best_loss = val_loss\n","      saved_model = io.BytesIO()\n","      torch.save(model.state_dict(), saved_model)\n","    elif epoch > best_epoch + val_epochs:\n","      break\n","\n","    with open(logs, 'a') as f:\n","      is_best = 'BEST' if epoch == best_epoch else '-'\n","      f.write(f'{epoch}\\t')\n","      f.write(f'{trn_loss:.4f}\\t{trn_acc:.4f}\\t')\n","      f.write(f'{val_loss:.4f}\\t{val_acc:.4f}\\t')\n","      f.write(f'{size}\\t{is_best}\\n')\n","\n","  saved_model.seek(0)\n","  model.load_state_dict(torch.load(saved_model))\n","\n","\n","def edit_model(dataset_name):\n","  dataset = os.path.splitext(dataset_name)[0]\n","  # print(dataset)\n","  if dataset not in get_valid_datasets():\n","    return\n","\n","  depth = 8\n","  batch_size = 128\n","  seed = 2019\n","  log_path = f'../out/edit/logs/{dataset}.txt'\n","  model_path = f'../out/edit/models/{dataset}.pth'\n","  data_path = project_dir_path + 'EDiT/datasets'\n","\n","  distill = False  # True in the paper\n","  tying_ratio = 1.0  # 0.5 in the paper\n","  pruning_ratio = 1.0  # 0.5 in the paper\n","  lambda_l1reg = 0  # No optimal values\n","  tree_threshold = 0  # 1e-4 in paper\n","\n","  os.makedirs(os.path.dirname(log_path), exist_ok=True)\n","  if os.path.exists(log_path):\n","    os.remove(log_path)\n","\n","  set_device()\n","  set_seeds(seed)\n","\n","  data_dict = read_data(data_path, dataset, validation=True)\n","\n","  model = CompactSDT(\n","    in_features=data_dict['nx'],\n","    out_classes=data_dict['ny'],\n","    depth=depth,\n","    tying=tying_ratio)\n","  model = model.to(DEVICE)\n","\n","  if distill:\n","    rf_path = '../out/rf/models/{}.pkl'.format(dataset)\n","    rf_model: RandomForestClassifier = joblib.load(rf_path)\n","    pred_y = rf_model.predict_proba(data_dict['trn_x'])\n","\n","    trn_y = data_dict['trn_y']\n","    trn_y_onehot = np.zeros_like(pred_y)\n","    trn_y_onehot[np.arange(trn_y.shape[0]), trn_y] = 1\n","    data_dict['trn_y'] = (trn_y_onehot + pred_y) / 2\n","\n","  trn_x = data_dict['trn_x']\n","  trn_y = data_dict['trn_y']\n","  val_x = data_dict['val_x']\n","  val_y = data_dict['val_y']\n","\n","  trn_loader = to_loader(trn_x, trn_y, batch_size, shuffle=True)\n","  val_loader = to_loader(val_x, val_y, batch_size)\n","  loaders = (trn_loader, val_loader)\n","\n","  start_time = time()\n","\n","  train(model, loaders, lambda_l1reg, tree_threshold, log_path)\n","  if pruning_ratio < 1:\n","    model.prune_weights(ratio=pruning_ratio)\n","    train(model, loaders, lambda_l1reg, tree_threshold, log_path)\n","\n","  test_x = data_dict['test_x']\n","  test_y = data_dict['test_y']\n","  test_loader = to_loader(test_x, test_y, batch_size)\n","\n","  train_time = time() - start_time\n","  os.makedirs(os.path.dirname(model_path), exist_ok=True)\n","  torch.save(model.state_dict(), model_path)\n","  loss, acc = evaluate(model, test_loader, lambda_l1reg)\n","  \n","  print(j, acc, loss)\n","  add_result(dataset_name,'EDit', j, model.parameters(), acc,0,0,0,0,0,train_time,0)\n","  "],"execution_count":291,"outputs":[]},{"cell_type":"code","metadata":{"id":"zL0g7m1nzhib","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hmCRIaBuztpX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1597609603860,"user_tz":-180,"elapsed":2508465,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"c24d9fe4-760a-4734-93d1-98b90821100f"},"source":["# k=0\n","for dn in data_dic:\n","  # k+=1\n","  for dn in data_dic:\n","    edit_model(dn)\n","\n","FINISH_SOUNDS()"],"execution_count":292,"outputs":[{"output_type":"stream","text":["10 1.0 0.004014664329588413\n","10 1.0 0.003362958086654544\n","10 0.99 0.12234637141227722\n","10 0.968 0.22228653728961945\n","10 0.8972375690607735 0.2601724455534424\n","10 0.8133333333333334 0.4691156287988027\n","10 0.6724137931034483 0.6200370192527771\n","10 0.9642857142857143 0.1727866326059614\n","10 0.9824561403508771 0.11608713120222092\n","10 0.9 0.4918762147426605\n","10 0.45454545454545453 1.0917084217071533\n","10 0.9884393063583815 0.061256658371990125\n","10 0.8732394366197183 0.32873091591355946\n","10 0.7981220657276995 0.7869873234363789\n","10 0.9953125 0.046043113619089124\n","10 0.5517241379310345 0.7417647838592529\n","10 0.8809523809523809 0.3802904784679413\n","10 0.5220338983050847 0.9847467782133716\n","10 0.9956709956709957 0.1052974665384272\n","10 0.8623188405797102 0.4210339209091836\n","10 0.7378640776699029 0.6166465878486633\n","10 0.9594594594594594 0.17646153271198273\n","10 0.7407407407407407 0.5238217711448669\n","10 0.961038961038961 0.13410523185482273\n","10 0.8896103896103896 0.27805178699555333\n","10 0.95 0.31337881088256836\n","10 0.6744186046511628 0.987498939037323\n","10 0.6774193548387096 0.6900351047515869\n","10 0.6065573770491803 1.1123967170715332\n","10 0.7627118644067796 0.5734229683876038\n","10 0.44 1.4496546983718872\n","10 0.3 1.6325615644454956\n","10 0.8709677419354839 0.416906476020813\n","10 0.75 0.8271204233169556\n","10 0.5313531353135313 0.6867072954036222\n","10 0.8088235294117647 0.5504682064056396\n","10 0.6495726495726496 0.5209138989448547\n","10 0.8961904761904762 0.4312072411037627\n","10 0.9014084507042254 0.29969868063926697\n","10 0.9 0.2116292417049408\n","10 0.685 1.097096791267395\n","10 1.0 0.9638466238975525\n","10 0.875 0.7052955627441406\n","10 0.42857142857142855 1.3981359004974365\n","10 0.9 0.5055269598960876\n","10 0.8238341968911918 0.42532382697021404\n","10 0.7272727272727273 0.6820335388183594\n","10 0.8166144200626959 0.6455256750217426\n","10 0.8819444444444444 0.6600898482181408\n","10 0.8171296296296297 0.5473191075854831\n","10 0.8055555555555556 0.5699184823919226\n","10 1.0 1.5996884685274784e-08\n","10 0.9270833333333334 0.29157277941703796\n","10 0.7804878048780488 0.562099999334754\n","10 0.9414634146341463 0.205475023316174\n","10 0.7868852459016393 0.5123074680078225\n","10 0.9398907103825137 0.23433275691798475\n","10 0.9665354330708661 0.11263961702819884\n","10 0.9743589743589743 0.1875430941581726\n","10 0.7857142857142857 0.4967838510290369\n","10 0.7727272727272727 0.47291839122772217\n","10 0.6666666666666666 0.9451810717582703\n","10 0.7368421052631579 0.8969971537590027\n","10 0.5238095238095238 1.493566632270813\n","10 0.6756756756756757 0.7296578884124756\n","10 0.46875 1.9931678533554078\n","10 0.265625 2.468038558959961\n","10 0.53125 1.9837640523910522\n","10 0.8333333333333334 0.8326676487922668\n","10 0.8809523809523809 0.5628458857536316\n","10 0.9247648902821317 0.4918888740031323\n","10 0.8803191489361702 0.6646938374701966\n","10 0.9163952225841476 0.2742077778624401\n","10 0.5698924731182796 0.8898143556810194\n","10 0.44919786096256686 0.8679110133711667\n","10 0.7318840579710145 0.614224561314652\n","10 0.725 0.5820263600349427\n","10 0.9588744588744589 0.1811762604362521\n","10 0.711764705882353 0.5603530953912174\n","10 0.712082262210797 0.8219177088578133\n","10 1.0 0.08744107186794281\n","10 0.4838709677419355 1.1687850952148438\n","10 1.0 0.04465099424123764\n","10 0.7596371882086168 0.5320572875389437\n","10 0.8387096774193549 0.45942163467407227\n","10 0.8709677419354839 0.4284641146659851\n","10 0.8818681318681318 0.41565126966644117\n","10 0.854 0.32126562142372134\n","10 0.843 0.3918613882064819\n","10 1.0 0.10902949422597885\n","10 0.55625 1.0628774166107178\n","10 0.5581632653061225 1.0938103364438427\n","10 0.531986531986532 1.2435026602311567\n","10 1.0 0.004630448296666145\n","10 1.0 0.003362958086654544\n","10 0.99 0.12234637141227722\n","10 0.968 0.22228653728961945\n","10 0.8972375690607735 0.2601724455534424\n","10 0.8133333333333334 0.4691156287988027\n","10 0.6724137931034483 0.6200370192527771\n","10 0.9642857142857143 0.1727866326059614\n","10 0.9824561403508771 0.11608713120222092\n","10 0.9 0.4918762147426605\n","10 0.45454545454545453 1.0917084217071533\n","10 0.9884393063583815 0.061256658371990125\n","10 0.8732394366197183 0.32873091591355946\n","10 0.7981220657276995 0.7869873234363789\n","10 0.9953125 0.046043113619089124\n","10 0.5517241379310345 0.7417647838592529\n","10 0.8809523809523809 0.3802904784679413\n","10 0.5220338983050847 0.9847467782133716\n","10 0.9956709956709957 0.1052974665384272\n","10 0.8623188405797102 0.4210339209091836\n","10 0.7378640776699029 0.6166465878486633\n","10 0.9594594594594594 0.17646153271198273\n","10 0.7407407407407407 0.5238217711448669\n","10 0.961038961038961 0.13410523185482273\n","10 0.8896103896103896 0.27805178699555333\n","10 0.95 0.31337881088256836\n","10 0.6744186046511628 0.987498939037323\n","10 0.6774193548387096 0.6900351047515869\n","10 0.6065573770491803 1.1123967170715332\n","10 0.7627118644067796 0.5734229683876038\n","10 0.44 1.4496546983718872\n","10 0.3 1.6325615644454956\n","10 0.8709677419354839 0.416906476020813\n","10 0.75 0.8271204233169556\n","10 0.5313531353135313 0.6867072954036222\n","10 0.8088235294117647 0.5504682064056396\n","10 0.6495726495726496 0.5209138989448547\n","10 0.8961904761904762 0.4312072411037627\n","10 0.9014084507042254 0.29969868063926697\n","10 0.9 0.2116292417049408\n","10 0.685 1.097096791267395\n","10 1.0 0.9638466238975525\n","10 0.875 0.7052955627441406\n","10 0.42857142857142855 1.3981359004974365\n","10 0.9 0.5055269598960876\n","10 0.8238341968911918 0.42532382697021404\n","10 0.7272727272727273 0.6820335388183594\n","10 0.8166144200626959 0.6455256750217426\n","10 0.8819444444444444 0.6600898482181408\n","10 0.8171296296296297 0.5473191075854831\n","10 0.8055555555555556 0.5699184823919226\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-292-3fb411c6069a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# k+=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_dic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0medit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# FINISH_SOUNDS()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-291-6f45a350e973>\u001b[0m in \u001b[0;36medit_model\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_l1reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpruning_ratio\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprune_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpruning_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-291-6f45a350e973>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loaders, l1reg, pruning, logs)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ml1reg\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml1reg\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_l1_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-65-154e7a0da068>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(self, x, y, accumulate)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mn_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_leaves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mpath_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccumulate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-65-154e7a0da068>\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, x, accumulate)\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0maccumulate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0macc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"4yoN91lbYNo0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597607005457,"user_tz":-180,"elapsed":1000,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"e7039d90-0d19-4413-ab59-4b6907d45f6e"},"source":["result_list"],"execution_count":287,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 1,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f1460594db0>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.731360673904419},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 2,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14606abdb0>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.729043960571289},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 3,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14606abf10>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.705652952194214},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 4,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ad606db0>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.552695751190186},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 5,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ad606e60>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.817415237426758},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 6,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14606abf68>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.737898349761963},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 7,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14606abeb8>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.38474154472351},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 8,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14606abe60>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.48927354812622},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 9,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14c4048780>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.7183837890625},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 10,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14c4048258>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.782522439956665},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 1,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14c4048830>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.819944381713867},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 2,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f146557ddb0>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.915183067321777},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 3,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f1460716830>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.754610300064087},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 4,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f1460716ba0>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.755831003189087},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 5,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f1460782db0>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.489542961120605},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 6,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f146557d0a0>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.677230834960938},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 7,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f1460550ba0>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.576639652252197},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 8,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14605505c8>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.773167133331299},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 9,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f146557d620>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.574708700180054},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 10,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f146557d360>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 13.0075843334198},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 1,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14c4048728>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 31.678767681121826},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 2,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ab19fd58>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 49.74059081077576},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 3,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ab19fe60>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 48.21053338050842},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 4,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ab19fdb0>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 47.24045968055725},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 5,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ad40eeb8>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 48.514241218566895},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 6,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ad40ee60>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 48.17061924934387},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 7,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ad40ef10>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 48.1655433177948},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 8,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ad40ebf8>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 48.21348428726196},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 9,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ad40ee08>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 48.71085023880005},\n"," {'AUC': 0,\n","  'Accuracy': 0.99,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 10,\n","  'Dataset Name': 'annealing.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14ad40ef68>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 48.03397822380066},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 10,\n","  'Dataset Name': 'acute-inflammation.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14aac06620>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.355851650238037},\n"," {'AUC': 0,\n","  'Accuracy': 1.0,\n","  'Algorithm Name': 'EDit',\n","  'Cross Validation': 10,\n","  'Dataset Name': 'acute-nephritis.csv',\n","  'FPR': 0,\n","  'Hyper-Parameters Values': <generator object Module.parameters at 0x7f14aac06048>,\n","  'Inference Time': 0,\n","  'PR-Curve': 0,\n","  'Precision': 0,\n","  'TPR': 0,\n","  'Training Time': 12.844717741012573}]"]},"metadata":{"tags":[]},"execution_count":287}]},{"cell_type":"code","metadata":{"id":"XkIVcXKvdmIE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1597609686551,"user_tz":-180,"elapsed":1045,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"1190d87a-aea9-4b2b-dffd-6c156f4e4d81"},"source":["edit_res= pd.DataFrame(result_list).drop(['AUC', 'Cross Validation','PR-Curve','TPR','FPR','Precision','Inference Time'],axis=1)\n","edit_res.mean(0)"],"execution_count":294,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Accuracy          0.828835\n","Training Time    17.446746\n","dtype: float64"]},"metadata":{"tags":[]},"execution_count":294}]},{"cell_type":"markdown","metadata":{"id":"Vh4QLlkb10M6","colab_type":"text"},"source":["##Rotation Forest"]},{"cell_type":"code","metadata":{"id":"DN7ZvRZBY8qO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590706943,"user_tz":-180,"elapsed":1063,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def rotation_forest(df_name):\n","  df = data_dic[df_name]\n","  target = pd.DataFrame(df[df.columns[-1]])\n","  train = df.drop([df.columns[-1]], axis=1)\n","  print(df)\n","  data = np.array(df)\n","  total_num_of_features = len(data[0])-1\n","  feature_per_tree = int(math.sqrt(total_num_of_features))\n","  num_feature = feature_per_tree * feature_per_tree\n","\n","  train_arr = np.array(train).tolist()\n","  target_arr = np.array(target).tolist()\n","  classes = np.unique(target_arr)\n","  i=0\n","  start_time = time()\n","  # print('train_arr')\n","  # print(train_arr)\n","  # print('target_arr')\n","  # print(target_arr)\n","  # print(data)\n","  # print(feature_per_tree)\n","  \n","  kf = KFold(n_splits=10, random_state=random_state, shuffle=True).split(train_arr,target_arr)\n","  \n","\n","  for train_idx, test_idx in kf:\n","    i+=1\n","    # print('train_idx')\n","    # print(train_idx)\n","    # print('test_idx')\n","    # print(test_idx)\n","    train_x=[train_arr[ii] for ii in train_idx]\n","    test_x=[train_arr[ii] for ii in test_idx]\n","    train_y=[target_arr[ii] for ii in train_idx]\n","    test_y=[target_arr[ii] for ii in test_idx]  \n","          \n","    # print('train_x')\n","    # print(train_x)\n","    # print('train_y')\n","    # print(train_y)\n","    \n","    # print('test_x')\n","    # print(test_x)\n","    print('test_y')\n","    print(test_y) \n","\n","  # print('xtrain\n","  \n","  # xtrain, xtest, ytrain, ytest = train_test_split(train, target, test_size=test_size, random_state=random_state)\n","\n","  # train_x = np.array(xtrain.values.tolist())\n","  # train_y = np.array(ytrain.values.tolist())\n","  # test_x = np.array(xtest.values.tolist())\n","  # test_y = np.array(ytest.values.tolist())\n","\n","\n","  rf = af.RotationForestClassifier(bootstrap=True, max_depth=8, min_samples_leaf=1, min_samples_split=5,n_estimators=100, n_features_per_subset=feature_per_tree\n","                                   ,n_jobs=8, random_state=random_state)#,verbose=verbose)\n","\n"," \n","\n","  rf.fit(train_x, train_y)\n","  end_time = time()\n","  inference_start_time = time()\n","\n","  pred_y = rf.predict(test_x)\n","\n","  inference_end_time = time()\n","\n","  inference_time = (1000/len(pred_y))*(inference_end_time-inference_start_time)\n","  \n","\n","\n","  acc, tpr, fpr, precision, auc, prc = get_metrics(test_y, pred_y, classes)\n","\n","  \n","\n","  train_time = end_time - start_time\n","\n","  add_result(df_name,'Rotation Forest', i, rf.get_params(), acc, tpr, fpr, precision, auc, prc, train_time, inference_time)\n","\n","  # print('xtrain')\n","  # print(xtrain)\n","  # print('ytrain')\n","  # print(ytrain)\n","\n","  # print('xtest')\n","  # print(xtest)\n","  # print('ytest')\n","  # print(ytest)\n","\n","\n","  # print('train_x')\n","  # print(train_x)\n","  # print('train_y')\n","  # print(train_y)\n","  \n","  # print('test_x')\n","  # print(test_x)\n","  # print('test_y')\n","  # print(test_y) \n","\n","\n","\n","\n","\n","# predict_y\n"],"execution_count":67,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VD1fDX-waEMP","colab_type":"text"},"source":["#Friedman"]},{"cell_type":"code","metadata":{"id":"Y0f8JrWMaH76","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560061,"user_tz":-180,"elapsed":8694,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["j = 0 \n","df = pd.DataFrame(columns=['Dataset_Name','EDit', 'KiGB', 'Arranged_Forest'])\n","for dn in data_dic:\n","  l1 = acc_edit_model(dn)\n","  if l1 is not None:\n","    l2 = acc_kigb(dn)\n","    l3 = acc_arranged_forest(dn)\n","    l4 = acc_rotation_forest(dn)\n","    df = df.append({'Dataset_Name':dn,'EDit':l1, 'KiGB':l2, 'Arranged_Forest':l3,'Rotation_Forest':l4},ignore_index=True)\n","  #   j+=1\n","  # print(l1)\n","  # print(df)\n","  # if j==3:\n","  #   break\n","df\n","FINISH_SOUNDS()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhTyK3fyFNv9","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597590746113,"user_tz":-180,"elapsed":1351,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["df = pd.read_csv(results_path+'/alg_acc.csv')"],"execution_count":68,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTtkH4vWGOEA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":407},"executionInfo":{"status":"ok","timestamp":1597590848681,"user_tz":-180,"elapsed":1277,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"60578acf-c0b6-4b04-c0a4-738697c8b89f"},"source":["df = df.drop(columns=['Unnamed: 0','Dataset_Name'],axis=1)\n","df"],"execution_count":70,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EDit</th>\n","      <th>KiGB</th>\n","      <th>Arranged_Forest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.625000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.000000</td>\n","      <td>1.000000</td>\n","      <td>0.895833</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.970000</td>\n","      <td>0.933333</td>\n","      <td>0.825000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.952000</td>\n","      <td>0.848000</td>\n","      <td>0.664000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.895028</td>\n","      <td>0.908789</td>\n","      <td>0.882808</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>0.834000</td>\n","      <td>0.857000</td>\n","      <td>0.634500</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>0.944444</td>\n","      <td>1.000000</td>\n","      <td>0.888889</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>0.540625</td>\n","      <td>0.615625</td>\n","      <td>0.531250</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>0.540816</td>\n","      <td>0.581122</td>\n","      <td>0.503061</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>0.542088</td>\n","      <td>0.654882</td>\n","      <td>0.434343</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>93 rows × 3 columns</p>\n","</div>"],"text/plain":["        EDit      KiGB  Arranged_Forest\n","0   1.000000  1.000000         0.625000\n","1   1.000000  1.000000         0.895833\n","2   0.970000  0.933333         0.825000\n","3   0.952000  0.848000         0.664000\n","4   0.895028  0.908789         0.882808\n","..       ...       ...              ...\n","88  0.834000  0.857000         0.634500\n","89  0.944444  1.000000         0.888889\n","90  0.540625  0.615625         0.531250\n","91  0.540816  0.581122         0.503061\n","92  0.542088  0.654882         0.434343\n","\n","[93 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":70}]},{"cell_type":"code","metadata":{"id":"FqoY59vl-UdJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1597590876770,"user_tz":-180,"elapsed":959,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"fc26ccb2-b4d4-4beb-e808-2d8cae07fdf9"},"source":["\n","acc_edit = df['EDit']\n","acc_kigb = df['KiGB']\n","acc_af = df['Arranged_Forest']\n","acc_rf = df['Rotation_Forest']\n","\n","stat, p_val = friedmanchisquare(acc_edit,acc_kigb,acc_af,acc_rf)\n","\n","friedmanchisquare(acc_edit,acc_kigb,acc_af,acc_rf)"],"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FriedmanchisquareResult(statistic=56.68888888888902, pvalue=4.899640154085197e-13)"]},"metadata":{"tags":[]},"execution_count":72}]},{"cell_type":"code","metadata":{"id":"mzkiyFU__dsn","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560062,"user_tz":-180,"elapsed":8641,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-91698xF01wj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597591014400,"user_tz":-180,"elapsed":1203,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def acc_rotation_forest(df_name):\n","  df = data_dic[df_name]\n","  target = pd.DataFrame(df[df.columns[-1]])\n","  train = df.drop([df.columns[-1]], axis=1)\n","  # print(df)\n","  data = np.array(df)\n","  total_num_of_features = len(data[0])-1\n","  feature_per_tree = int(math.sqrt(total_num_of_features))\n","  num_feature = feature_per_tree * feature_per_tree\n","\n","  train_arr = np.array(train).tolist()\n","  target_arr = np.array(target).tolist()\n","  classes = np.unique(target_arr)\n","  i=0\n","  start_time = time()\n","  # print('train_arr')\n","  # print(train_arr)\n","  # print('target_arr')\n","  # print(target_arr)\n","  # print(data)\n","  # print(feature_per_tree)\n","  \n","  # kf = KFold(n_splits=10, random_state=random_state, shuffle=True).split(train_arr,target_arr)\n","  \n","\n","  # for train_idx, test_idx in kf:\n","  #   i+=1\n","  #   # print('train_idx')\n","  #   # print(train_idx)\n","  #   # print('test_idx')\n","  #   # print(test_idx)\n","  #   train_x=[train_arr[ii] for ii in train_idx]\n","  #   test_x=[train_arr[ii] for ii in test_idx]\n","  #   train_y=[target_arr[ii] for ii in train_idx]\n","  #   test_y=[target_arr[ii] for ii in test_idx]  \n","          \n","    # print('train_x')\n","    # print(train_x)\n","    # print('train_y')\n","    # print(train_y)\n","    \n","    # print('test_x')\n","    # print(test_x)\n","    # print('test_y')\n","    # print(test_y) \n","\n","  # print('xtrain\n","  \n","  xtrain, xtest, ytrain, ytest = train_test_split(train, target, test_size=test_size, random_state=random_state)\n","\n","  train_x = np.array(xtrain.values.tolist())\n","  train_y = np.array(ytrain.values.tolist())\n","  test_x = np.array(xtest.values.tolist())\n","  test_y = np.array(ytest.values.tolist())\n","\n","\n","  rf = af.RotationForestClassifier(bootstrap=True, max_depth=8, min_samples_leaf=1, min_samples_split=5,n_estimators=100, n_features_per_subset=feature_per_tree\n","                                   ,n_jobs=8, random_state=random_state)#,verbose=verbose)\n","\n"," \n","\n","  rf.fit(train_x, train_y)\n","  end_time = time()\n","  inference_start_time = time()\n","\n","  pred_y = rf.predict(test_x)\n","\n","  return accuracy_score(test_y, pred_y)\n","\n","  # print('xtrain')\n","  # print(xtrain)\n","  # print('ytrain')\n","  # print(ytrain)\n","\n","  # print('xtest')\n","  # print(xtest)\n","  # print('ytest')\n","  # print(ytest)\n","\n","\n","  # print('train_x')\n","  # print(train_x)\n","  # print('train_y')\n","  # print(train_y)\n","  \n","  # print('test_x')\n","  # print(test_x)\n","  # print('test_y')\n","  # print(test_y) \n","\n","\n","\n","\n","\n","# predict_y\n"],"execution_count":73,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7eKWG2y0TWo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597591016028,"user_tz":-180,"elapsed":1172,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["\n","\n","def acc_edit_model(dataset_name):\n","  dataset = os.path.splitext(dataset_name)[0]\n","  # print(dataset)\n","  if dataset not in get_valid_datasets():\n","    return\n","\n","  depth = 8\n","  batch_size = 128\n","  seed = 2019\n","  log_path = f'../out/edit/logs/{dataset}.txt'\n","  model_path = f'../out/edit/models/{dataset}.pth'\n","  data_path = project_dir_path + 'EDiT/datasets'\n","\n","  distill = False  # True in the paper\n","  tying_ratio = 1.0  # 0.5 in the paper\n","  pruning_ratio = 1.0  # 0.5 in the paper\n","  lambda_l1reg = 0  # No optimal values\n","  tree_threshold = 0  # 1e-4 in paper\n","\n","  os.makedirs(os.path.dirname(log_path), exist_ok=True)\n","  if os.path.exists(log_path):\n","    os.remove(log_path)\n","\n","  set_device()\n","  set_seeds(seed)\n","\n","  data_dict = read_data(data_path, dataset, validation=True)\n","\n","  model = CompactSDT(\n","    in_features=data_dict['nx'],\n","    out_classes=data_dict['ny'],\n","    depth=depth,\n","    tying=tying_ratio)\n","  model = model.to(DEVICE)\n","\n","  if distill:\n","    rf_path = '../out/rf/models/{}.pkl'.format(dataset)\n","    rf_model: RandomForestClassifier = joblib.load(rf_path)\n","    pred_y = rf_model.predict_proba(data_dict['trn_x'])\n","\n","    trn_y = data_dict['trn_y']\n","    trn_y_onehot = np.zeros_like(pred_y)\n","    trn_y_onehot[np.arange(trn_y.shape[0]), trn_y] = 1\n","    data_dict['trn_y'] = (trn_y_onehot + pred_y) / 2\n","\n","  trn_x = data_dict['trn_x']\n","  trn_y = data_dict['trn_y']\n","  val_x = data_dict['val_x']\n","  val_y = data_dict['val_y']\n","\n","  trn_loader = to_loader(trn_x, trn_y, batch_size, shuffle=True)\n","  val_loader = to_loader(val_x, val_y, batch_size)\n","  loaders = (trn_loader, val_loader)\n","\n","  # start_time = time()\n","\n","  train(model, loaders, lambda_l1reg, tree_threshold, log_path)\n","  if pruning_ratio < 1:\n","    model.prune_weights(ratio=pruning_ratio)\n","    train(model, loaders, lambda_l1reg, tree_threshold, log_path)\n","\n","  test_x = data_dict['test_x']\n","  test_y = data_dict['test_y']\n","  test_loader = to_loader(test_x, test_y, batch_size)\n","\n","  # train_time = time() - start_time\n","  os.makedirs(os.path.dirname(model_path), exist_ok=True)\n","  torch.save(model.state_dict(), model_path)\n","  loss, acc = evaluate(model, test_loader, lambda_l1reg)\n","  \n","\n","  return acc"],"execution_count":74,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wm-UsPCzl9L","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597591019411,"user_tz":-180,"elapsed":942,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["def acc_kigb(df_name):\n","  df = data_dic[df_name]\n","  target = pd.DataFrame(df[df.columns[-1]])\n","  train = df.drop([df.columns[-1]], axis=1)\n","  # print(df)\n","  data = np.array(df)\n","  total_num_of_features = len(data[0])-1\n","  feature_per_tree = int(math.sqrt(total_num_of_features))\n","  num_feature = feature_per_tree * feature_per_tree\n","\n","  train_arr = np.array(train).tolist()\n","  target_arr = np.array(target).tolist()\n","  classes = np.unique(target_arr)\n","  i=0\n","  \n","  xtrain, xtest, ytrain, ytest = train_test_split(train, target, test_size=test_size, random_state=random_state)\n","\n","  train_x = np.array(xtrain.values.tolist())\n","  train_y = np.array(ytrain.values.tolist())\n","  test_x = np.array(xtest.values.tolist())\n","  test_y = np.array(ytest.values.tolist())\n"," \n","\n","  gb = GradientBoostingClassifier(verbose=0)\n","  gb.fit(train_x, train_y)\n","  end_time = time()\n","  inference_start_time = time()\n","\n","  pred_y = gb.predict(test_x)\n","\n","  return accuracy_score(test_y,pred_y)\n","\n","  # print('xtrain')\n","  # print(xtrain)\n","  # print('ytrain')\n","  # print(ytrain)\n","\n","  # print('xtest')\n","  # print(xtest)\n","  # print('ytest')\n","  # print(ytest)\n","\n","\n","  # print('train_x')\n","  # print(train_x)\n","  # print('train_y')\n","  # print(train_y)\n","  \n","  # print('test_x')\n","  # print(test_x)\n","  # print('test_y')\n","  # print(test_y) \n","\n","  \n"],"execution_count":75,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqBUYCug0oXI","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560064,"user_tz":-180,"elapsed":8594,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YlCO4dHStcPK","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597591023033,"user_tz":-180,"elapsed":1474,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["\n","def acc_arranged_forest(df_name):\n","  df = data_dic[df_name]\n","  target = pd.DataFrame(df[df.columns[-1]])\n","  train = df.drop([df.columns[-1]], axis=1)\n","  # print()\n","  # print(df_name)\n","  # print()\n","  # print(df)\n","  data = np.array(df)\n","  total_num_of_features = len(df.columns)-1\n","  # print(total_num_of_features)\n","  feature_per_tree = int(math.sqrt(total_num_of_features))\n","  num_feature = feature_per_tree * feature_per_tree\n","  \n","  train_arr = np.array(train).tolist()\n","  target_arr = np.array(target).tolist()\n","  classes = np.unique(target_arr)\n","\n","  # print(data)\n","  # print(feature_per_tree)\n","  \n","  xtrain, xtest, ytrain, ytest = train_test_split(train, target, test_size=test_size, random_state=random_state)\n","\n","  train_x = np.array(xtrain.values.tolist())\n","  train_y = np.array(ytrain.values.tolist())\n","  test_x = np.array(xtest.values.tolist())\n","  test_y = np.array(ytest.values.tolist())\n","\n","\n","  # if df_name=='audiology-std.csv':\n","  # print('xtrain')\n","  # print(train_x.shape)\n","  # print('ytrain')\n","  # print(train_y.shape)\n","  # print('xtest')\n","  # print(test_x.shape)\n","  # print('ytest')\n","  # print(test_y.shape)\n","  # train_x = data[:, 0:-1]\n","  # train_y = data[:, -1]\n","\n","  \n","\n","  # test_x = test[:, 0:-1]\n","  # test_y = test[:, -1]\n","  boot_xtrain, boot_ytrain = bootstrap_samples(feature_per_tree, train_x, train_y, seed=seed)\n","\n","  feature_matrix = build_feature_matrix(num_feature=num_feature, feature_per_tree=feature_per_tree)\n","\n","  k_family_F = modified_diagonal_distribute(feature_per_tree=feature_per_tree, feature_matrix=feature_matrix)\n","\n","  # print(k_family_F)\n","\n","  arranged_clf = ControlledForestClassifier(n_estimators=feature_per_tree)\n","\n","  arranged_clf.fit(k_family_F, boot_xtrain, boot_ytrain, train_y)\n","\n","  \n","  pred_y = arranged_clf.predict(test_x)\n","\n","  return accuracy_score(test_y, pred_y)\n","\n","  # print(arranged_report)"],"execution_count":76,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b0yY8pKLaLoC","colab_type":"text"},"source":["#ad-Hoc"]},{"cell_type":"code","metadata":{"id":"Tq256eCUDFwc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":138},"executionInfo":{"status":"ok","timestamp":1597591052153,"user_tz":-180,"elapsed":774,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"129882f0-62f0-4172-e9fc-3fe16878c26a"},"source":["scl_hoc.posthoc_nemenyi_friedman(df,melted=False)"],"execution_count":79,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EDit</th>\n","      <th>KiGB</th>\n","      <th>Arranged_Forest</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>EDit</th>\n","      <td>1.000</td>\n","      <td>0.001</td>\n","      <td>0.001</td>\n","    </tr>\n","    <tr>\n","      <th>KiGB</th>\n","      <td>0.001</td>\n","      <td>1.000</td>\n","      <td>0.001</td>\n","    </tr>\n","    <tr>\n","      <th>Arranged_Forest</th>\n","      <td>0.001</td>\n","      <td>0.001</td>\n","      <td>1.000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                  EDit   KiGB  Arranged_Forest\n","EDit             1.000  0.001            0.001\n","KiGB             0.001  1.000            0.001\n","Arranged_Forest  0.001  0.001            1.000"]},"metadata":{"tags":[]},"execution_count":79}]},{"cell_type":"markdown","metadata":{"id":"6z3wDm6saOC3","colab_type":"text"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Ms9BP_nTWRQv","colab_type":"text"},"source":["#Main"]},{"cell_type":"code","metadata":{"id":"ZwIope_Wn8Cv","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560065,"user_tz":-180,"elapsed":8566,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["j = 0 \n","for dn in data_dic:\n","  arranged_forest(dn)\n","  # kigb(dn)\n","  # edit_model(dn)\n","  # rotation_forest(dn)\n","  # if j == 3:\n","  #   break\n","  # j+=1\n","FINISH_SOUNDS()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yMMFBzcB_SOD","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560065,"user_tz":-180,"elapsed":8556,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["result_list"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_39FC35Fas7S","colab_type":"text"},"source":["#Meta-Learning Model"]},{"cell_type":"markdown","metadata":{"id":"zQQ4Z_rRyjo8","colab_type":"text"},"source":["##Make dataset"]},{"cell_type":"code","metadata":{"id":"e6e9_pMfymvr","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560066,"user_tz":-180,"elapsed":8547,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pm66lxoJqaeu","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560066,"user_tz":-180,"elapsed":8537,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["# meta_df = pd.DataFrame(columns=['Dataset_Name','Model_Name','accuracy'])\n","# for row in df.values:\n","#   print(row)\n","#   meta_df = meta_df.append({'Dataset_Name':row[0],'Model_Name':'EDit', 'accuracy':row[1]},ignore_index=True)\n","#   meta_df = meta_df.append({'Dataset_Name':row[0],'Model_Name': 'KiGB', 'accuracy':row[2]},ignore_index=True)\n","#   meta_df = meta_df.append({'Dataset_Name':row[0],'Model_Name':'Arranged_Forest', 'accuracy':row[3]},ignore_index=True)\n","#   meta_df = meta_df.append({'Dataset_Name':row[0],'Model_Name':'Rotation_Forest', 'accuracy':row[4]},ignore_index=True)\n","# meta_df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RvoO0yucyqcP","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560067,"user_tz":-180,"elapsed":8528,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":["# import numpy as np\n","# import csv\n","# from csv import reader\n","\n","EDit = 0\n","KiGB = 1\n","Arranged_Forest = 2\n","\n","# drive_path = 'data/'\n","\n","# with open(drive_path + 'alg_acc.csv', 'r') as read_obj:\n","#     alg_acc = np.array(list(reader(read_obj)))\n","# with open(drive_path + 'ClassificationAllMetaFeatures.csv', 'r') as read_obj:\n","#     allMeta = np.array(list(reader(read_obj)))\n","\n","# dataset = np.append(allMeta[0], 'best_alg')\n","\n","# alg_acc = alg_acc[1:, 1:]\n","# allMeta = allMeta[1:]\n","# dataset_names = alg_acc[:, 0]\n","\n","# for i in range(len(allMeta)):\n","#     dataset_name = allMeta[i][0]\n","#     for j in range(len(alg_acc)):\n","#         alg_acc_dataset_name = alg_acc[j][0][:-4]\n","#         if dataset_name == alg_acc_dataset_name:\n","#             algorithms = alg_acc[j][1:]\n","#             best_alg = np.argmax(algorithms)\n","#             dataset_line = np.append(allMeta[i], best_alg)\n","#             dataset = np.vstack((dataset, dataset_line))\n","\n","# csv_file = \"allMeta.csv\"\n","# # opening the csv file in 'w+' mode\n","# file = open(csv_file, 'w+', newline='')\n","\n","# # writing the data into the file\n","# with file:\n","#     write = csv.writer(file)\n","#     write.writerows(dataset)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bWiWGVn-zECb","colab_type":"text"},"source":["##XGBoost Meta-Learning"]},{"cell_type":"code","metadata":{"id":"Whd-wc1zzgls","colab_type":"code","colab":{},"executionInfo":{"status":"aborted","timestamp":1597590560067,"user_tz":-180,"elapsed":8518,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WS4fDCMPzJS8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1597610047750,"user_tz":-180,"elapsed":24265,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"b2556f9c-8ac9-43f2-ab4a-a2bbc0b03139"},"source":["from numpy import genfromtxt\n","from sklearn.model_selection import LeaveOneOut\n","from xgboost import XGBClassifier\n","all_meta_path = '/content/drive/Shared drives/Machine_Learning_Project/project files/allMeta.csv'\n","all_meta = pd.read_csv(all_meta_path)\n","\n","# remove dataset names\n","all_meta = all_meta.drop(['dataset','best_alg.1'],axis=1)\n","# all_meta\n","target = pd.DataFrame(all_meta['best_alg'])\n","# target\n","train = all_meta.drop(['best_alg'], axis=1)\n","# train\n","data = np.array(all_meta)\n","train_arr = np.array(train).tolist()\n","target_arr = np.array(target).tolist()\n","classes = np.unique(target_arr)\n","i=0\n","# start_time = time()\n","# # print('train_arr')\n","# # print(train_arr)\n","# # print('target_arr')\n","# # print(target_arr)\n","# # print(data)\n","# # print(feature_per_tree)\n","\n","\n","meta_df = pd.DataFrame(columns=['accuracy','TPR', 'FPR', 'Precision', 'AUC'])\n","kf = KFold(n_splits=len(data), random_state=random_state, shuffle=True).split(train_arr,target_arr)\n","\n","xgbc = XGBClassifier()\n","\n","for train_idx, test_idx in kf:\n","  i+=1\n","#   # print('train_idx')\n","#   # print(train_idx)\n","#   # print('test_idx')\n","#   # print(test_idx)\n","  train_x=np.array([train_arr[ii] for ii in train_idx])\n","  test_x=np.array([train_arr[ii] for ii in test_idx])\n","  train_y=np.array([target_arr[ii] for ii in train_idx])\n","  test_y=np.array([target_arr[ii] for ii in test_idx])\n","\n","  # train_X = pd.DataFrame(train_x)\n","  # break\n","# train_x\n","  xgbc.fit(train_x,train_y)\n","  pred_y = xgbc.predict_proba(test_x)[0]\n","  # test_y_proba = np.zeros((1,3))[0].tolist()\n","  test_y_proba = np.zeros((1,3),dtype=pred_y.dtype)[0]\n","  test_y_proba[test_y[0][0]]=1\n","  # acc, tpr, fpr, precision, auc, prc = get_metrics(test_y_proba, pred_y, classes)\n","  acc, tpr, fpr, precision,auc = get_metrics(test_y_proba.T, pred_y.round().T, classes)\n","  print('accuracy',acc,'TPR',tpr, 'FPR',fpr, 'Precision',precision, 'AUC',auc)\n","  meta_df = meta_df.append({'accuracy':acc,'TPR':tpr, 'FPR':fpr, 'Precision':precision, 'AUC':auc},ignore_index=True)\n","  # break\n","# test_y[0][0]\n","# test_y_proba\n","# pred_y.round()\n","# classes\n","\n","\n","# meta_df.to_csv('/content/drive/Shared drives/Machine_Learning_Project/project files/allMeta_metrics.csv')\n","# # dataset = genfromtxt(drive_path + 'abalon.csv', delimiter=',', skip_header=1)\n","\n","\n","\n","# # # split data into X and y\n","# # dataset_names = dataset[:, 0]\n","# # X = dataset[:, 1:-1]\n","# # Y = dataset[:, -1]\n","\n","# # model = XGBClassifier()\n","# # loo = LeaveOneOut()\n","# # for train_index, test_index in loo.split(X):\n","# #     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","# #     X_train, X_test = X[train_index], X[test_index]\n","# #     y_train, y_test = Y[train_index], Y[test_index]\n","# #     print(X_train, X_test, y_train, y_test)\n","# #     dataset_test_name = dataset_names[test_index]\n","\n","# #     model.fit(X_train, y_train)\n","# #     y_pred_prob = model.predict_proba(X_test)\n","\n","# # # split data into train and test sets\n"],"execution_count":303,"outputs":[{"output_type":"stream","text":["accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.6666666666666666 TPR [1. 0.] FPR [1. 0.] Precision 0.3333333333333333 AUC 0.5\n","accuracy 0.6666666666666666 TPR [1. 0.] FPR [1. 0.] Precision 0.3333333333333333 AUC 0.5\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 1.0 TPR [1. 1.] FPR [0. 0.] Precision 1.0 AUC 1.0\n","accuracy 0.3333333333333333 TPR [0.5 0. ] FPR [1.  0.5] Precision 0.25 AUC 0.25\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rVcwAW6mKQso","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":126},"executionInfo":{"status":"ok","timestamp":1597609908799,"user_tz":-180,"elapsed":7191,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"3702d655-86a4-4f33-b89e-bb0a1c8bcce1"},"source":["meta_df.mean(0)"],"execution_count":299,"outputs":[{"output_type":"execute_result","data":{"text/plain":["accuracy                        0.65942\n","TPR          [0.75, 0.4782608695652174]\n","FPR          [0.5217391304347826, 0.25]\n","Precision                      0.610507\n","AUC                             0.61413\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":299}]},{"cell_type":"code","metadata":{"id":"SXfIId_LC-gb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":485},"executionInfo":{"status":"ok","timestamp":1597610571804,"user_tz":-180,"elapsed":17180,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"161aec4b-4f60-4629-9ab6-90937e381ba9"},"source":["import matplotlib\n","xgb.plot_tree(xgbc,num_trees=2)\n","fig = matplotlib.pyplot.gcf()\n","fig.set_size_inches(150, 100)\n","fig.savefig('tree.png')"],"execution_count":310,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 10800x7200 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"3GBh35QxBFDb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"status":"ok","timestamp":1597611218011,"user_tz":-180,"elapsed":1004,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"77df6482-d88e-4769-86a7-c2a41ad43cd0"},"source":["xgb.plot_importance(xgbc, importance_type=\"weight\",max_num_features=20)"],"execution_count":323,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f142324b390>"]},"metadata":{"tags":[]},"execution_count":323},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"3ODhUOrVBvNo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"status":"ok","timestamp":1597611283390,"user_tz":-180,"elapsed":1348,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"8f73d67f-8070-40de-fbd2-7cd0fce2647b"},"source":["xgb.plot_importance(xgbc, importance_type=\"gain\",max_num_features=20)"],"execution_count":324,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f1423181c88>"]},"metadata":{"tags":[]},"execution_count":324},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"N0uG9ERXDiJz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":313},"executionInfo":{"status":"ok","timestamp":1597611328590,"user_tz":-180,"elapsed":1561,"user":{"displayName":"Shawn Seiref","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiDZwr3l6tGETAy6zbfvk9ZA5FA79ThUCB84Fim=s64","userId":"12245099796351150260"}},"outputId":"c1fca17b-f211-49e5-c6fb-b02fca571ef4"},"source":["xgb.plot_importance(xgbc, importance_type=\"cover\",max_num_features=20)"],"execution_count":325,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f1423137320>"]},"metadata":{"tags":[]},"execution_count":325},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}